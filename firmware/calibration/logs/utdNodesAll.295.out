Running calibration scripts for UTD Node: 6
Running on host: compute-1-1-21

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
              R2020a Update 1 (9.8.0.1359463) 64-bit (glnxa64)
                               April 9, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 


    "---------------------MINTS---------------------"

19-Nov-2020 09:25:18

mintsDefinitions = 

  struct with fields:

                dataFolder: '/home/lhw150030/mintsData'
               poolWorkers: 16
                  timeSpan: 30
                  airmarID: '001e0610c0e4'
             binsPerColumn: 500
              numberPerBin: 2
                    pValid: 0.1500
                   nodeIDs: {1x16 cell}
               inputStack1: {1x9 cell}
         mintsInputsStack1: {1x35 cell}
    mintsInputLabelsStack1: {1x35 cell}
               inputStack2: {1x11 cell}
         mintsInputsStack2: {1x35 cell}
    mintsInputLabelsStack2: {1x35 cell}
               inputStack3: {1x10 cell}
         mintsInputsStack3: {1x38 cell}
    mintsInputLabelsStack3: {1x38 cell}
              mintsTargets: {1x10 cell}
         mintsTargetLabels: {1x10 cell}
                     units: {1x10 cell}
               instruments: {1x10 cell}

Starting parallel pool (parpool) using the 'local' profile ...
Connected to the parallel pool (number of workers: 16).

ans = 

 ProcessPool with properties: 

            Connected: true
           NumWorkers: 16
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


airmarFolder = 

    "/home/lhw150030/mintsData/referenceMats/airmar"

UTD_Rsl_All_2020_11_19_09_25_44


UTD_Rsl_All_Daily


Super Learner All Inputs




    "Data Folder Located @:/home/lhw150030/mintsData"

    "Raw Data Located @: /home/lhw150030/mintsData"

    "Raw DotMat Data Located @ :/home/lhw150030/mintsData/rawMats"

    "UTD Nodes DotMat Data Located @ :/home/lhw150030/mintsData/rawMats/UTDNodes"

    "Reference Data Located @: /home/lhw150030/mintsData/reference"

    "Reference DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats"

    "Palas Raw Data Located @ :/home/lhw150030/mintsData/reference/palasStream"

    "Palas DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats/palas"

    "Car GPS Files Located @ :/home/lhw150030/mintsData/referenceMats/carMintsGPS"

    "Loading Palas Files"

    "Loading GPS Files"

    "Loading Airmar Files"

    "Aligning GPS data with Palas Data"

    "WSTC Palas Data"

    "Palas With Airmar"

    "Analysis"

    "Save merged data for calibration: 001e06305a57"



    "Creating Training Data Sets for Node: 001e06305a57"



    "Gainin Data set for Node 001e06305a57 with target output pm1_palas @ 19-Nov-2020 09:25:55"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 315 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 68 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 87 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 59 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 24 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 12 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 10 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 9 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 6 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 5 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 218 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 284 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 214 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 128 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        9018


ans =

        1591

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |       1 | Best   |      9.4925 |      2.7262 |      9.4925 |      30.834 |            8 |      0.84842 |
|    2 |       1 | Accept |      46.342 |      2.9482 |      9.4925 |      30.834 |           78 |      0.92742 |
|    3 |       1 | Accept |      17.978 |      2.8008 |      9.4925 |      30.834 |           26 |     0.017495 |
|    4 |       1 | Accept |      18.778 |      2.8102 |      9.4925 |      30.834 |           96 |     0.006571 |
|    5 |       1 | Accept |      50.762 |      2.7791 |      9.4925 |      30.834 |           77 |      0.33654 |
|    6 |       1 | Accept |      21.032 |      2.7431 |      9.4925 |      30.834 |           83 |      0.22175 |
|    7 |       1 | Accept |      49.516 |      2.7717 |      9.4925 |      30.834 |           90 |      0.47026 |
|    8 |       1 | Accept |      13.582 |      2.7121 |      9.4925 |      30.834 |           24 |    0.0011762 |
|    9 |       1 | Accept |      25.952 |       2.687 |      9.4925 |      30.834 |           39 |      0.34644 |
|   10 |       1 | Accept |      39.741 |      2.7593 |      9.4925 |      30.834 |           48 |    0.0016828 |
|   11 |       1 | Accept |      54.187 |      2.7072 |      9.4925 |      30.834 |           69 |     0.011725 |
|   12 |       1 | Accept |       38.23 |      2.7322 |      9.4925 |      30.834 |           69 |    0.0010981 |
|   13 |       1 | Accept |      23.324 |      2.7927 |      9.4925 |      30.834 |           37 |    0.0084656 |
|   14 |       1 | Accept |      19.007 |      2.6976 |      9.4925 |      30.834 |           67 |      0.16328 |
|   15 |       1 | Accept |      126.54 |      2.6899 |      9.4925 |      30.834 |           63 |      0.34082 |
|   16 |       1 | Accept |      55.893 |      2.7315 |      9.4925 |      30.834 |           87 |     0.053589 |
|   17 |      16 | Accept |      22.645 |     0.52087 |      9.4925 |      27.908 |           15 |    0.0010169 |
|   18 |       2 | Accept |       14.49 |     0.61448 |      9.4925 |      34.365 |           47 |      0.32343 |
|   19 |       2 | Accept |        42.8 |      0.6999 |      9.4925 |      34.365 |           91 |    0.0071229 |
|   20 |       2 | Accept |      33.053 |     0.55203 |      9.4925 |      34.365 |           16 |      0.14165 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       2 | Accept |      46.296 |     0.58238 |      9.4925 |      34.365 |           50 |      0.24213 |
|   22 |       2 | Accept |      15.891 |     0.57179 |      9.4925 |      34.365 |           29 |    0.0025563 |
|   23 |       2 | Accept |      25.189 |     0.60685 |      9.4925 |      34.365 |           69 |      0.54339 |
|   24 |       2 | Accept |      23.736 |     0.58046 |      9.4925 |      34.365 |            7 |      0.27617 |
|   25 |       2 | Accept |      31.917 |     0.60639 |      9.4925 |      34.365 |           44 |     0.024283 |
|   26 |       2 | Accept |      38.421 |     0.62136 |      9.4925 |      34.365 |           55 |      0.19914 |
|   27 |       2 | Accept |      34.539 |     0.53979 |      9.4925 |      34.365 |           24 |      0.23825 |
|   28 |       2 | Accept |      43.496 |     0.76509 |      9.4925 |      34.365 |           92 |    0.0073803 |
|   29 |       2 | Accept |      16.392 |     0.63652 |      9.4925 |      34.365 |           63 |      0.70357 |
|   30 |       2 | Accept |      48.753 |     0.56224 |      9.4925 |      34.365 |           18 |      0.51128 |
|   31 |       2 | Accept |      40.182 |     0.64009 |      9.4925 |      34.365 |           36 |    0.0045952 |
|   32 |       2 | Accept |      11.533 |     0.64305 |      9.4925 |      34.365 |           80 |      0.35573 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 32
Total elapsed time: 15.8988 seconds.
Total objective function evaluation time: 53.8321

Best observed feasible point:
    hiddenLayerSize      lr   
    _______________    _______

           8           0.84842

Observed objective function value = 9.4925
Estimated objective function value = 34.3652
Function evaluation time = 2.7262

Best estimated feasible point (according to models):
    hiddenLayerSize      lr   
    _______________    _______

           7           0.27617

Estimated objective function value = 34.3652
Estimated function evaluation time = 1.2923


T =

  1x2 table

    hiddenLayerSize      lr   
    _______________    _______

           7           0.27617

Elapsed time is 22.013395 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      3.1184 |      202.32 |      3.1184 |      3.1184 |       1.5108 |     constant |     matern32 |   1.0975e+11 |         true |
|    2 |      16 | Accept |      8.7751 |      225.68 |      3.1184 |      3.3433 |   0.00023607 | pureQuadrati |     matern52 |   9.0654e+11 |         true |
|    3 |      16 | Accept |      6.9412 |      226.56 |      3.1184 |      3.1195 |    0.0059861 |       linear |     matern52 |   2.8383e+12 |         true |
|    4 |      16 | Accept |      9.0318 |      234.88 |      3.1184 |      3.3286 |      0.31268 |       linear |  exponential |   1.2859e+13 |         true |
|    5 |      16 | Accept |      7.4205 |      245.55 |      3.1184 |      3.3188 |       6.2345 |       linear |  exponential |   4.5756e+12 |         true |
|    6 |      16 | Best   |      3.1179 |      223.51 |      3.1179 |      3.3491 |   0.00011144 |     constant |     matern32 |   3.4738e+11 |         true |
|    7 |      16 | Best   |      3.1176 |      243.51 |      3.1176 |      3.2217 |       36.434 |     constant |     matern32 |   5.7474e+11 |         true |
|    8 |      16 | Best   |      3.1175 |      243.71 |      3.1175 |      3.1768 |       7.8444 |     constant |     matern32 |   3.3749e+10 |         true |
|    9 |      16 | Accept |      3.1181 |      247.33 |      3.1175 |       3.117 |      0.19177 |     constant |     matern32 |   8.3076e+10 |         true |
|   10 |      16 | Accept |       3.643 |      543.36 |      3.1175 |      3.1171 |     0.029988 |         none |     matern52 |   1.7007e+13 |        false |
|   11 |      16 | Accept |      3.1178 |      218.04 |      3.1175 |      3.1173 |     0.009034 |     constant |     matern52 |   1.9153e+13 |         true |
|   12 |      16 | Accept |      3.1181 |      244.74 |      3.1175 |      3.1173 |        3.996 |     constant |  exponential |   2.0041e+13 |         true |
|   13 |      16 | Accept |      7.8676 |      237.66 |      3.1175 |      3.1062 |       9.5423 |       linear |  exponential |   2.0686e+10 |         true |
|   14 |      16 | Accept |      3.1176 |      239.79 |      3.1175 |      3.1331 |       22.747 |     constant |     matern52 |   1.1032e+11 |         true |
|   15 |      16 | Accept |      4.9473 |       525.1 |      3.1175 |      3.1349 |    0.0010917 |     constant |     matern32 |   1.5146e+13 |        false |
|   16 |      16 | Accept |      3.1176 |      144.98 |      3.1175 |      3.1334 |       31.129 |         none |     matern32 |    1.115e+11 |         true |
|   17 |      16 | Error  |         NaN |      482.29 |      3.1175 |      3.1334 |     0.014306 |     constant |     matern52 |   1.1941e+11 |        false |
|   18 |      16 | Accept |      3.1308 |      704.99 |      3.1175 |      3.1322 |       20.564 |         none |     matern52 |   4.0267e+10 |        false |
|   19 |      16 | Best   |      1.6987 |      557.49 |      1.6987 |       2.454 |       0.1083 |     constant |  exponential |   1.0433e+11 |         true |
|   20 |      16 | Accept |      3.1176 |      157.78 |      1.6987 |      2.4539 |       19.614 |         none |     matern52 |   5.7685e+11 |         true |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      16 | Error  |         NaN |      459.61 |      1.6987 |      2.4539 |       1.8736 |     constant |  exponential |   1.8286e+13 |        false |
|   22 |      16 | Accept |      5.9143 |      363.37 |      1.6987 |      2.4625 |        1.289 |         none |     matern32 |   1.1892e+12 |        false |
|   23 |      16 | Accept |      3.1178 |       236.9 |      1.6987 |      2.4622 |      0.34966 |     constant | rationalquad |   4.7903e+10 |         true |
|   24 |      16 | Accept |      3.1176 |      217.98 |      1.6987 |      2.4626 |       9.5193 |         none | rationalquad |   4.5849e+11 |         true |
|   25 |      16 | Accept |      3.1176 |      156.64 |      1.6987 |      2.4634 |       13.773 |         none |  exponential |   2.0921e+10 |         true |
|   26 |      16 | Accept |      3.1174 |      199.37 |      1.6987 |      2.4646 |    0.0001081 |     constant | squaredexpon |   4.8279e+10 |         true |
|   27 |      16 | Accept |      3.1176 |      141.51 |      1.6987 |      2.4774 |      0.99825 |         none | squaredexpon |   4.2172e+11 |         true |
|   28 |      16 | Accept |      3.1178 |       236.3 |      1.6987 |      2.4775 |       1.3773 |         none | squaredexpon |   3.5681e+11 |        false |
|   29 |      16 | Best   |      1.6839 |      558.84 |      1.6839 |       1.653 |    0.0083676 |     constant |  exponential |   2.0847e+10 |         true |
|   30 |      16 | Error  |         NaN |      442.76 |      1.6839 |       1.653 |    0.0016259 |     constant | squaredexpon |   5.0128e+10 |        false |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 2146.6753 seconds.
Total objective function evaluation time: 9162.5692

Best observed feasible point:
      Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    _________    _____________    ______________    ___________    ___________

    0.0083676      constant        exponential      2.0847e+10        true    

Observed objective function value = 1.6839
Estimated objective function value = 1.653
Function evaluation time = 558.841

Best estimated feasible point (according to models):
      Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    _________    _____________    ______________    ___________    ___________

    0.0083676      constant        exponential      2.0847e+10        true    

Estimated objective function value = 1.653
Estimated function evaluation time = 562.6355

Elapsed time is 2163.774416 seconds.
Take a copy of the best attributes
Now use these optimum settings to do an exact GPR fit
Elapsed time is 9.854234 seconds.
Train a hyper-parameter optimized Ensemble of Trees model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|    1 |      16 | Best   |      2.5014 |      2.0574 |      2.5014 |      2.5014 |          Bag |           11 |            - |           61 |            8 |            6 |
|    2 |      15 | Accept |      2.9928 |      3.2559 |      2.5014 |      2.5642 |          Bag |           36 |            - |           40 |          192 |            3 |
|    3 |      15 | Accept |      3.3347 |      2.3916 |      2.5014 |      2.5642 |      LSBoost |           12 |     0.023226 |           39 |         2658 |            5 |
|    4 |      12 | Accept |      3.1177 |      7.4927 |      1.5228 |      1.5307 |          Bag |          139 |            - |          467 |         8950 |            1 |
|    5 |      12 | Best   |      1.5228 |      7.2541 |      1.5228 |      1.5307 |          Bag |           34 |            - |            1 |          784 |            5 |
|    6 |      12 | Accept |      2.9897 |      6.0947 |      1.5228 |      1.5307 |      LSBoost |           73 |     0.029077 |            2 |         3492 |            3 |
|    7 |      12 | Accept |      1.9663 |      2.6569 |      1.5228 |      1.5307 |      LSBoost |           25 |      0.15879 |            4 |           48 |            4 |
|    8 |       9 | Accept |        2.19 |      10.649 |      1.5228 |      1.5229 |          Bag |           40 |            - |            4 |            8 |           26 |
|    9 |       9 | Accept |      2.3314 |      8.8657 |      1.5228 |      1.5229 |      LSBoost |           20 |     0.053108 |          122 |           56 |           34 |
|   10 |       9 | Accept |      2.7785 |      9.7208 |      1.5228 |      1.5229 |          Bag |           95 |            - |          951 |           97 |           14 |
|   11 |       9 | Accept |      2.5844 |     0.87762 |      1.5228 |      1.5229 |          Bag |           10 |            - |           45 |            9 |            4 |
|   12 |      16 | Accept |      3.6143 |      13.145 |      1.5228 |      1.5229 |      LSBoost |           31 |    0.0028549 |            1 |          274 |           20 |
|   13 |      13 | Accept |      2.5468 |      16.417 |      1.5228 |      1.5229 |          Bag |           95 |            - |          161 |            5 |           22 |
|   14 |      13 | Accept |      3.1024 |      14.878 |      1.5228 |      1.5229 |      LSBoost |          373 |      0.28574 |         1207 |         1928 |            2 |
|   15 |      13 | Accept |      2.5457 |      2.2062 |      1.5228 |      1.5229 |          Bag |           14 |            - |          177 |          730 |            9 |
|   16 |      13 | Accept |      2.4373 |      2.0998 |      1.5228 |      1.5229 |      LSBoost |           18 |      0.20797 |         1684 |          482 |           27 |
|   17 |      10 | Best   |      1.1605 |      19.132 |      1.1605 |      1.1607 |          Bag |           28 |            - |           14 |         1184 |           32 |
|   18 |      10 | Accept |       1.962 |      18.094 |      1.1605 |      1.1607 |          Bag |           66 |            - |           80 |           96 |           18 |
|   19 |      10 | Accept |      2.3509 |      5.5692 |      1.1605 |      1.1607 |          Bag |           26 |            - |            5 |           15 |           21 |
|   20 |      10 | Accept |      3.0657 |      4.4133 |      1.1605 |      1.1607 |          Bag |           76 |            - |           23 |            3 |            3 |
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|   21 |      15 | Accept |      1.2171 |      8.2386 |      1.1605 |      1.1606 |          Bag |           14 |            - |            2 |          301 |           31 |
|   22 |      15 | Accept |      3.0715 |     0.75631 |      1.1605 |      1.1606 |          Bag |           10 |            - |            1 |            3 |            2 |
|   23 |      11 | Accept |      2.8836 |      13.112 |      1.1605 |      1.1606 |          Bag |          275 |            - |         2023 |          873 |            4 |
|   24 |      11 | Accept |      3.1934 |      14.881 |      1.1605 |      1.1606 |      LSBoost |          126 |    0.0038502 |         1199 |           82 |           32 |
|   25 |      11 | Accept |      2.8837 |      1.0394 |      1.1605 |      1.1606 |          Bag |           12 |            - |         2688 |          212 |           17 |
|   26 |      11 | Accept |      2.5705 |      2.2969 |      1.1605 |      1.1606 |      LSBoost |           36 |      0.16186 |         2352 |            1 |           26 |
|   27 |      11 | Accept |      3.6045 |     0.74491 |      1.1605 |      1.1606 |      LSBoost |           11 |     0.015552 |           65 |         1918 |            2 |
|   28 |      15 | Accept |      1.6327 |      21.263 |      1.1605 |       1.212 |          Bag |           88 |            - |            1 |          140 |           13 |
|   29 |      15 | Accept |      2.1071 |      18.559 |      1.1605 |       1.212 |          Bag |           83 |            - |            9 |           22 |           20 |
|   30 |      15 | Accept |      1.8089 |      2.4735 |      1.1605 |      1.2245 |      LSBoost |           17 |      0.87053 |            3 |           48 |            7 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 44.228 seconds.
Total objective function evaluation time: 240.6354

Best observed feasible point:
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             28               NaN           14             1184                 32         

Observed objective function value = 1.1605
Estimated objective function value = 1.2244
Function evaluation time = 19.1318

Best estimated feasible point (according to models):
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             14               NaN            2             301                  31         

Estimated objective function value = 1.2245
Estimated function evaluation time = 7.941

Elapsed time is 46.964122 seconds.
Train the super learner model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Error  |         NaN |      187.65 |         NaN |         NaN |     0.015211 | pureQuadrati |  exponential |   2.5104e+11 |        false |
