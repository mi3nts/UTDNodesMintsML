Running calibration scripts for UTD Node: 15
Running on host: compute-1-1-15

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
              R2020a Update 1 (9.8.0.1359463) 64-bit (glnxa64)
                               April 9, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 


    "---------------------MINTS---------------------"

22-Nov-2020 18:38:33

mintsDefinitions = 

  struct with fields:

                dataFolder: '/home/lhw150030/mintsData'
               poolWorkers: 16
                  timeSpan: 30
                  airmarID: '001e0610c0e4'
             binsPerColumn: 500
              numberPerBin: 2
                    pValid: 0.1500
                   nodeIDs: {1x16 cell}
               inputStack1: {1x9 cell}
         mintsInputsStack1: {1x35 cell}
    mintsInputLabelsStack1: {1x35 cell}
               inputStack2: {1x11 cell}
         mintsInputsStack2: {1x35 cell}
    mintsInputLabelsStack2: {1x35 cell}
               inputStack3: {1x10 cell}
         mintsInputsStack3: {1x38 cell}
    mintsInputLabelsStack3: {1x38 cell}
              mintsTargets: {1x10 cell}
         mintsTargetLabels: {1x10 cell}
                     units: {1x10 cell}
               instruments: {1x10 cell}

Starting parallel pool (parpool) using the 'local' profile ...
Connected to the parallel pool (number of workers: 16).

ans = 

 ProcessPool with properties: 

            Connected: true
           NumWorkers: 16
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


airmarFolder = 

    "/home/lhw150030/mintsData/referenceMats/airmar"

UTD_Rsl_All_2020_11_22_18_39_00


UTD_Rsl_All_Daily


Super Learner All Inputs




    "Data Folder Located @:/home/lhw150030/mintsData"

    "Raw Data Located @: /home/lhw150030/mintsData"

    "Raw DotMat Data Located @ :/home/lhw150030/mintsData/rawMats"

    "UTD Nodes DotMat Data Located @ :/home/lhw150030/mintsData/rawMats/UTDNodes"

    "Reference Data Located @: /home/lhw150030/mintsData/reference"

    "Reference DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats"

    "Palas Raw Data Located @ :/home/lhw150030/mintsData/reference/palasStream"

    "Palas DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats/palas"

    "Car GPS Files Located @ :/home/lhw150030/mintsData/referenceMats/carMintsGPS"

    "Loading Palas Files"

    "Loading GPS Files"

    "Loading Airmar Files"

    "Aligning GPS data with Palas Data"

    "WSTC Palas Data"

    "Palas With Airmar"

    "Analysis"

    "Save merged data for calibration: 001e06318cf1"



    "Creating Training Data Sets for Node: 001e06318cf1"



    "Gainin Data set for Node 001e06318cf1 with target output pm1_palas @ 22-Nov-2020 18:39:08"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 292 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 73 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 213 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 97 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 49 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 13 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 10 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 7 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 6 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 219 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 77 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 37 and choosing a representative sample. Choosing 140 bins for this column. With 2 members per bin.
Going through column 38 and choosing a representative sample. Choosing 282 bins for this column. With 2 members per bin.
Going through column 39 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        8627


ans =

        1522

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |       1 | Accept |      39.828 |      3.0698 |      5.3384 |      14.666 |            6 |      0.97097 |
|    2 |       1 | Accept |      24.054 |      3.1216 |      5.3384 |      14.666 |           67 |    0.0014335 |
|    3 |       1 | Accept |      46.939 |      3.1088 |      5.3384 |      14.666 |           98 |      0.26651 |
|    4 |       1 | Best   |      5.3384 |      2.9516 |      5.3384 |      14.666 |           19 |     0.010056 |
|    5 |       1 | Accept |      25.966 |      3.0141 |      5.3384 |      14.666 |           71 |    0.0040894 |
|    6 |       1 | Accept |      12.408 |      3.0048 |      5.3384 |      14.666 |           20 |      0.96442 |
|    7 |       1 | Accept |      36.174 |      2.9854 |      5.3384 |      14.666 |           55 |    0.0068442 |
|    8 |       1 | Accept |      22.757 |      3.0207 |      5.3384 |      14.666 |           70 |      0.26547 |
|    9 |       1 | Accept |      11.957 |      3.0312 |      5.3384 |      14.666 |           97 |     0.013333 |
|   10 |       1 | Accept |      14.647 |      2.9359 |      5.3384 |      14.666 |           38 |    0.0012094 |
|   11 |       1 | Accept |      79.992 |      3.0246 |      5.3384 |      14.666 |           83 |     0.014177 |
|   12 |       1 | Accept |      46.278 |      2.9975 |      5.3384 |      14.666 |           85 |      0.13151 |
|   13 |       1 | Accept |      18.576 |      2.9404 |      5.3384 |      14.666 |           49 |    0.0013057 |
|   14 |       1 | Accept |       10.72 |      2.9253 |      5.3384 |      14.666 |            9 |      0.15665 |
|   15 |       1 | Accept |      14.589 |      2.9398 |      5.3384 |      14.666 |           60 |       0.5412 |
|   16 |       1 | Accept |      8.4133 |      2.8504 |      5.3384 |      14.666 |           26 |     0.060741 |
|   17 |       1 | Accept |       11.52 |     0.59602 |      5.3384 |      18.124 |           23 |    0.0010278 |
|   18 |       1 | Accept |      44.977 |     0.62366 |      5.3384 |      18.124 |           88 |     0.053742 |
|   19 |       1 | Accept |       8.517 |      0.5874 |      5.3384 |      18.124 |           40 |      0.76482 |
|   20 |       1 | Accept |      22.088 |     0.66446 |      5.3384 |      18.124 |           74 |    0.0050907 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       1 | Accept |      12.082 |     0.62723 |      5.3384 |      18.124 |           95 |      0.33593 |
|   22 |       1 | Accept |      16.731 |     0.60844 |      5.3384 |      18.124 |           59 |     0.095836 |
|   23 |       1 | Accept |      25.329 |     0.66808 |      5.3384 |      18.124 |           75 |      0.22838 |
|   24 |       1 | Accept |      45.718 |     0.53234 |      5.3384 |      18.124 |           23 |      0.47432 |
|   25 |       1 | Accept |      30.709 |       0.613 |      5.3384 |      18.124 |           34 |     0.082216 |
|   26 |       1 | Accept |      26.652 |     0.70339 |      5.3384 |      18.124 |           59 |     0.010785 |
|   27 |       1 | Accept |        45.3 |     0.58233 |      5.3384 |      18.124 |           35 |      0.66716 |
|   28 |       1 | Accept |      21.334 |     0.54848 |      5.3384 |      18.124 |           32 |     0.029685 |
|   29 |       1 | Accept |      22.416 |     0.59175 |      5.3384 |      18.124 |           30 |     0.091584 |
|   30 |       1 | Accept |      62.129 |     0.70715 |      5.3384 |      18.124 |           58 |     0.021347 |
|   31 |       1 | Accept |      63.909 |     0.60899 |      5.3384 |      18.124 |           68 |      0.04349 |
|   32 |       1 | Accept |      15.293 |     0.62507 |      5.3384 |      18.124 |           29 |     0.014107 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 32
Total elapsed time: 14.8215 seconds.
Total objective function evaluation time: 57.81

Best observed feasible point:
    hiddenLayerSize       lr   
    _______________    ________

          19           0.010056

Observed objective function value = 5.3384
Estimated objective function value = 18.1241
Function evaluation time = 2.9516

Best estimated feasible point (according to models):
    hiddenLayerSize       lr   
    _______________    ________

          19           0.010056

Estimated objective function value = 18.1241
Estimated function evaluation time = 1.3583


T =

  1x2 table

    hiddenLayerSize       lr   
    _______________    ________

          19           0.010056

Elapsed time is 47.848130 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      2.9922 |      153.97 |      2.9922 |      2.9922 |       16.081 |         none |  exponential |   3.9163e+12 |        false |
|    2 |      16 | Accept |      18.007 |      198.66 |      2.9922 |      3.5892 |       1.6346 | pureQuadrati |     matern52 |   2.1879e+11 |         true |
|    3 |      16 | Best   |       2.992 |      209.69 |       2.992 |      3.2971 |      0.84108 |     constant |     matern52 |   9.1268e+09 |         true |
|    4 |      16 | Best   |      2.8128 |      313.39 |      2.8128 |      2.8138 |       0.0295 |     constant |  exponential |   2.0901e+12 |        false |
|    5 |      16 | Accept |      2.9924 |      320.24 |      2.8128 |      2.8209 |        42.06 |         none | rationalquad |   3.0734e+10 |        false |
|    6 |      16 | Accept |      2.9925 |      133.51 |      2.8128 |      2.8131 |       39.279 |         none |  exponential |    3.934e+11 |        false |
|    7 |      16 | Accept |      2.8128 |      402.59 |      2.8128 |      2.8129 |   0.00011287 |     constant |  exponential |   1.9349e+12 |        false |
|    8 |      16 | Accept |       4.672 |      546.81 |      2.8128 |      2.8129 |   0.00016333 |       linear |  exponential |   1.4845e+12 |         true |
|    9 |      16 | Accept |       20.41 |      551.37 |      2.8128 |       2.813 |    0.0017994 |       linear |     matern52 |   9.4522e+09 |        false |
|   10 |      16 | Accept |      2.9922 |      211.09 |      2.8128 |       2.813 |       0.3964 |     constant |     matern32 |   1.5484e+12 |        false |
|   11 |      16 | Best   |      2.7125 |      248.19 |      2.7125 |      2.7795 |       3.2284 |     constant |  exponential |   7.2753e+09 |        false |
|   12 |      16 | Accept |      12.589 |      676.68 |      2.7125 |      2.7795 |    0.0005749 |     constant | rationalquad |   6.0493e+10 |        false |
|   13 |      16 | Accept |      2.9922 |      147.34 |      2.7125 |      2.7795 |      0.44299 |         none |  exponential |   3.7927e+11 |         true |
|   14 |      16 | Accept |      2.9922 |      400.08 |      2.7125 |       2.779 |       6.7209 |         none | rationalquad |   5.4137e+12 |        false |
|   15 |      16 | Accept |        20.2 |      744.28 |      2.7125 |      2.7795 |   0.00036932 | pureQuadrati | rationalquad |   1.6567e+10 |         true |
|   16 |      16 | Accept |      2.9931 |      560.62 |      2.7125 |      2.7795 |    0.0038716 |     constant |     matern52 |   3.1991e+10 |         true |
|   17 |      16 | Accept |      2.9929 |      230.63 |      2.7125 |      2.7795 |      0.50739 |     constant |     matern32 |   1.0141e+11 |         true |
|   18 |      16 | Accept |       2.993 |      141.98 |      2.7125 |      2.7795 |       37.797 |         none |     matern32 |   2.5856e+10 |        false |
|   19 |      16 | Accept |      2.9923 |      254.61 |      2.7125 |      2.7795 |       0.6239 |     constant |     matern52 |   1.8241e+11 |        false |
|   20 |      16 | Accept |      2.9922 |      149.76 |      2.7125 |      2.7795 |      0.73121 |         none |     matern32 |   1.4946e+11 |         true |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      16 | Best   |      1.4439 |      520.58 |      1.4439 |      1.4443 |    0.0028609 |     constant |  exponential |   8.4968e+11 |         true |
|   22 |      16 | Accept |      2.9922 |      146.81 |      1.4439 |      1.4443 |       25.431 |         none |     matern52 |    1.638e+10 |         true |
|   23 |      16 | Accept |      2.9923 |      143.43 |      1.4439 |      1.4443 |       10.439 |         none | squaredexpon |   1.4226e+12 |        false |
|   24 |      16 | Accept |      8.5748 |      443.44 |      1.4439 |      1.4443 |      0.16625 |       linear |  exponential |   3.1644e+11 |        false |
|   25 |      16 | Accept |      2.9922 |      218.39 |      1.4439 |      1.4443 |       12.515 |         none | rationalquad |   9.5475e+11 |         true |
|   26 |      16 | Accept |       20.92 |      895.73 |      1.4439 |      1.4443 |       0.5697 | pureQuadrati | rationalquad |   7.1252e+10 |        false |
|   27 |      16 | Accept |      2.9922 |      147.06 |      1.4439 |      1.4443 |       12.055 |         none | squaredexpon |   1.6834e+12 |         true |
|   28 |      16 | Accept |      2.9922 |      157.14 |      1.4439 |      1.4443 |       18.196 |         none |     matern52 |   6.4243e+12 |        false |
|   29 |      16 | Accept |      2.9924 |      234.05 |      1.4439 |      1.4443 |       7.0166 |     constant | squaredexpon |   2.3665e+12 |         true |
|   30 |      16 | Accept |      2.8696 |      549.25 |      1.4439 |      1.4443 |     0.024441 |       linear |     matern32 |   4.2048e+11 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 1432.5558 seconds.
Total objective function evaluation time: 10051.3897

Best observed feasible point:
      Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    _________    _____________    ______________    ___________    ___________

    0.0028609      constant        exponential      8.4968e+11        true    

Observed objective function value = 1.4439
Estimated objective function value = 1.4443
Function evaluation time = 520.5786

Best estimated feasible point (according to models):
      Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    _________    _____________    ______________    ___________    ___________

    0.0028609      constant        exponential      8.4968e+11        true    

Estimated objective function value = 1.4443
Estimated function evaluation time = 520.5407

Elapsed time is 1450.665663 seconds.
Take a copy of the best attributes
Now use these optimum settings to do an exact GPR fit
Elapsed time is 9.806687 seconds.
Train a hyper-parameter optimized Ensemble of Trees model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|    1 |      16 | Best   |      2.0327 |      1.7851 |      2.0327 |      2.0327 |          Bag |           10 |            - |           31 |           15 |            5 |
|    2 |      15 | Accept |      2.3753 |      2.3559 |      2.0327 |      2.0863 |          Bag |           15 |            - |          252 |            3 |           11 |
|    3 |      15 | Accept |      2.5877 |      2.9093 |      2.0327 |      2.0863 |          Bag |           35 |            - |           15 |            3 |            2 |
|    4 |      12 | Accept |      3.5892 |      5.6099 |      1.0912 |      1.0913 |      LSBoost |           20 |     0.002516 |            8 |         5869 |            7 |
|    5 |      12 | Accept |      3.0894 |      7.2136 |      1.0912 |      1.0913 |      LSBoost |           22 |     0.017191 |           41 |           14 |           33 |
|    6 |      12 | Best   |      1.0912 |      7.7495 |      1.0912 |      1.0913 |          Bag |           16 |            - |           20 |          153 |           25 |
|    7 |      12 | Accept |      2.6667 |      4.2714 |      1.0912 |      1.0913 |      LSBoost |           88 |      0.56255 |         3382 |           13 |           15 |
|    8 |      11 | Accept |      2.8267 |      9.7841 |      1.0912 |      1.0915 |          Bag |          178 |            - |         2242 |            2 |            4 |
|    9 |      11 | Accept |      1.9559 |      1.5772 |      1.0912 |      1.0915 |          Bag |           10 |            - |          266 |           15 |           11 |
|   10 |      14 | Accept |      1.1102 |      13.034 |      1.0912 |      1.0914 |          Bag |           24 |            - |           38 |         6131 |           31 |
|   11 |      14 | Accept |      3.1375 |      14.951 |      1.0912 |      1.0914 |      LSBoost |           72 |    0.0054161 |          737 |         1040 |           37 |
|   12 |      14 | Accept |      2.9379 |     0.63096 |      1.0912 |      1.0914 |          Bag |           11 |            - |          509 |         8358 |            1 |
|   13 |      13 | Accept |      2.4795 |      18.802 |      1.0912 |      1.0913 |          Bag |          238 |            - |            2 |            2 |            5 |
|   14 |      13 | Accept |      3.5439 |      3.4842 |      1.0912 |      1.0913 |      LSBoost |           29 |    0.0033707 |         1144 |            7 |           23 |
|   15 |      13 | Accept |      1.1676 |       21.08 |      1.0912 |      1.0912 |      LSBoost |           44 |      0.90102 |          206 |          874 |           36 |
|   16 |      14 | Best   |     0.86102 |       28.82 |     0.86102 |     0.86088 |          Bag |           36 |            - |            2 |          528 |           35 |
|   17 |      14 | Accept |      1.2702 |      4.4388 |     0.86102 |     0.86075 |      LSBoost |           13 |       0.9081 |           83 |         7950 |           15 |
|   18 |      14 | Accept |      2.9367 |      23.784 |     0.86102 |     0.86088 |          Bag |          495 |            - |          133 |         7845 |            1 |
|   19 |      12 | Accept |      2.2653 |      29.049 |     0.83756 |     0.83764 |          Bag |          176 |            - |            1 |            4 |           21 |
|   20 |      12 | Best   |     0.83756 |      15.889 |     0.83756 |     0.83764 |          Bag |           14 |            - |            1 |         8530 |           38 |
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|   21 |      12 | Accept |      2.3826 |      5.0385 |     0.83756 |     0.83764 |      LSBoost |           91 |      0.94983 |         3028 |         8488 |           31 |
|   22 |      12 | Accept |      1.1573 |      32.023 |     0.83756 |     0.83764 |          Bag |          134 |            - |           39 |         2702 |           13 |
|   23 |      11 | Accept |      1.8725 |      35.757 |     0.83756 |     0.83764 |          Bag |          135 |            - |           26 |           11 |           32 |
|   24 |      11 | Accept |      2.9924 |       5.391 |     0.83756 |     0.83764 |          Bag |          124 |            - |         4074 |          633 |           38 |
|   25 |      16 | Accept |      2.2916 |      2.4208 |     0.83756 |     0.83764 |          Bag |           14 |            - |            9 |            2 |           33 |
|   26 |      13 | Accept |      1.9276 |      61.905 |     0.83756 |      0.8377 |      LSBoost |          429 |    0.0090695 |          875 |            3 |           34 |
|   27 |      13 | Accept |     0.86082 |      60.741 |     0.83756 |      0.8377 |          Bag |          101 |            - |           12 |          712 |           28 |
|   28 |      13 | Accept |     0.87074 |       8.993 |     0.83756 |      0.8377 |          Bag |           10 |            - |            6 |         4057 |           36 |
|   29 |      13 | Accept |      2.4479 |      2.4226 |     0.83756 |      0.8377 |      LSBoost |           26 |     0.039962 |          249 |           71 |            4 |
|   30 |      11 | Accept |      2.3083 |      64.556 |     0.83756 |     0.83753 |          Bag |          485 |            - |          868 |           16 |           23 |
|   31 |      11 | Accept |       2.726 |      8.5065 |     0.83756 |     0.83753 |          Bag |          126 |            - |         3037 |           80 |           37 |
|   32 |      11 | Accept |      2.0312 |      1.4854 |     0.83756 |     0.83753 |          Bag |           11 |            - |            1 |         1895 |            1 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 32
Total elapsed time: 73.4406 seconds.
Total objective function evaluation time: 506.4574

Best observed feasible point:
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             14               NaN            1             8530                 38         

Observed objective function value = 0.83756
Estimated objective function value = 0.83753
Function evaluation time = 15.8887

Best estimated feasible point (according to models):
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             14               NaN            1             8530                 38         

Estimated objective function value = 0.83753
Estimated function evaluation time = 15.8188

Elapsed time is 76.501203 seconds.
Train the super learner model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      4.6089 |      161.21 |      4.6089 |      4.6089 |       5.5689 | pureQuadrati |  exponential |   2.8568e+11 |        false |
|    2 |      16 | Best   |      2.7928 |      465.98 |      2.7928 |       2.865 |   0.00058187 |         none |  exponential |   1.9139e+12 |        false |
|    3 |      16 | Accept |      12.656 |      510.71 |      2.7928 |      3.0301 |    0.0044752 | pureQuadrati | squaredexpon |   2.6856e+10 |        false |
|    4 |      16 | Best   |     0.17343 |      543.95 |     0.17343 |      1.8848 |     0.031559 |       linear | squaredexpon |   5.8604e+11 |         true |
|    5 |      16 | Accept |      1.9795 |      567.88 |     0.17343 |      1.5575 |   0.00032782 | pureQuadrati |  exponential |    2.693e+10 |         true |
|    6 |      16 | Accept |      2.7927 |       186.6 |     0.17343 |     0.17387 |    0.0025787 |         none |  exponential |   1.7687e+11 |        false |
|    7 |      16 | Accept |      14.275 |      761.91 |     0.17343 |     0.17405 |     0.049348 |     constant | rationalquad |   1.5443e+10 |        false |
|    8 |      16 | Accept |      2.9923 |      150.16 |     0.17343 |       0.174 |       16.634 |         none | squaredexpon |   3.9664e+11 |         true |
|    9 |      16 | Accept |     0.17524 |      958.21 |     0.17343 |     0.17392 |     0.001659 |       linear | rationalquad |   2.0042e+11 |        false |
|   10 |      16 | Accept |     0.18906 |      259.24 |     0.17343 |     0.17386 |      0.13145 |       linear | rationalquad |    8.371e+11 |         true |
|   11 |      16 | Accept |      2.7926 |      556.62 |     0.17343 |     0.17382 |     0.025708 |         none |  exponential |   6.4008e+12 |        false |
|   12 |      16 | Accept |     0.23051 |      546.03 |     0.17343 |     0.20215 |     0.034652 |       linear | squaredexpon |   5.6259e+11 |         true |
|   13 |      16 | Accept |     0.24126 |      564.22 |     0.17343 |     0.21519 |     0.028353 |       linear | squaredexpon |   8.8858e+11 |         true |
|   14 |      16 | Accept |     0.17653 |       254.2 |     0.17343 |     0.21517 |       15.523 |       linear |     matern52 |   6.8782e+11 |        false |
|   15 |      16 | Accept |      8.5917 |      290.72 |     0.17343 |     0.21519 |      0.04691 | pureQuadrati | rationalquad |   3.0373e+10 |         true |
|   16 |      16 | Accept |      2.9943 |      180.25 |     0.17343 |     0.21519 |       11.869 | pureQuadrati |     matern52 |   6.4621e+12 |        false |
|   17 |      16 | Accept |     0.69599 |      596.87 |     0.17343 |     0.21518 |    0.0012217 |       linear |  exponential |   4.9591e+12 |        false |
|   18 |      16 | Accept |      2.9923 |      157.37 |     0.17343 |     0.21518 |        2.498 |         none |     matern52 |   2.7774e+11 |        false |
|   19 |      16 | Accept |      3.3778 |      570.93 |     0.17343 |     0.21518 |     0.015221 |       linear |     matern52 |   8.4504e+11 |         true |
|   20 |      16 | Accept |     0.60242 |      245.57 |     0.17343 |     0.21517 |       22.597 |       linear |     matern32 |   1.9072e+10 |        false |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 1640.967 seconds.
Total objective function evaluation time: 8528.6248

Best observed feasible point:
     Sigma      BasisFunction      KernelFunction      KernelScale    Standardize
    ________    _____________    __________________    ___________    ___________

    0.031559       linear        squaredexponential    5.8604e+11        true    

Observed objective function value = 0.17343
Estimated objective function value = 0.21517
Function evaluation time = 543.9455

Best estimated feasible point (according to models):
     Sigma      BasisFunction      KernelFunction      KernelScale    Standardize
    ________    _____________    __________________    ___________    ___________

    0.031559       linear        squaredexponential    5.8604e+11        true    

Estimated objective function value = 0.21517
Estimated function evaluation time = 545.9999

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 90)
  In utdNodesOptSolo2 (line 214)] 
Elapsed time is 1657.229634 seconds.
Train the super learner error model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |     0.16871 |      236.67 |     0.16871 |     0.16871 |       2.8351 |     constant |  exponential |   2.0081e+12 |         true |
|    2 |      16 | Best   |     0.16867 |      259.68 |     0.16867 |     0.16867 |    0.0020358 |         none |     matern32 |   2.4363e+12 |         true |
|    3 |      16 | Accept |     0.39498 |      467.93 |     0.16867 |     0.23894 |    0.0094147 |       linear |  exponential |   1.2802e+12 |         true |
|    4 |      16 | Accept |      17.384 |      468.91 |     0.16867 |     0.44896 |     0.013289 | pureQuadrati |     matern32 |   4.8124e+11 |         true |
|    5 |      16 | Accept |       11.68 |      479.16 |     0.16867 |     0.37066 |   0.00073082 | pureQuadrati |     matern52 |   1.1329e+12 |        false |
|    6 |      16 | Accept |     0.16867 |      232.12 |     0.16867 |     0.16899 |    0.0012412 |         none |     matern32 |    4.571e+12 |         true |
|    7 |      16 | Accept |      2.0028 |      529.92 |     0.16867 |     0.16895 |   0.00027919 |       linear |     matern52 |   2.6458e+12 |        false |
|    8 |      16 | Accept |     0.53246 |      532.57 |     0.16867 |     0.16891 |      0.36853 |       linear |     matern32 |    5.536e+11 |        false |
|    9 |      16 | Accept |     0.93939 |      547.28 |     0.16867 |     0.16888 |   0.00011068 |       linear |  exponential |   1.5331e+12 |        false |
|   10 |      16 | Accept |      2.4385 |      677.24 |     0.16867 |     0.16887 |    0.0002013 |         none | rationalquad |    4.893e+12 |        false |
|   11 |      16 | Accept |     0.16877 |      231.23 |     0.16867 |     0.16885 |      0.16872 |     constant |  exponential |   1.0909e+12 |         true |
|   12 |      16 | Best   |     0.16864 |      242.09 |     0.16864 |     0.16877 |       2.6736 |         none |     matern32 |   2.3333e+12 |         true |
|   13 |      16 | Accept |      1.7653 |      247.03 |     0.16864 |     0.16868 |     0.087163 |       linear |  exponential |   6.5658e+10 |         true |
|   14 |      16 | Accept |     0.16867 |       184.3 |     0.16864 |     0.16867 |    0.0015876 |         none |     matern52 |   3.4808e+10 |         true |
|   15 |      16 | Accept |     0.16867 |      247.83 |     0.16864 |     0.16867 |     0.034533 |         none |  exponential |   3.0099e+10 |         true |
|   16 |      16 | Accept |     0.32136 |      747.05 |     0.16864 |     0.16866 |   0.00036797 |       linear | rationalquad |   7.4339e+11 |         true |
|   17 |      16 | Accept |     0.16876 |      249.34 |     0.16864 |     0.16866 |      0.06565 |     constant |     matern32 |   2.4404e+12 |         true |
|   18 |      16 | Accept |     0.17061 |      374.71 |     0.16864 |     0.16866 |     0.020423 |         none |     matern32 |   7.1864e+11 |        false |
|   19 |      16 | Accept |     0.16865 |      193.33 |     0.16864 |     0.16865 |      0.31881 |         none |     matern52 |   3.4242e+12 |        false |
|   20 |      16 | Accept |     0.16877 |      249.23 |     0.16864 |     0.16865 |       3.1289 |     constant |  exponential |   5.5602e+10 |        false |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 936.6246 seconds.
Total objective function evaluation time: 7397.606

Best observed feasible point:
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    2.6736        none            matern32       2.3333e+12        true    

Observed objective function value = 0.16864
Estimated objective function value = 0.16875
Function evaluation time = 242.0879

Best estimated feasible point (according to models):
      Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    _________    _____________    ______________    ___________    ___________

    0.0020358        none            matern32       2.4363e+12        true    

Estimated objective function value = 0.16865
Estimated function evaluation time = 248.8515

Elapsed time is 943.880270 seconds.
Elapsed time is 943.882426 seconds.
Use the hyper-parameter optimized NN model for regression
Elapsed time is 0.136299 seconds.
Use the hyper-parameter optimized GPR model for regression
Elapsed time is 0.268369 seconds.
Use the hyper-parameter optimized Ensemble of Trees model for regression
Elapsed time is 0.037843 seconds.
Use the super learner model for regression
Elapsed time is 0.138724 seconds.
Use the error estimate to update the Super Learner Estimate
Elapsed time is 0.213132 seconds.
Use the hyper-parameter optimized NN model for regression
Elapsed time is 0.037996 seconds.
Use the hyper-parameter optimized GPR model for regression
Elapsed time is 0.048422 seconds.
Use the hyper-parameter optimized Ensemble of Trees model for regression
Elapsed time is 0.024273 seconds.
Use the super learner model for regression
Elapsed time is 0.026742 seconds.
Use the error estimate to update the Super Learner Estimate
Elapsed time is 0.045843 seconds.



combinedFigDaily = 

    "/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e06318cf1/UTD_Rsl_All_Daily_001e06318cf1_pm1_palas.png"


combinedFig = 

    "/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e06318cf1/UTD_Rsl_All_2020_11_22_18_39_00/UTD_Rsl_All_2020_11_22_18_39_00_001e06318cf1_pm1_palas.png"

    "Creating Folder @: '/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e06318cf1/UTD_Rsl_All_2020_11_22_18_39_00'"

The identifier was:
MATLAB:license:checkouterrorThere was an error! The message was:
License checkout failed.
License Manager Error -97
License Manager cannot start. 
Check that the ports specified in the license file are not already in use. 
Restarting your machine may clear the ports.

Troubleshoot this issue by visiting: 
https://www.mathworks.com/support/lme/R2020a/97

Diagnostic Information:
Feature: Curve_Fitting_Toolbox 
License path: /home/lhw150030/.matlab/R2020a_licenses:/opt/ohpc/pub/unpackaged/apps/matlab/R2020a/licenses/license.dat:/opt/ohpc/pub/unpackaged/apps/matlab/R2020a/licenses/network.lic 
Licensing error: -97,121.

    "Gainin Data set for Node 001e06318cf1 with target output pm2_5_palas @ 22-Nov-2020 19:49:26"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 292 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 73 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 213 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 97 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 49 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 13 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 10 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 7 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 6 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 219 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 77 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 37 and choosing a representative sample. Choosing 140 bins for this column. With 2 members per bin.
Going through column 38 and choosing a representative sample. Choosing 282 bins for this column. With 2 members per bin.
Going through column 39 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        7917


ans =

        1397

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |       1 | Accept |      44.619 |     0.60443 |      9.8285 |      41.679 |           13 |      0.10692 |
|    2 |       1 | Best   |      9.8285 |     0.58827 |      9.8285 |      41.679 |           15 |     0.002404 |
|    3 |       1 | Accept |      85.125 |     0.68086 |      9.8285 |      41.679 |           65 |     0.014515 |
|    4 |       1 | Accept |      15.109 |      0.6471 |      9.8285 |      41.679 |            7 |      0.00111 |
|    5 |       1 | Accept |      72.388 |     0.66605 |      9.8285 |      41.679 |           57 |      0.34307 |
|    6 |       1 | Accept |      29.534 |     0.72791 |      9.8285 |      41.679 |           94 |      0.44443 |
|    7 |       1 | Accept |       39.93 |     0.58935 |      9.8285 |      41.679 |            7 |      0.66677 |
|    8 |       1 | Accept |      27.681 |     0.64715 |      9.8285 |      41.679 |           58 |    0.0093588 |
|    9 |       1 | Accept |      68.007 |     0.72838 |      9.8285 |      41.679 |           54 |      0.17471 |
|   10 |       1 | Accept |       64.21 |     0.69201 |      9.8285 |      41.679 |           96 |    0.0073813 |
|   11 |       1 | Accept |      59.209 |      0.7133 |      9.8285 |      41.679 |           85 |      0.98897 |
|   12 |       1 | Accept |      38.108 |      0.7543 |      9.8285 |      41.679 |           97 |     0.015781 |
|   13 |       1 | Accept |      108.39 |     0.65866 |      9.8285 |      41.679 |           38 |     0.011014 |
|   14 |       1 | Accept |      49.832 |     0.66479 |      9.8285 |      41.679 |           76 |     0.046065 |
|   15 |       1 | Accept |      69.647 |     0.58437 |      9.8285 |      41.679 |           17 |    0.0054835 |
|   16 |       1 | Accept |      22.633 |     0.62044 |      9.8285 |      41.679 |           14 |     0.031954 |
|   17 |       1 | Accept |      12.359 |     0.23459 |      9.8285 |      35.353 |            5 |    0.0010012 |
|   18 |       1 | Accept |      40.931 |     0.22806 |      9.8285 |      35.353 |           26 |      0.31215 |
|   19 |       1 | Accept |      34.475 |     0.27252 |      9.8285 |      35.353 |           56 |      0.00436 |
|   20 |       1 | Accept |       15.03 |     0.24599 |      9.8285 |      35.353 |           22 |    0.0098218 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       1 | Accept |      49.533 |     0.26836 |      9.8285 |      35.353 |           24 |     0.025858 |
|   22 |       1 | Accept |      61.387 |     0.30293 |      9.8285 |      35.353 |           62 |     0.036785 |
|   23 |       1 | Accept |      71.704 |     0.27447 |      9.8285 |      35.353 |           57 |     0.072027 |
|   24 |       1 | Accept |      39.619 |     0.24678 |      9.8285 |      35.353 |           26 |    0.0092237 |
|   25 |       1 | Accept |       31.31 |     0.29046 |      9.8285 |      35.353 |           25 |     0.029613 |
|   26 |       1 | Accept |      66.446 |     0.29122 |      9.8285 |      35.353 |           69 |     0.036006 |
|   27 |       1 | Accept |      36.878 |     0.21064 |      9.8285 |      35.353 |            9 |     0.098232 |
|   28 |       1 | Accept |      12.243 |     0.28353 |      9.8285 |      35.353 |           29 |      0.34672 |
|   29 |       1 | Accept |      48.075 |     0.30162 |      9.8285 |      35.353 |           77 |      0.26707 |
|   30 |       1 | Accept |      24.326 |     0.28367 |      9.8285 |      35.353 |           49 |      0.22964 |
|   31 |       1 | Accept |      51.024 |     0.27253 |      9.8285 |      35.353 |           53 |    0.0092849 |
|   32 |       1 | Accept |       14.89 |     0.26869 |      9.8285 |      35.353 |           34 |    0.0094058 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 32
Total elapsed time: 3.6393 seconds.
Total objective function evaluation time: 14.8434

Best observed feasible point:
    hiddenLayerSize       lr   
    _______________    ________

          15           0.002404

Observed objective function value = 9.8285
Estimated objective function value = 35.6698
Function evaluation time = 0.58827

Best estimated feasible point (according to models):
    hiddenLayerSize      lr   
    _______________    _______

          13           0.10692

Estimated objective function value = 35.3529
Estimated function evaluation time = 0.47796


T =

  1x2 table

    hiddenLayerSize      lr   
    _______________    _______

          13           0.10692

Elapsed time is 24.501611 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      7.2178 |      191.37 |      7.2178 |      7.2178 |       10.527 | pureQuadrati |  exponential |   1.6472e+12 |        false |
|    2 |      16 | Best   |      2.4566 |      211.88 |      2.4566 |      2.6459 |      0.36383 |       linear | squaredexpon |   3.3911e+12 |         true |
|    3 |      16 | Accept |      12.254 |      227.16 |      2.4566 |      2.7524 |    0.0048069 | pureQuadrati |     matern32 |   9.3158e+09 |         true |
|    4 |      16 | Best   |      2.2333 |      238.64 |      2.2333 |      2.2338 |      0.23654 |       linear | rationalquad |   2.6905e+11 |         true |
|    5 |      16 | Accept |      3.6373 |      274.03 |      2.2333 |      2.2337 |     0.013258 |     constant | rationalquad |   4.2799e+12 |         true |
|    6 |      16 | Best   |      2.2134 |      292.71 |      2.2134 |      2.2138 |       1.0539 |       linear | squaredexpon |   2.0882e+12 |        false |
|    7 |      16 | Accept |      3.6377 |      243.92 |      2.2134 |      2.2137 |      0.17446 |     constant | rationalquad |     3.67e+12 |         true |
|    8 |      16 | Accept |      3.2876 |      228.81 |      2.2134 |      2.2137 |       4.1054 |       linear | squaredexpon |   4.6744e+11 |         true |
|    9 |      16 | Accept |      2.2842 |      220.26 |      2.2134 |      2.2136 |    0.0085582 |       linear | squaredexpon |   1.7219e+12 |         true |
|   10 |      16 | Accept |      12.865 |      240.77 |      2.2134 |      2.2138 |      0.19631 | pureQuadrati | rationalquad |   1.6041e+12 |         true |
|   11 |      16 | Accept |      35.449 |       491.4 |      2.2134 |      2.2141 |   0.00014847 | pureQuadrati |     matern32 |   1.1264e+11 |        false |
|   12 |      16 | Accept |      3.6371 |      528.92 |      2.2134 |       2.214 |    0.0096511 |         none |     matern52 |   7.2486e+09 |         true |
|   13 |      16 | Best   |       1.341 |      533.83 |       1.341 |      1.3416 |    0.0011627 |         none |  exponential |   1.1626e+11 |         true |
|   14 |      16 | Accept |      2.2283 |      278.78 |       1.341 |      1.3416 |    0.0001009 |       linear | rationalquad |   1.7124e+10 |         true |
|   15 |      16 | Best   |      1.3387 |      571.09 |      1.3387 |      1.3391 |      0.33193 |         none |  exponential |    2.814e+10 |         true |
|   16 |      16 | Accept |       2.265 |      235.96 |      1.3387 |      1.3391 |     0.057927 |       linear |     matern52 |    4.633e+10 |         true |
|   17 |      16 | Accept |      3.6374 |      228.58 |      1.3387 |       1.339 |      0.01834 |     constant |     matern52 |   1.8948e+11 |         true |
|   18 |      16 | Accept |      13.901 |      498.56 |      1.3387 |       1.339 |   0.00010037 |       linear | squaredexpon |   1.1527e+10 |        false |
|   19 |      16 | Accept |      11.372 |       370.3 |      1.3387 |       1.339 |      0.24084 | pureQuadrati | squaredexpon |   2.1626e+12 |        false |
|   20 |      16 | Accept |      20.794 |      410.74 |      1.3387 |      1.3391 |      0.19513 |         none | squaredexpon |   2.6977e+12 |        false |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      16 | Accept |      3.6371 |      439.64 |      1.3387 |      1.3391 |   0.00027416 |         none | squaredexpon |   6.5584e+12 |         true |
|   22 |      16 | Accept |      3.6371 |      402.58 |      1.3387 |      1.3391 |    0.0024491 |         none |     matern32 |   3.2997e+10 |         true |
|   23 |      16 | Accept |      3.6371 |      528.08 |      1.3387 |       1.339 |    0.0032759 |         none | rationalquad |   7.9144e+11 |         true |
|   24 |      16 | Accept |      3.6371 |      150.93 |      1.3387 |       1.339 |       1.6004 |         none |     matern52 |   6.8694e+12 |         true |
|   25 |      16 | Accept |      2.2585 |      240.47 |      1.3387 |       1.339 |     0.075517 |       linear |  exponential |   6.2348e+10 |         true |
|   26 |      16 | Accept |      2.4284 |      610.75 |      1.3387 |       1.339 |      0.21386 |       linear | rationalquad |   7.9598e+11 |        false |
|   27 |      16 | Accept |      1.3392 |      476.69 |      1.3387 |       1.339 |     0.094728 |     constant |  exponential |   5.8054e+10 |         true |
|   28 |      16 | Accept |       2.177 |      239.13 |      1.3387 |       1.339 |    0.0020928 |       linear |     matern52 |   6.8362e+12 |         true |
|   29 |      16 | Accept |      3.6377 |      237.87 |      1.3387 |       1.339 |    0.0079323 |     constant |     matern32 |   7.2271e+10 |         true |
|   30 |      16 | Accept |      3.0226 |      421.12 |      1.3387 |       1.339 |     0.066085 |         none |  exponential |   4.3426e+10 |        false |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 1196.0012 seconds.
Total objective function evaluation time: 10264.9307

Best observed feasible point:
     Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    _______    _____________    ______________    ___________    ___________

    0.33193        none          exponential       2.814e+10        true    

Observed objective function value = 1.3387
Estimated objective function value = 1.339
Function evaluation time = 571.0871

Best estimated feasible point (according to models):
     Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    _______    _____________    ______________    ___________    ___________

    0.33193        none          exponential       2.814e+10        true    

Estimated objective function value = 1.339
Estimated function evaluation time = 563.8471

Elapsed time is 1215.226519 seconds.
Take a copy of the best attributes
Now use these optimum settings to do an exact GPR fit
Elapsed time is 10.421493 seconds.
Train a hyper-parameter optimized Ensemble of Trees model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|    1 |      16 | Best   |      1.7659 |      3.7704 |      1.7659 |      1.7659 |          Bag |           18 |            - |           97 |           83 |           15 |
|    2 |      15 | Accept |      1.9681 |      4.5946 |      1.5298 |      1.6051 |          Bag |           36 |            - |          196 |           59 |            9 |
|    3 |      15 | Best   |      1.5298 |      4.7759 |      1.5298 |      1.6051 |      LSBoost |           33 |      0.64274 |          216 |           52 |            8 |
|    4 |      14 | Accept |      2.3317 |      7.2249 |      1.4277 |      1.4277 |          Bag |           59 |            - |           39 |            3 |           20 |
|    5 |      14 | Best   |      1.4277 |      7.0862 |      1.4277 |      1.4277 |      LSBoost |           61 |     0.068702 |           11 |           17 |           11 |
|    6 |      14 | Accept |      3.8602 |      13.852 |      1.4277 |      1.4279 |      LSBoost |           78 |    0.0029249 |            2 |         5532 |            4 |
|    7 |      14 | Accept |      4.0843 |      13.875 |      1.4277 |      1.4279 |      LSBoost |          112 |    0.0011134 |           44 |            2 |           26 |
|    8 |      14 | Accept |      1.4642 |      6.2094 |      1.4277 |      1.4278 |      LSBoost |           30 |      0.71171 |           94 |           36 |            8 |
|    9 |      12 | Accept |       2.572 |      20.961 |      1.1637 |      1.1643 |          Bag |          186 |            - |         1540 |           39 |           37 |
|   10 |      12 | Best   |      1.1637 |      8.1521 |      1.1637 |      1.1643 |          Bag |           10 |            - |            3 |         7665 |           30 |
|   11 |      12 | Accept |      2.4801 |      1.4296 |      1.1637 |      1.1643 |      LSBoost |           15 |      0.13887 |           54 |            1 |           17 |
|   12 |      11 | Accept |      1.8172 |      23.675 |      1.1637 |      1.1638 |          Bag |          237 |            - |           73 |         2993 |            5 |
|   13 |      11 | Accept |      2.1999 |     0.76121 |      1.1637 |      1.1638 |      LSBoost |           10 |      0.96874 |            5 |            1 |           17 |
|   14 |      16 | Accept |      3.4687 |      1.1081 |      1.1637 |      1.1639 |      LSBoost |           12 |     0.038654 |           34 |         7258 |            3 |
|   15 |      14 | Accept |      2.0638 |      30.057 |      1.1637 |      1.1638 |          Bag |          120 |            - |          374 |         1041 |           36 |
|   16 |      14 | Accept |      1.8622 |       2.625 |      1.1637 |      1.1638 |      LSBoost |           19 |      0.62365 |          257 |            3 |           21 |
|   17 |      14 | Accept |      2.7849 |      1.0587 |      1.1637 |      1.1638 |          Bag |           12 |            - |            4 |            1 |           11 |
|   18 |      14 | Accept |      2.4308 |      8.5706 |      1.1637 |      1.1639 |          Bag |           70 |            - |          782 |            5 |           17 |
|   19 |      13 | Accept |      1.4162 |      12.707 |      1.1637 |      1.1639 |          Bag |           60 |            - |            2 |          163 |           10 |
|   20 |      13 | Accept |      1.6658 |      1.2154 |      1.1637 |      1.1639 |          Bag |           10 |            - |           20 |         7773 |            3 |
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|   21 |      12 | Accept |      2.9417 |      29.788 |      1.1637 |       1.164 |      LSBoost |          496 |    0.0025835 |            9 |            1 |           14 |
|   22 |      12 | Accept |      2.5847 |      16.941 |      1.1637 |       1.164 |      LSBoost |          142 |      0.01028 |         1084 |           34 |           29 |
|   23 |      12 | Accept |      1.1818 |      7.4637 |      1.1637 |      1.1709 |          Bag |           10 |            - |            1 |         1978 |           29 |
|   24 |      12 | Accept |      2.2262 |      52.742 |      1.1637 |      1.1638 |      LSBoost |          139 |    0.0091234 |           31 |           86 |           28 |
|   25 |      12 | Accept |      1.8599 |      26.593 |      1.1637 |      1.1639 |      LSBoost |          486 |      0.69556 |          981 |            8 |            6 |
|   26 |      12 | Accept |      2.4674 |      4.7045 |      1.1637 |      1.1639 |      LSBoost |          122 |      0.76805 |           15 |            1 |            3 |
|   27 |      13 | Accept |      1.2207 |      64.648 |      1.1637 |       1.163 |          Bag |          122 |            - |           16 |         6738 |           30 |
|   28 |      14 | Accept |      1.5185 |       39.52 |      1.1637 |      1.1613 |      LSBoost |          498 |      0.83007 |          780 |         6563 |           13 |
|   29 |      14 | Accept |      1.6363 |      5.7225 |      1.1637 |      1.1635 |      LSBoost |           30 |      0.98016 |          671 |           97 |           34 |
|   30 |      14 | Accept |      2.5123 |      1.2697 |      1.1637 |      1.1644 |      LSBoost |           23 |      0.91568 |         2401 |         7863 |           25 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 81.0511 seconds.
Total objective function evaluation time: 423.1012

Best observed feasible point:
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             10               NaN            3             7665                 30         

Observed objective function value = 1.1637
Estimated objective function value = 1.1644
Function evaluation time = 8.1521

Best estimated feasible point (according to models):
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             10               NaN            3             7665                 30         

Estimated objective function value = 1.1644
Estimated function evaluation time = 7.923

Elapsed time is 82.981634 seconds.
Train the super learner model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      3.6372 |       144.4 |      3.6372 |      3.6372 |       9.1753 |         none | squaredexpon |   5.2059e+12 |         true |
|    2 |      16 | Best   |  0.00014326 |      230.63 |  0.00014326 |     0.14476 |      0.01153 |       linear |  exponential |   9.5525e+09 |         true |
|    3 |      16 | Accept |    0.003962 |      239.96 |  0.00014326 |    0.074124 |     0.045234 | pureQuadrati |     matern52 |    3.212e+12 |         true |
|    4 |      16 | Best   |  3.3427e-06 |      279.89 |  3.3427e-06 |    0.049732 |    0.0039576 |       linear | rationalquad |   3.6525e+10 |        false |
|    5 |      16 | Best   |  3.1214e-06 |      218.67 |  3.1214e-06 |  0.00012175 |       1.9971 |       linear |  exponential |   3.9417e+10 |         true |
|    6 |      16 | Accept |  3.1295e-06 |      230.98 |  3.1214e-06 |  7.6816e-05 |   0.00058529 |       linear |  exponential |   5.6262e+10 |         true |
|    7 |      16 | Accept |  3.4189e-06 |      326.14 |  3.1214e-06 |  7.2964e-05 |       1.8613 |       linear | rationalquad |   8.4349e+09 |        false |
|    8 |      16 | Accept |  4.1788e-05 |      225.82 |  3.1214e-06 |  6.8813e-05 |     0.022013 |       linear |     matern52 |   3.6992e+10 |        false |
|    9 |      16 | Accept |  3.2823e-06 |      236.44 |  3.1214e-06 |   6.602e-05 |     0.054198 |       linear |     matern32 |    1.519e+11 |         true |
|   10 |      16 | Accept |      3.6372 |      745.34 |  3.1214e-06 |   8.003e-05 |    0.0011346 |         none | rationalquad |   2.7887e+12 |         true |
|   11 |      16 | Accept |  1.7125e-05 |      237.11 |  3.1214e-06 |  7.6321e-05 |     0.021092 |       linear |     matern52 |   3.5761e+11 |         true |
|   12 |      16 | Accept |  3.1529e-06 |      241.56 |  3.1214e-06 |  7.3488e-05 |     0.001442 |       linear |     matern32 |   6.3351e+10 |        false |
|   13 |      16 | Accept |     0.09644 |       247.6 |  3.1214e-06 |  7.1565e-05 |       4.1176 | pureQuadrati |     matern32 |   6.9535e+11 |         true |
|   14 |      16 | Accept |  3.8235e-06 |      205.45 |  3.1214e-06 |  6.9684e-05 |   0.00011588 |       linear |  exponential |   1.2199e+11 |        false |
|   15 |      16 | Accept |  0.00035584 |      211.51 |  3.1214e-06 |  6.8117e-05 |      0.69904 | pureQuadrati |  exponential |    5.258e+11 |         true |
|   16 |      16 | Accept |      32.064 |      773.58 |  3.1214e-06 |  0.00013947 |      0.43269 | pureQuadrati | rationalquad |    7.739e+09 |        false |
|   17 |      16 | Accept |      21.276 |      559.37 |  3.1214e-06 |  0.00018086 |     0.038745 | pureQuadrati |     matern52 |   3.1336e+11 |        false |
|   18 |      16 | Accept |      15.146 |      549.98 |  3.1214e-06 |  0.00020538 |    0.0020297 | pureQuadrati |     matern32 |   1.9452e+11 |        false |
|   19 |      16 | Accept |      9.7055 |      233.91 |  3.1214e-06 |  0.00021637 |       5.5566 | pureQuadrati |  exponential |   4.4493e+10 |        false |
|   20 |      16 | Best   |  3.0837e-06 |      289.65 |  3.0837e-06 |  0.00020666 |     0.025269 |       linear | rationalquad |   5.4315e+10 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 1682.353 seconds.
Total objective function evaluation time: 6427.9889

Best observed feasible point:
     Sigma      BasisFunction     KernelFunction      KernelScale    Standardize
    ________    _____________    _________________    ___________    ___________

    0.025269       linear        rationalquadratic    5.4315e+10        true    

Observed objective function value = 3.0837e-06
Estimated objective function value = 0.00047382
Function evaluation time = 289.6458

Best estimated feasible point (according to models):
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    1.9971       linear         exponential      3.9417e+10        true    

Estimated objective function value = 0.00020666
Estimated function evaluation time = 218.7678

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 90)
  In utdNodesOptSolo2 (line 214)] 
Elapsed time is 1689.526843 seconds.
Train the super learner error model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |  3.3176e-06 |      324.36 |  3.3176e-06 |  3.3176e-06 |   0.00066902 |         none |  exponential |   2.2537e+12 |         true |
|    2 |      16 | Accept |  0.00020945 |      420.83 |  3.3176e-06 |  1.5333e-05 |    0.0001577 | pureQuadrati |     matern52 |   1.0598e+10 |        false |
|    3 |      16 | Accept |   3.318e-06 |      465.54 |  3.3176e-06 |  8.8599e-06 |    0.0030745 |     constant |     matern52 |   1.0628e+11 |         true |
|    4 |      16 | Accept |  3.3178e-06 |      469.12 |  3.3176e-06 |  3.3459e-06 |     0.015788 |         none |     matern32 |   1.1475e+12 |         true |
|    5 |      16 | Accept |  1.9973e-05 |      498.78 |  3.3176e-06 |  3.3278e-06 |     0.001165 |       linear |     matern32 |   1.0813e+12 |        false |
|    6 |      16 | Accept |   3.318e-06 |      322.85 |  3.3176e-06 |   3.325e-06 |   0.00071006 |         none | rationalquad |   2.0158e+11 |         true |
|    7 |      16 | Best   |  3.3173e-06 |      347.76 |  3.3173e-06 |  3.3207e-06 |   0.00031488 |         none |  exponential |   3.1921e+11 |         true |
|    8 |      16 | Accept |  3.3227e-06 |       464.5 |  3.3173e-06 |  3.3207e-06 |    0.0064688 |     constant |     matern52 |   1.9026e+12 |         true |
|    9 |      16 | Accept |  3.3178e-06 |      473.38 |  3.3173e-06 |  3.3207e-06 |    0.0091831 |         none |     matern32 |   7.2048e+09 |         true |
|   10 |      16 | Accept |  3.3191e-06 |      474.07 |  3.3173e-06 |  3.3221e-06 |   0.00010117 |     constant |     matern52 |   6.9423e+09 |         true |
|   11 |      16 | Accept |  3.3178e-06 |      464.81 |  3.3173e-06 |   3.322e-06 |    0.0032688 |         none |     matern52 |   6.4404e+11 |         true |
|   12 |      16 | Accept |   3.318e-06 |      458.58 |  3.3173e-06 |  3.3219e-06 |    0.0001418 |     constant |     matern32 |   4.6054e+11 |         true |
|   13 |      16 | Accept |  3.3178e-06 |      747.52 |  3.3173e-06 |  3.3219e-06 |    0.0077809 |         none | rationalquad |   5.7135e+12 |         true |
|   14 |      16 | Accept |  3.3178e-06 |      569.99 |  3.3173e-06 |  3.3219e-06 |    0.0096473 |         none |     matern32 |    5.985e+11 |        false |
|   15 |      16 | Accept |  3.3174e-06 |       670.2 |  3.3173e-06 |  3.3219e-06 |    0.0015763 |     constant | rationalquad |   1.5217e+10 |         true |
|   16 |      16 | Accept |  2.9445e-05 |       462.4 |  3.3173e-06 |  3.3221e-06 |    0.0055435 |       linear |     matern32 |   4.8602e+12 |         true |
|   17 |      16 | Accept |  3.3175e-06 |      453.07 |  3.3173e-06 |  3.3221e-06 |   0.00023996 |     constant |  exponential |   3.8161e+11 |         true |
|   18 |      16 | Accept |  3.3178e-06 |      522.55 |  3.3173e-06 |  3.3221e-06 |    0.0026075 |         none |     matern52 |    3.319e+11 |        false |
|   19 |      16 | Accept |  3.3195e-06 |      511.09 |  3.3173e-06 |   3.322e-06 |    0.0010874 |     constant |     matern32 |   1.3622e+11 |        false |
|   20 |      16 | Accept |  3.8391e-06 |      274.15 |  3.3173e-06 |   3.322e-06 |   0.00026315 |     constant |  exponential |   5.8643e+11 |        false |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 2128.1585 seconds.
Total objective function evaluation time: 9395.5335

Best observed feasible point:
      Sigma       BasisFunction    KernelFunction    KernelScale    Standardize
    __________    _____________    ______________    ___________    ___________

    0.00031488        none          exponential      3.1921e+11        true    

Observed objective function value = 3.3173e-06
Estimated objective function value = 3.3206e-06
Function evaluation time = 347.759

Best estimated feasible point (according to models):
      Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    _________    _____________    ______________    ___________    ___________

    0.0030745      constant          matern52       1.0628e+11        true    

Estimated objective function value = 3.322e-06
Estimated function evaluation time = 465.5401

Elapsed time is 2140.373025 seconds.
Elapsed time is 2140.375848 seconds.
Use the hyper-parameter optimized NN model for regression
Elapsed time is 0.051881 seconds.
Use the hyper-parameter optimized GPR model for regression
Elapsed time is 0.201146 seconds.
Use the hyper-parameter optimized Ensemble of Trees model for regression
Elapsed time is 0.039453 seconds.
Use the super learner model for regression
Elapsed time is 0.162306 seconds.
Use the error estimate to update the Super Learner Estimate
Elapsed time is 0.174399 seconds.
Use the hyper-parameter optimized NN model for regression
Elapsed time is 0.016125 seconds.
Use the hyper-parameter optimized GPR model for regression
Elapsed time is 0.037270 seconds.
Use the hyper-parameter optimized Ensemble of Trees model for regression
Elapsed time is 0.014606 seconds.
Use the super learner model for regression
Elapsed time is 0.031923 seconds.
Use the error estimate to update the Super Learner Estimate
Elapsed time is 0.035815 seconds.



combinedFigDaily = 

    "/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e06318cf1/UTD_Rsl_All_Daily_001e06318cf1_pm2_5_palas.png"


combinedFig = 

    "/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e06318cf1/UTD_Rsl_All_2020_11_22_18_39_00/UTD_Rsl_All_2020_11_22_18_39_00_001e06318cf1_pm2_5_palas.png"

The identifier was:
MATLAB:license:checkouterrorThere was an error! The message was:
License checkout failed.
License Manager Error -97
License Manager cannot start. 
Check that the ports specified in the license file are not already in use. 
Restarting your machine may clear the ports.

Troubleshoot this issue by visiting: 
https://www.mathworks.com/support/lme/R2020a/97

Diagnostic Information:
Feature: Curve_Fitting_Toolbox 
License path: /home/lhw150030/.matlab/R2020a_licenses:/opt/ohpc/pub/unpackaged/apps/matlab/R2020a/licenses/license.dat:/opt/ohpc/pub/unpackaged/apps/matlab/R2020a/licenses/network.lic 
Licensing error: -97,121.

    "Gainin Data set for Node 001e06318cf1 with target output pm4_palas @ 22-Nov-2020 21:16:04"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 292 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 73 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 213 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 97 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 49 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 13 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 10 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 7 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 6 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 219 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 77 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 37 and choosing a representative sample. Choosing 140 bins for this column. With 2 members per bin.
Going through column 38 and choosing a representative sample. Choosing 282 bins for this column. With 2 members per bin.
Going through column 39 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        7772


ans =

        1372

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |      16 | Best   |      45.587 |     0.42133 |      45.587 |      45.587 |            7 |     0.026247 |
|    2 |       2 | Accept |       124.7 |     0.52104 |      45.587 |      128.21 |           25 |      0.84988 |
|    3 |       2 | Accept |      173.68 |     0.51426 |      45.587 |      128.21 |           39 |    0.0018688 |
|    4 |       2 | Accept |      83.644 |      0.5852 |      45.587 |      128.21 |           97 |       0.3522 |
|    5 |       2 | Accept |      143.68 |     0.56167 |      45.587 |      128.21 |           80 |    0.0039685 |
|    6 |       2 | Accept |      88.975 |     0.48529 |      45.587 |      128.21 |           33 |    0.0020422 |
|    7 |       2 | Accept |      148.55 |     0.54521 |      45.587 |      128.21 |           83 |      0.04232 |
|    8 |       2 | Accept |      91.995 |     0.50926 |      45.587 |      128.21 |           60 |    0.0051692 |
|    9 |       2 | Accept |      114.02 |     0.55069 |      45.587 |      128.21 |           94 |    0.0060239 |
|   10 |       2 | Accept |      57.332 |     0.54735 |      45.587 |      128.21 |           94 |     0.080775 |
|   11 |       2 | Accept |      63.709 |     0.55203 |      45.587 |      128.21 |           89 |    0.0050984 |
|   12 |       2 | Accept |       128.8 |     0.52276 |      45.587 |      128.21 |           48 |      0.11046 |
|   13 |       2 | Accept |      206.43 |     0.45688 |      45.587 |      128.21 |           37 |      0.04881 |
|   14 |       2 | Accept |      119.36 |     0.45631 |      45.587 |      128.21 |           53 |       0.4339 |
|   15 |       2 | Accept |      305.94 |     0.56207 |      45.587 |      128.21 |           90 |      0.33251 |
|   16 |       2 | Accept |      154.94 |     0.54144 |      45.587 |      128.21 |           77 |      0.35859 |
|   17 |      16 | Accept |      45.668 |     0.17943 |      45.587 |      123.35 |           41 |     0.010124 |
|   18 |       2 | Accept |      55.861 |     0.15823 |      28.653 |      94.103 |            5 |    0.0010008 |
|   19 |       2 | Accept |      251.69 |     0.22196 |      28.653 |      94.103 |           60 |    0.0016912 |
|   20 |       2 | Accept |      106.21 |     0.18525 |      28.653 |      94.103 |           29 |     0.053596 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       2 | Accept |      374.31 |     0.29462 |      28.653 |      94.103 |           77 |    0.0079285 |
|   22 |       2 | Accept |      120.56 |     0.19996 |      28.653 |      94.103 |           28 |      0.09335 |
|   23 |       2 | Accept |      75.353 |     0.18743 |      28.653 |      94.103 |           40 |      0.32348 |
|   24 |       2 | Accept |      225.24 |     0.24319 |      28.653 |      94.103 |           79 |     0.082114 |
|   25 |       2 | Accept |      92.186 |     0.27807 |      28.653 |      94.103 |           83 |     0.002397 |
|   26 |       2 | Accept |      80.567 |     0.23425 |      28.653 |      94.103 |           23 |      0.51203 |
|   27 |       2 | Accept |       32.94 |     0.21628 |      28.653 |      94.103 |            8 |      0.04801 |
|   28 |       2 | Best   |      28.653 |     0.22842 |      28.653 |      94.103 |           45 |     0.013944 |
|   29 |       2 | Accept |      115.34 |     0.22716 |      28.653 |      94.103 |           42 |      0.30942 |
|   30 |       2 | Accept |      95.027 |     0.28215 |      28.653 |      94.103 |           89 |     0.019716 |
|   31 |       2 | Accept |      35.391 |     0.20956 |      28.653 |      94.103 |           41 |    0.0012362 |
|   32 |       2 | Accept |      45.135 |     0.27714 |      28.653 |      94.103 |           59 |     0.022636 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 32
Total elapsed time: 5.4142 seconds.
Total objective function evaluation time: 11.9559

Best observed feasible point:
    hiddenLayerSize       lr   
    _______________    ________

          45           0.013944

Observed objective function value = 28.6532
Estimated objective function value = 106.1726
Function evaluation time = 0.22842

Best estimated feasible point (according to models):
    hiddenLayerSize       lr   
    _______________    ________

           7           0.026247

Estimated objective function value = 94.1031
Estimated function evaluation time = 0.28461


T =

  1x2 table

    hiddenLayerSize       lr   
    _______________    ________

           7           0.026247

Elapsed time is 14.650584 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      4.9254 |      166.32 |      4.9254 |      4.9254 |       3.0037 |         none |     matern52 |   2.6256e+12 |         true |
|    2 |      16 | Accept |      14.156 |      204.76 |      4.9254 |      5.2924 |      0.77837 | pureQuadrati |  exponential |   1.4269e+11 |         true |
|    3 |      16 | Accept |      4.9268 |      215.48 |      4.9254 |       5.113 |       101.55 |     constant |  exponential |   5.0584e+12 |        false |
|    4 |      16 | Accept |      4.9257 |      150.66 |      4.9254 |      4.9257 |       108.54 |         none |     matern52 |   8.4376e+11 |         true |
|    5 |      16 | Accept |      4.9264 |         263 |      4.9254 |      4.9257 |    0.0016748 |     constant | rationalquad |   6.2075e+12 |         true |
|    6 |      16 | Accept |      4.9254 |      479.34 |      4.9254 |      4.9255 |     0.088451 |         none |     matern52 |   1.8292e+11 |         true |
|    7 |      16 | Best   |      4.9247 |      239.03 |      4.9247 |      4.9255 |       17.503 |     constant |     matern52 |   4.4997e+12 |         true |
|    8 |      16 | Accept |      4.9254 |      226.84 |      4.9247 |      4.9255 |       13.515 |         none | rationalquad |   1.3096e+11 |         true |
|    9 |      16 | Best   |      4.1193 |       513.8 |      4.1193 |      4.5316 |       4.0805 |     constant |  exponential |    3.658e+11 |        false |
|   10 |      16 | Accept |      4.9254 |      397.85 |      4.1193 |      4.5317 |    0.0032364 |         none |     matern32 |   6.2824e+11 |         true |
|   11 |      16 | Accept |      4.9249 |      235.95 |      4.1193 |       4.122 |     0.070076 |     constant |     matern32 |   1.0047e+12 |         true |
|   12 |      16 | Error  |         NaN |      440.42 |      4.1193 |       4.122 |    0.0002065 |     constant |     matern32 |   8.1216e+09 |        false |
|   13 |      16 | Error  |         NaN |      514.09 |      4.1193 |       4.122 |    0.0007291 |     constant |     matern52 |    2.024e+12 |        false |
|   14 |      16 | Accept |       4.254 |      236.82 |      4.1193 |      4.1218 |    0.0070815 |         none |  exponential |   7.3936e+09 |        false |
|   15 |      16 | Accept |      15.475 |      781.52 |      4.1193 |      4.2711 |      0.21577 |         none | rationalquad |    9.729e+10 |        false |
|   16 |      16 | Best   |      2.2064 |      558.26 |      2.2064 |       2.234 |   0.00095715 |     constant |  exponential |   7.3903e+09 |         true |
|   17 |      16 | Best   |      2.2062 |      500.46 |      2.2062 |      2.2315 |     0.080767 |         none |  exponential |   2.4901e+10 |         true |
|   18 |      16 | Error  |         NaN |      502.29 |      2.2062 |      2.2315 |    0.0025441 |         none |     matern32 |   3.5957e+10 |        false |
|   19 |      16 | Accept |      2.8503 |       18299 |      2.2062 |      2.2307 |       33.976 |         none | ardexponenti |            - |         true |
|   20 |      16 | Accept |      2.9011 |       21042 |      2.2062 |      2.2302 |       60.063 |         none |  ardmatern52 |            - |         true |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      16 | Accept |      21.721 |       25907 |      2.2062 |       2.222 |       14.582 | pureQuadrati | ardsquaredex |            - |        false |
|   22 |      16 | Accept |      8.2313 |       31258 |      2.2062 |      2.2234 |      0.44398 | pureQuadrati | ardexponenti |            - |         true |
|   23 |      16 | Accept |      2.2726 |       34579 |      2.2062 |      2.2227 |      0.81686 |         none |  ardmatern32 |            - |        false |
|   24 |      16 | Accept |        2.35 |       38432 |      2.2062 |      2.2222 |   0.00046167 |     constant |  ardmatern32 |            - |         true |
|   25 |      16 | Best   |      2.1912 |       40357 |      2.1912 |      2.2069 |      0.28362 |       linear |  ardmatern32 |            - |         true |
|   26 |      16 | Accept |      2.8929 |       22262 |      2.1912 |      2.2067 |       34.195 |     constant | ardexponenti |            - |         true |
|   27 |      16 | Accept |      2.8505 |       39609 |      2.1912 |      2.2066 |     0.073788 |         none | ardsquaredex |            - |         true |
|   28 |      16 | Accept |      2.8969 |       21059 |      2.1912 |      2.2065 |       46.587 |         none |  ardmatern32 |            - |         true |
|   29 |      16 | Accept |      2.7078 |       41500 |      2.1912 |      2.2064 |   0.00055815 |     constant | ardsquaredex |            - |         true |
|   30 |      16 | Accept |      2.3374 |       45202 |      2.1912 |      2.2062 |    0.0049093 |       linear |  ardmatern32 |            - |        false |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 45205.9729 seconds.
Total objective function evaluation time: 386133.661

Best observed feasible point:
     Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    _______    _____________    ______________    ___________    ___________

    0.28362       linear         ardmatern32          NaN           true    

Observed objective function value = 2.1912
Estimated objective function value = 2.2062
Function evaluation time = 40356.7882

Best estimated feasible point (according to models):
     Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    _______    _____________    ______________    ___________    ___________

    0.28362       linear         ardmatern32          NaN           true    

Estimated objective function value = 2.2062
Estimated function evaluation time = 40345.8603

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 29)
  In utdNodesOptSolo2 (line 214)] 
Elapsed time is 46573.244314 seconds.
Take a copy of the best attributes
Now use these optimum settings to do an exact GPR fit
[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In fitrsuperOptimized (line 51)
  In utdNodesOptSolo2 (line 214)] 
Elapsed time is 1196.379330 seconds.
Train a hyper-parameter optimized Ensemble of Trees model for regression
Starting parallel pool (parpool) using the 'local' profile ...
The identifier was:
parallel:cluster:PoolRunValidationThere was an error! The message was:
Parallel pool failed to start with the following error. For more detailed information, validate the profile 'local' in the Cluster Profile Manager.

    "Gainin Data set for Node 001e06318cf1 with target output pm10_palas @ 23-Nov-2020 10:33:05"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 292 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 73 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 213 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 97 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 49 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 13 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 10 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 7 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 6 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 219 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 77 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 37 and choosing a representative sample. Choosing 140 bins for this column. With 2 members per bin.
Going through column 38 and choosing a representative sample. Choosing 282 bins for this column. With 2 members per bin.
Going through column 39 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        7040


ans =

        1242

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Starting parallel pool (parpool) using the 'local' profile ...
The identifier was:
parallel:cluster:PoolRunValidationThere was an error! The message was:
Parallel pool failed to start with the following error. For more detailed information, validate the profile 'local' in the Cluster Profile Manager.

    "Gainin Data set for Node 001e06318cf1 with target output pmTotal_palas @ 23-Nov-2020 10:33:14"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 292 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 73 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 213 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 97 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 49 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 13 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 10 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 7 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 6 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 219 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 77 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 37 and choosing a representative sample. Choosing 140 bins for this column. With 2 members per bin.
Going through column 38 and choosing a representative sample. Choosing 282 bins for this column. With 2 members per bin.
Going through column 39 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        6609


ans =

        1166

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Starting parallel pool (parpool) using the 'local' profile ...
The identifier was:
parallel:cluster:PoolRunValidationThere was an error! The message was:
Parallel pool failed to start with the following error. For more detailed information, validate the profile 'local' in the Cluster Profile Manager.

    "Gainin Data set for Node 001e06318cf1 with target output dCn_palas @ 23-Nov-2020 10:33:23"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 292 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 73 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 213 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 97 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 49 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 13 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 10 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 7 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 6 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 219 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 77 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 37 and choosing a representative sample. Choosing 140 bins for this column. With 2 members per bin.
Going through column 38 and choosing a representative sample. Choosing 282 bins for this column. With 2 members per bin.
Going through column 39 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        8580


ans =

        1514

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Starting parallel pool (parpool) using the 'local' profile ...
The identifier was:
parallel:cluster:PoolRunValidationThere was an error! The message was:
Parallel pool failed to start with the following error. For more detailed information, validate the profile 'local' in the Cluster Profile Manager.

    "Gainin Data set for Node 001e06318cf1 with target output temperatureAirmar @ 23-Nov-2020 10:33:32"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 292 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 73 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 213 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 97 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 49 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 13 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 10 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 7 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 6 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 219 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 77 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 37 and choosing a representative sample. Choosing 140 bins for this column. With 2 members per bin.
Going through column 38 and choosing a representative sample. Choosing 282 bins for this column. With 2 members per bin.
Going through column 39 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        9274


ans =

        1637

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Starting parallel pool (parpool) using the 'local' profile ...
The identifier was:
parallel:cluster:PoolRunValidationThere was an error! The message was:
Parallel pool failed to start with the following error. For more detailed information, validate the profile 'local' in the Cluster Profile Manager.

    "Gainin Data set for Node 001e06318cf1 with target output humidityAirmar @ 23-Nov-2020 10:33:41"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 292 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 73 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 213 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 97 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 49 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 13 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 10 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 7 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 6 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 219 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 77 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 37 and choosing a representative sample. Choosing 140 bins for this column. With 2 members per bin.
Going through column 38 and choosing a representative sample. Choosing 282 bins for this column. With 2 members per bin.
Going through column 39 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        9323


ans =

        1645

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Starting parallel pool (parpool) using the 'local' profile ...
The identifier was:
parallel:cluster:PoolRunValidationThere was an error! The message was:
Parallel pool failed to start with the following error. For more detailed information, validate the profile 'local' in the Cluster Profile Manager.

    "Gainin Data set for Node 001e06318cf1 with target output dewPointAirmar @ 23-Nov-2020 10:33:51"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 292 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 73 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 213 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 97 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 49 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 13 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 10 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 7 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 6 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 219 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 77 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 37 and choosing a representative sample. Choosing 140 bins for this column. With 2 members per bin.
Going through column 38 and choosing a representative sample. Choosing 282 bins for this column. With 2 members per bin.
Going through column 39 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        9285


ans =

        1639

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Starting parallel pool (parpool) using the 'local' profile ...
The identifier was:
parallel:cluster:PoolRunValidationThere was an error! The message was:
Parallel pool failed to start with the following error. For more detailed information, validate the profile 'local' in the Cluster Profile Manager.

    "Gainin Data set for Node 001e06318cf1 with target output pressureAirmar @ 23-Nov-2020 10:34:01"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 292 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 73 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 213 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 97 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 49 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 13 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 10 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 7 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 6 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 219 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 77 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 37 and choosing a representative sample. Choosing 140 bins for this column. With 2 members per bin.
Going through column 38 and choosing a representative sample. Choosing 282 bins for this column. With 2 members per bin.
Going through column 39 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        9314


ans =

        1644

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Starting parallel pool (parpool) using the 'local' profile ...
The identifier was:
parallel:cluster:PoolRunValidationThere was an error! The message was:
Parallel pool failed to start with the following error. For more detailed information, validate the profile 'local' in the Cluster Profile Manager.

IdleTimeout has been reached.
Parallel pool using the 'local' profile is shutting down.
