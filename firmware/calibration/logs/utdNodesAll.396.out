Running calibration scripts for UTD Node: 12
Running on host: compute-1-1-12

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
              R2020a Update 1 (9.8.0.1359463) 64-bit (glnxa64)
                               April 9, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 


    "---------------------MINTS---------------------"

22-Nov-2020 18:38:28

mintsDefinitions = 

  struct with fields:

                dataFolder: '/home/lhw150030/mintsData'
               poolWorkers: 16
                  timeSpan: 30
                  airmarID: '001e0610c0e4'
             binsPerColumn: 500
              numberPerBin: 2
                    pValid: 0.1500
                   nodeIDs: {1x16 cell}
               inputStack1: {1x9 cell}
         mintsInputsStack1: {1x35 cell}
    mintsInputLabelsStack1: {1x35 cell}
               inputStack2: {1x11 cell}
         mintsInputsStack2: {1x35 cell}
    mintsInputLabelsStack2: {1x35 cell}
               inputStack3: {1x10 cell}
         mintsInputsStack3: {1x38 cell}
    mintsInputLabelsStack3: {1x38 cell}
              mintsTargets: {1x10 cell}
         mintsTargetLabels: {1x10 cell}
                     units: {1x10 cell}
               instruments: {1x10 cell}

Starting parallel pool (parpool) using the 'local' profile ...
Connected to the parallel pool (number of workers: 16).

ans = 

 ProcessPool with properties: 

            Connected: true
           NumWorkers: 16
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


airmarFolder = 

    "/home/lhw150030/mintsData/referenceMats/airmar"

UTD_Rsl_All_2020_11_22_18_38_54


UTD_Rsl_All_Daily


Super Learner All Inputs




    "Data Folder Located @:/home/lhw150030/mintsData"

    "Raw Data Located @: /home/lhw150030/mintsData"

    "Raw DotMat Data Located @ :/home/lhw150030/mintsData/rawMats"

    "UTD Nodes DotMat Data Located @ :/home/lhw150030/mintsData/rawMats/UTDNodes"

    "Reference Data Located @: /home/lhw150030/mintsData/reference"

    "Reference DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats"

    "Palas Raw Data Located @ :/home/lhw150030/mintsData/reference/palasStream"

    "Palas DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats/palas"

    "Car GPS Files Located @ :/home/lhw150030/mintsData/referenceMats/carMintsGPS"

    "Loading Palas Files"

    "Loading GPS Files"

    "Loading Airmar Files"

    "Aligning GPS data with Palas Data"

    "WSTC Palas Data"

    "Palas With Airmar"

    "Analysis"

    "Save merged data for calibration: 001e063239e6"



    "Creating Training Data Sets for Node: 001e063239e6"



    "Gainin Data set for Node 001e063239e6 with target output pm1_palas @ 22-Nov-2020 18:39:02"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 323 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 75 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 318 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 81 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 59 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 38 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 19 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 8 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 432 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 457 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 319 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 188 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 37 and choosing a representative sample. Choosing 138 bins for this column. With 2 members per bin.
Going through column 38 and choosing a representative sample. Choosing 289 bins for this column. With 2 members per bin.
Going through column 39 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

       10906


ans =

        1925

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |       1 | Best   |      8.1215 |      2.7848 |      8.1215 |      11.102 |            7 |    0.0051364 |
|    2 |       1 | Accept |       12.72 |      2.9143 |      8.1215 |      11.102 |           73 |     0.016433 |
|    3 |       1 | Accept |      24.892 |      2.8724 |      8.1215 |      11.102 |           52 |      0.24407 |
|    4 |       1 | Accept |      36.964 |      3.0581 |      8.1215 |      11.102 |           98 |      0.54963 |
|    5 |       1 | Accept |       155.8 |       2.938 |      8.1215 |      11.102 |          100 |    0.0091087 |
|    6 |       1 | Accept |      20.739 |      2.8129 |      8.1215 |      11.102 |           70 |     0.027015 |
|    7 |       1 | Accept |       81.52 |      2.7615 |      8.1215 |      11.102 |           52 |      0.45124 |
|    8 |       1 | Accept |      35.995 |      2.8369 |      8.1215 |      11.102 |           71 |     0.062311 |
|    9 |       1 | Accept |      13.958 |      2.7584 |      8.1215 |      11.102 |           21 |     0.082522 |
|   10 |       1 | Accept |       21.52 |      2.8402 |      8.1215 |      11.102 |           89 |      0.20763 |
|   11 |       1 | Accept |      22.344 |      2.7973 |      8.1215 |      11.102 |           50 |    0.0061941 |
|   12 |       1 | Accept |      21.639 |      2.7277 |      8.1215 |      11.102 |           44 |      0.43702 |
|   13 |       1 | Accept |      12.855 |      2.8731 |      8.1215 |      11.102 |           88 |      0.16418 |
|   14 |       1 | Accept |      38.749 |      2.8687 |      8.1215 |      11.102 |           65 |    0.0022853 |
|   15 |       1 | Accept |      8.6031 |      2.6835 |      8.1215 |      11.102 |           16 |     0.011102 |
|   16 |       1 | Accept |      8.6199 |      2.6982 |      8.1215 |      11.102 |           19 |      0.28674 |
|   17 |       2 | Accept |      26.716 |      0.5282 |      5.8468 |       31.99 |           14 |     0.064869 |
|   18 |       2 | Accept |      17.831 |     0.59372 |      5.8468 |       31.99 |           34 |      0.19176 |
|   19 |       2 | Accept |      102.87 |      0.6401 |      5.8468 |       31.99 |           35 |     0.058466 |
|   20 |       2 | Best   |      5.8468 |     0.58405 |      5.8468 |       31.99 |           11 |    0.0057402 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       2 | Accept |      25.444 |     0.66094 |      5.8468 |       31.99 |           83 |     0.008162 |
|   22 |       2 | Accept |      9.6917 |     0.63327 |      5.8468 |       31.99 |           23 |     0.079083 |
|   23 |       2 | Accept |      29.824 |     0.64312 |      5.8468 |       31.99 |           23 |       0.1894 |
|   24 |       2 | Accept |      10.152 |      0.6772 |      5.8468 |       31.99 |           34 |     0.071937 |
|   25 |       2 | Accept |      31.477 |     0.70722 |      5.8468 |       31.99 |           94 |      0.14343 |
|   26 |       2 | Accept |      16.741 |     0.70839 |      5.8468 |       31.99 |           65 |       0.5778 |
|   27 |       2 | Accept |       46.45 |     0.66504 |      5.8468 |       31.99 |           79 |     0.050769 |
|   28 |       2 | Accept |      32.459 |      0.6546 |      5.8468 |       31.99 |           77 |     0.038485 |
|   29 |       2 | Accept |      58.826 |     0.64439 |      5.8468 |       31.99 |           21 |       0.2269 |
|   30 |       2 | Accept |      20.058 |     0.73644 |      5.8468 |       31.99 |           99 |     0.024349 |
|   31 |       2 | Accept |      32.268 |     0.58806 |      5.8468 |       31.99 |           35 |     0.042335 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 31
Total elapsed time: 14.3095 seconds.
Total objective function evaluation time: 54.8906

Best observed feasible point:
    hiddenLayerSize       lr    
    _______________    _________

          11           0.0057402

Observed objective function value = 5.8468
Estimated objective function value = 31.9896
Function evaluation time = 0.58405

Best estimated feasible point (according to models):
    hiddenLayerSize       lr    
    _______________    _________

           7           0.0051364

Estimated objective function value = 31.9896
Estimated function evaluation time = 1.3794


T =

  1x2 table

    hiddenLayerSize       lr    
    _______________    _________

           7           0.0051364

Elapsed time is 21.488713 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      3.0197 |      174.91 |      3.0197 |      3.0197 |       2.7514 |         none | squaredexpon |   8.3285e+12 |         true |
|    2 |      16 | Best   |      3.0019 |      184.36 |      3.0019 |      3.0026 |       3.6408 |         none |     matern52 |   6.9439e+11 |        false |
|    3 |      16 | Error  |         NaN |      265.61 |         NaN |       3.019 |   0.00019586 |         none |  exponential |   2.9567e+10 |        false |
|    4 |      16 | Best   |      2.9476 |      205.87 |      2.9476 |      2.9538 |       2.2635 |         none |     matern52 |   6.7125e+10 |        false |
|    5 |      16 | Accept |      11.416 |      510.21 |      2.9476 |      2.9749 |     0.070747 |       linear | squaredexpon |   5.2764e+11 |        false |
|    6 |      16 | Accept |      3.0197 |      659.88 |      2.9476 |      2.9738 |    0.0019819 |         none | rationalquad |   1.0708e+12 |         true |
|    7 |      16 | Error  |         NaN |      608.23 |      2.9476 |      2.9738 |      0.42201 |         none |     matern52 |   6.3301e+10 |        false |
|    8 |      16 | Accept |      3.0197 |      492.46 |      2.9476 |      2.9697 |   0.00010448 |         none |     matern52 |   1.8117e+13 |         true |
|    9 |      16 | Accept |      3.5353 |      759.72 |      2.9476 |      2.9665 |   0.00010399 |         none | rationalquad |   9.4301e+12 |        false |
|   10 |      16 | Error  |         NaN |      642.99 |      2.9476 |      2.9665 |   0.00011305 |       linear |     matern52 |   4.4456e+10 |        false |
|   11 |      16 | Error  |         NaN |      461.04 |      2.9476 |      2.9665 |    0.0001055 |         none |     matern32 |   5.4016e+10 |        false |
|   12 |      16 | Accept |      10.403 |       550.7 |      2.9476 |      2.9721 |   0.00010123 |       linear |     matern52 |   1.8811e+13 |        false |
|   13 |      16 | Accept |        3.02 |      754.66 |      2.9476 |      2.9719 |    0.0019052 |     constant | rationalquad |   9.1735e+11 |         true |
|   14 |      16 | Error  |         NaN |      1064.4 |      2.9476 |      2.9719 |   0.00010049 |         none |     matern32 |   2.4362e+10 |        false |
|   15 |      16 | Accept |      3.0198 |      253.95 |      2.9476 |      2.9708 |       2.5103 |     constant | squaredexpon |   5.1323e+12 |         true |
|   16 |      16 | Accept |      3.0199 |      569.34 |      2.9476 |      2.9695 |    0.0003179 |     constant |     matern52 |   6.6576e+11 |         true |
|   17 |      16 | Accept |      3.0146 |      158.46 |      2.9476 |      2.9719 |       2.2928 |     constant | squaredexpon |   2.7986e+12 |        false |
|   18 |      16 | Accept |      2.9943 |      3540.3 |      2.9476 |      2.9722 |       8.8294 |     constant |     matern52 |   2.0805e+10 |        false |
|   19 |      16 | Accept |      8.1194 |      767.19 |      2.9476 |      2.9677 |    0.0016191 |     constant | rationalquad |   1.6373e+12 |        false |
|   20 |      16 | Accept |      2.9945 |      327.15 |      2.9476 |      2.9668 |       8.5061 |     constant |     matern32 |    4.857e+10 |        false |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      16 | Accept |      3.0202 |      573.97 |      2.9476 |      2.9701 |   0.00032271 |     constant |     matern32 |   1.3782e+12 |         true |
|   22 |      16 | Accept |      2.9855 |       175.5 |      2.9476 |      2.9721 |       4.2083 |         none |     matern32 |   2.3406e+11 |        false |
|   23 |      16 | Accept |      2.9861 |      219.65 |      2.9476 |      2.9646 |       10.334 |     constant |  exponential |   8.8089e+10 |        false |
|   24 |      16 | Best   |      2.8154 |      176.08 |      2.8154 |      2.8156 |        4.163 |         none |  exponential |   1.8129e+11 |        false |
|   25 |      16 | Accept |      3.0195 |      263.05 |      2.8154 |      2.8156 |       10.238 |     constant |  exponential |   1.4895e+11 |         true |
|   26 |      16 | Accept |      3.0197 |      183.84 |      2.8154 |      2.8156 |       4.3624 |         none |  exponential |   1.7337e+11 |         true |
|   27 |      16 | Accept |      3.0197 |      543.37 |      2.8154 |      2.8156 |    0.0006378 |         none |     matern32 |   1.3389e+13 |         true |
|   28 |      16 | Best   |      2.4517 |      279.18 |      2.4517 |      2.4519 |       4.1621 |       linear |  exponential |   4.5316e+11 |        false |
|   29 |      16 | Accept |      10.049 |      277.62 |      2.4517 |      2.4519 |       4.4974 |       linear |  exponential |   2.3426e+11 |         true |
|   30 |      16 | Accept |      2.8058 |      188.41 |      2.4517 |       2.452 |       4.0655 | pureQuadrati |  exponential |   6.4733e+11 |        false |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 5356.8131 seconds.
Total objective function evaluation time: 15832.0739

Best observed feasible point:
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    4.1621       linear         exponential      4.5316e+11        false   

Observed objective function value = 2.4517
Estimated objective function value = 2.452
Function evaluation time = 279.1791

Best estimated feasible point (according to models):
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    4.1621       linear         exponential      4.5316e+11        false   

Estimated objective function value = 2.452
Estimated function evaluation time = 279.4342

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 29)
  In utdNodesOptSolo2 (line 214)] 
Elapsed time is 5370.387417 seconds.
Take a copy of the best attributes
Now use these optimum settings to do an exact GPR fit
[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In fitrsuperOptimized (line 51)
  In utdNodesOptSolo2 (line 214)] 
Elapsed time is 6.281233 seconds.
Train a hyper-parameter optimized Ensemble of Trees model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|    1 |      16 | Best   |       3.567 |      1.3185 |       3.567 |       3.567 |      LSBoost |           12 |    0.0012465 |         1384 |          122 |            2 |
|    2 |      16 | Best   |      2.2652 |      3.1709 |      2.2652 |      2.4316 |          Bag |           13 |            - |           48 |            2 |           24 |
|    3 |      14 | Best   |      0.9114 |      6.3357 |      0.9114 |     0.91162 |          Bag |           18 |            - |            3 |         4425 |            5 |
|    4 |      14 | Accept |      1.5004 |      3.9738 |      0.9114 |     0.91162 |          Bag |           21 |            - |          125 |           26 |            7 |
|    5 |      14 | Accept |       3.082 |      6.5504 |      0.9114 |     0.91162 |      LSBoost |           27 |     0.012784 |          445 |           29 |           20 |
|    6 |      12 | Best   |     0.89492 |      12.068 |     0.89492 |     0.89523 |          Bag |           35 |            - |            9 |         2047 |            9 |
|    7 |      12 | Accept |      2.3791 |      12.428 |     0.89492 |     0.89523 |          Bag |          129 |            - |            2 |            5 |            4 |
|    8 |      12 | Accept |      2.2639 |      3.2879 |     0.89492 |     0.89523 |          Bag |           18 |            - |           65 |            2 |           23 |
|    9 |      12 | Accept |       2.607 |       16.16 |     0.89492 |     0.89499 |      LSBoost |           89 |    0.0095683 |          128 |            6 |           17 |
|   10 |      12 | Accept |      3.0198 |      0.7263 |     0.89492 |     0.89499 |          Bag |           11 |            - |         5123 |         4155 |            1 |
|   11 |      12 | Accept |      1.4984 |      19.063 |     0.89492 |     0.89504 |          Bag |           38 |            - |          199 |          750 |           35 |
|   12 |      11 | Accept |     0.91483 |      17.315 |     0.89492 |     0.89554 |          Bag |           60 |            - |            4 |         1435 |            6 |
|   13 |      11 | Accept |      2.8429 |      8.2892 |     0.89492 |     0.89554 |          Bag |          163 |            - |          395 |        10747 |            1 |
|   14 |      16 | Accept |      1.9577 |      6.2104 |     0.89492 |     0.89555 |      LSBoost |           56 |      0.95849 |          587 |            1 |           34 |
|   15 |      15 | Accept |      3.0531 |      26.709 |     0.89492 |     0.89559 |      LSBoost |           99 |    0.0034478 |          306 |         7484 |           22 |
|   16 |      15 | Accept |      3.2132 |      3.0262 |     0.89492 |     0.89559 |      LSBoost |           17 |     0.016066 |         1620 |         2700 |           36 |
|   17 |      15 | Best   |     0.73935 |      9.5178 |     0.73935 |     0.73942 |          Bag |           10 |            - |            6 |         1081 |           27 |
|   18 |      15 | Accept |      2.0303 |      8.5266 |     0.73935 |     0.73942 |          Bag |           33 |            - |          653 |         7626 |           31 |
|   19 |      14 | Accept |      1.9813 |      39.537 |     0.73935 |     0.73962 |          Bag |          244 |            - |          317 |         3762 |           11 |
|   20 |      14 | Accept |      0.9102 |      4.3306 |     0.73935 |     0.73962 |          Bag |           13 |            - |            1 |         2841 |            5 |
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|   21 |      16 | Accept |      1.1273 |      22.467 |     0.73935 |     0.73957 |      LSBoost |          112 |      0.87725 |          190 |            6 |           18 |
|   22 |      15 | Accept |      2.2583 |      54.526 |     0.73935 |     0.74015 |          Bag |          280 |            - |           30 |            2 |           31 |
|   23 |      15 | Accept |     0.75975 |       8.427 |     0.73935 |     0.74015 |          Bag |           10 |            - |            4 |         2455 |           22 |
|   24 |      15 | Accept |      1.4218 |      56.248 |     0.73935 |     0.74013 |      LSBoost |          125 |     0.014859 |            1 |           19 |           35 |
|   25 |      16 | Accept |      2.3079 |      8.6806 |     0.73935 |     0.73989 |      LSBoost |          162 |      0.95806 |            4 |           10 |            1 |
|   26 |      15 | Accept |     0.77332 |      45.535 |     0.73935 |     0.73983 |          Bag |           72 |            - |           13 |          432 |           23 |
|   27 |      15 | Accept |      1.1245 |      8.9504 |     0.73935 |     0.73983 |      LSBoost |           15 |      0.97896 |           17 |           28 |           38 |
|   28 |      14 | Best   |     0.68516 |      25.377 |     0.68516 |     0.68566 |          Bag |           35 |            - |            1 |        10408 |           17 |
|   29 |      14 | Accept |      2.5051 |      4.1509 |     0.68516 |     0.68566 |      LSBoost |           86 |      0.94911 |         4228 |           16 |            6 |
|   30 |      14 | Best   |     0.65138 |      56.571 |     0.65138 |     0.65157 |          Bag |           44 |            - |            1 |         9893 |           34 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 84.5641 seconds.
Total objective function evaluation time: 499.4759

Best observed feasible point:
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             44               NaN            1             9893                 34         

Observed objective function value = 0.65138
Estimated objective function value = 0.65157
Function evaluation time = 56.5705

Best estimated feasible point (according to models):
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             44               NaN            1             9893                 34         

Estimated objective function value = 0.65157
Estimated function evaluation time = 56.727

Elapsed time is 89.060717 seconds.
Train the super learner model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Error  |         NaN |      144.02 |         NaN |         NaN |   0.00019874 |     constant |  exponential |   6.7506e+10 |        false |
|    2 |      16 | Accept |      3.0197 |      331.35 |         NaN |      3.0197 |     0.000728 |         none | squaredexpon |   3.3012e+11 |         true |
|    3 |      16 | Accept |      5.7431 |      478.63 |      3.0197 |      4.3339 |    0.0016774 |       linear | squaredexpon |   8.4344e+10 |        false |
|    4 |      16 | Accept |      5.3018 |      548.31 |      3.0197 |      4.6508 |      0.13405 | pureQuadrati |     matern52 |   8.0493e+12 |        false |
|    5 |      16 | Accept |      5.7316 |      561.23 |      3.0197 |      4.8976 |    0.0002395 |     constant |     matern52 |   6.8666e+12 |        false |
|    6 |      16 | Accept |      5.7678 |      580.06 |      3.0197 |      3.1274 |   0.00012375 |       linear |  exponential |   4.5647e+11 |         true |
|    7 |      16 | Accept |      3.0197 |      256.12 |      3.0197 |      3.0199 |    0.0031619 |         none | squaredexpon |   3.5202e+11 |         true |
|    8 |      16 | Best   |     0.20792 |      784.97 |     0.20792 |     0.20835 |       2.2549 |       linear | rationalquad |   1.2767e+11 |        false |
|    9 |      16 | Accept |      0.2087 |      444.65 |     0.20792 |     0.20829 |     0.033288 |       linear | squaredexpon |   9.5311e+12 |        false |
|   10 |      16 | Accept |       6.116 |      795.79 |     0.20792 |     0.20832 |     0.095075 |         none | rationalquad |   6.3629e+11 |        false |
|   11 |      16 | Accept |      3.0197 |      334.62 |     0.20792 |     0.20829 |   0.00063533 |         none | squaredexpon |   3.3743e+11 |         true |
|   12 |      16 | Accept |      3.0197 |       400.5 |     0.20792 |     0.20825 |   0.00010054 |         none | squaredexpon |   1.9677e+11 |         true |
|   13 |      16 | Accept |     0.21797 |      173.94 |     0.20792 |     0.20831 |    0.0006718 |       linear | squaredexpon |    2.017e+13 |        false |
|   14 |      16 | Accept |      3.0197 |       407.3 |     0.20792 |     0.20827 |   0.00036495 |         none | squaredexpon |   1.2708e+12 |         true |
|   15 |      16 | Accept |     0.54589 |      396.03 |     0.20792 |     0.20829 |       17.562 |       linear | rationalquad |   2.5486e+10 |        false |
|   16 |      16 | Accept |      3.0196 |      566.65 |     0.20792 |     0.20828 |    0.0020122 |     constant | squaredexpon |   3.3596e+11 |         true |
|   17 |      16 | Accept |      3.0181 |      172.42 |     0.20792 |     0.20827 |       3.9195 | pureQuadrati | squaredexpon |   2.0115e+13 |        false |
|   18 |      16 | Accept |      4.8889 |       571.3 |     0.20792 |     0.20828 |    0.0055411 |       linear | squaredexpon |    1.898e+13 |         true |
|   19 |      16 | Accept |      3.7243 |      788.53 |     0.20792 |     0.20828 |   0.00059439 |       linear | rationalquad |   1.2809e+11 |         true |
|   20 |      16 | Accept |      0.4364 |      814.75 |     0.20792 |     0.20818 |     0.000131 |       linear | rationalquad |     5.23e+11 |        false |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 1613.788 seconds.
Total objective function evaluation time: 9551.1337

Best observed feasible point:
    Sigma     BasisFunction     KernelFunction      KernelScale    Standardize
    ______    _____________    _________________    ___________    ___________

    2.2549       linear        rationalquadratic    1.2767e+11        false   

Observed objective function value = 0.20792
Estimated objective function value = 0.20818
Function evaluation time = 784.9693

Best estimated feasible point (according to models):
    Sigma     BasisFunction     KernelFunction      KernelScale    Standardize
    ______    _____________    _________________    ___________    ___________

    2.2549       linear        rationalquadratic    1.2767e+11        false   

Estimated objective function value = 0.20818
Estimated function evaluation time = 784.8225

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 90)
  In utdNodesOptSolo2 (line 214)] 
Elapsed time is 1649.351112 seconds.
Train the super learner error model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |     0.18388 |      217.64 |     0.18388 |     0.18388 |   0.00068117 |         none |     matern52 |   4.5667e+11 |         true |
|    2 |      16 | Accept |     0.18396 |      236.62 |     0.18388 |     0.18388 |      0.35151 | pureQuadrati | squaredexpon |   3.0236e+10 |        false |
|    3 |      16 | Accept |      0.1839 |      262.43 |     0.18388 |     0.18388 |        1.634 | pureQuadrati | squaredexpon |   9.2033e+12 |        false |
|    4 |      16 | Best   |     0.18385 |      276.41 |     0.18385 |     0.18385 |       3.6647 |         none |  exponential |   2.4949e+10 |         true |
|    5 |      16 | Error  |         NaN |      442.48 |     0.18385 |     0.18385 |    0.0002971 |       linear |     matern52 |   3.7661e+11 |        false |
|    6 |      16 | Accept |     0.18388 |      224.41 |     0.18385 |     0.18385 |   0.00041655 |         none |     matern52 |   4.6767e+11 |         true |
|    7 |      16 | Error  |         NaN |      503.83 |     0.18385 |     0.18385 |   0.00027083 | pureQuadrati |     matern52 |   6.7422e+11 |        false |
|    8 |      16 | Accept |     0.18387 |      230.04 |     0.18385 |     0.18385 |     0.088579 |         none |  exponential |   2.9007e+10 |         true |
|    9 |      16 | Accept |     0.18388 |      278.61 |     0.18385 |     0.18385 |    0.0067007 |         none |     matern52 |   3.7793e+12 |         true |
|   10 |      16 | Accept |      0.2405 |      526.76 |     0.18385 |     0.18388 |    0.0049324 |         none |     matern52 |   8.9466e+12 |        false |
|   11 |      16 | Accept |     0.18385 |      259.33 |     0.18385 |     0.18385 |       2.1606 |         none |  exponential |   2.8702e+11 |         true |
|   12 |      16 | Accept |     0.18388 |      222.02 |     0.18385 |     0.18386 |     0.010387 |         none |  exponential |   2.0331e+13 |         true |
|   13 |      16 | Accept |     0.18385 |      242.02 |     0.18385 |     0.18386 |      0.68342 |         none |     matern52 |   2.5146e+10 |         true |
|   14 |      16 | Accept |      0.1839 |      245.81 |     0.18385 |     0.18386 |      0.43201 |     constant |  exponential |   2.6651e+10 |         true |
|   15 |      16 | Accept |     0.18385 |      277.25 |     0.18385 |     0.18386 |       3.8923 |         none |     matern32 |   4.2868e+10 |         true |
|   16 |      16 | Error  |         NaN |      179.11 |     0.18385 |     0.18386 |    0.0029169 |         none |  exponential |   7.6288e+12 |        false |
|   17 |      16 | Accept |      4.1498 |      275.42 |     0.18385 |     0.18387 |       4.1886 |       linear |  exponential |   1.1795e+12 |         true |
|   18 |      16 | Accept |     0.18396 |      248.28 |     0.18385 |     0.18387 |      0.75969 |     constant |     matern52 |   3.9213e+10 |         true |
|   19 |      16 | Accept |       4.462 |      480.16 |     0.18385 |     0.18388 |   0.00013454 | pureQuadrati | squaredexpon |   7.2804e+12 |         true |
|   20 |      16 | Accept |     0.18389 |       486.8 |     0.18385 |     0.18387 |     0.001153 |     constant |     matern32 |   3.1149e+12 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 1268.4967 seconds.
Total objective function evaluation time: 6115.4269

Best observed feasible point:
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    3.6647        none          exponential      2.4949e+10        true    

Observed objective function value = 0.18385
Estimated objective function value = 0.18387
Function evaluation time = 276.4061

Best estimated feasible point (according to models):
     Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    ________    _____________    ______________    ___________    ___________

    0.088579        none          exponential      2.9007e+10        true    

Estimated objective function value = 0.18387
Estimated function evaluation time = 232.0355

Elapsed time is 1330.432059 seconds.
Elapsed time is 1330.432601 seconds.
Use the hyper-parameter optimized NN model for regression
Elapsed time is 0.128229 seconds.
Use the hyper-parameter optimized GPR model for regression
Elapsed time is 0.411257 seconds.
Use the hyper-parameter optimized Ensemble of Trees model for regression
Elapsed time is 0.101855 seconds.
Use the super learner model for regression
Elapsed time is 0.417645 seconds.
Use the error estimate to update the Super Learner Estimate
Elapsed time is 0.296106 seconds.
Use the hyper-parameter optimized NN model for regression
Elapsed time is 0.034073 seconds.
Use the hyper-parameter optimized GPR model for regression
Elapsed time is 0.075556 seconds.
Use the hyper-parameter optimized Ensemble of Trees model for regression
Elapsed time is 0.061808 seconds.
Use the super learner model for regression
Elapsed time is 0.075251 seconds.
Use the error estimate to update the Super Learner Estimate
Elapsed time is 0.055710 seconds.



combinedFigDaily = 

    "/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e063239e6/UTD_Rsl_All_Daily_001e063239e6_pm1_palas.png"


combinedFig = 

    "/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e063239e6/UTD_Rsl_All_2020_11_22_18_38_54/UTD_Rsl_All_2020_11_22_18_38_54_001e063239e6_pm1_palas.png"

    "Creating Folder @: '/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e063239e6/UTD_Rsl_All_2020_11_22_18_38_54'"

The identifier was:
MATLAB:license:checkouterrorThere was an error! The message was:
License checkout failed.
License Manager Error -97
License Manager cannot start. 
Check that the ports specified in the license file are not already in use. 
Restarting your machine may clear the ports.

Troubleshoot this issue by visiting: 
https://www.mathworks.com/support/lme/R2020a/97

Diagnostic Information:
Feature: Curve_Fitting_Toolbox 
License path: /home/lhw150030/.matlab/R2020a_licenses:/opt/ohpc/pub/unpackaged/apps/matlab/R2020a/licenses/license.dat:/opt/ohpc/pub/unpackaged/apps/matlab/R2020a/licenses/network.lic 
Licensing error: -97,121.

    "Gainin Data set for Node 001e063239e6 with target output pm2_5_palas @ 22-Nov-2020 21:00:44"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 323 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 75 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 318 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 81 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 59 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 38 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 19 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 8 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 432 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 457 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 319 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 188 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 37 and choosing a representative sample. Choosing 138 bins for this column. With 2 members per bin.
Going through column 38 and choosing a representative sample. Choosing 289 bins for this column. With 2 members per bin.
Going through column 39 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

       10843


ans =

        1914

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |      16 | Best   |      12.637 |     0.58979 |      12.637 |      12.637 |           20 |      0.02176 |
|    2 |       2 | Accept |      24.407 |     0.68109 |      12.637 |      42.406 |           12 |    0.0014701 |
|    3 |       2 | Accept |      22.511 |     0.74292 |      12.637 |      42.406 |           80 |    0.0025539 |
|    4 |       2 | Accept |      113.69 |     0.68566 |      12.637 |      42.406 |           53 |      0.36814 |
|    5 |       2 | Accept |      93.827 |     0.65327 |      12.637 |      42.406 |           47 |      0.68073 |
|    6 |       2 | Accept |      22.146 |     0.74518 |      12.637 |      42.406 |           70 |     0.012622 |
|    7 |       2 | Accept |      66.362 |     0.66591 |      12.637 |      42.406 |           58 |      0.72608 |
|    8 |       2 | Accept |      76.953 |     0.66409 |      12.637 |      42.406 |           47 |     0.019262 |
|    9 |       2 | Accept |      96.523 |     0.70266 |      12.637 |      42.406 |           77 |      0.15311 |
|   10 |       2 | Accept |      49.677 |     0.66121 |      12.637 |      42.406 |           53 |      0.29595 |
|   11 |       2 | Accept |      51.211 |     0.76869 |      12.637 |      42.406 |           99 |     0.075985 |
|   12 |       2 | Accept |      40.626 |     0.73337 |      12.637 |      42.406 |           67 |      0.10182 |
|   13 |       2 | Accept |      131.66 |     0.68192 |      12.637 |      42.406 |           57 |    0.0025289 |
|   14 |       2 | Accept |      50.574 |     0.83083 |      12.637 |      42.406 |           63 |     0.010151 |
|   15 |       2 | Accept |      65.203 |     0.64583 |      12.637 |      42.406 |           38 |       0.3058 |
|   16 |       2 | Accept |      43.644 |     0.62586 |      12.637 |      42.406 |           24 |    0.0034353 |
|   17 |      16 | Accept |      26.766 |     0.34469 |      12.637 |      40.245 |           74 |     0.047438 |
|   18 |       2 | Accept |        99.4 |     0.59958 |      12.637 |       33.56 |           88 |    0.0010136 |
|   19 |       2 | Accept |      17.724 |     0.25298 |      12.637 |       33.56 |           13 |    0.0043624 |
|   20 |       2 | Accept |      29.598 |      0.2581 |      12.637 |       33.56 |           21 |     0.002021 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       2 | Accept |      73.005 |     0.36317 |      12.637 |       33.56 |           75 |    0.0048322 |
|   22 |       2 | Accept |      35.189 |     0.30902 |      12.637 |       33.56 |           30 |      0.62773 |
|   23 |       2 | Accept |      136.28 |     0.37587 |      12.637 |       33.56 |           59 |     0.015295 |
|   24 |       2 | Accept |      86.463 |     0.37074 |      12.637 |       33.56 |           74 |     0.072854 |
|   25 |       2 | Accept |      62.692 |     0.35321 |      12.637 |       33.56 |           55 |      0.66273 |
|   26 |       2 | Accept |      56.036 |      0.3159 |      12.637 |       33.56 |           62 |     0.015943 |
|   27 |       2 | Accept |      158.31 |     0.41561 |      12.637 |       33.56 |           90 |     0.013662 |
|   28 |       2 | Accept |       121.7 |     0.37987 |      12.637 |       33.56 |           69 |     0.001024 |
|   29 |       2 | Accept |       21.76 |     0.25919 |      12.637 |       33.56 |           16 |    0.0034049 |
|   30 |       2 | Accept |      33.725 |     0.40907 |      12.637 |       33.56 |           94 |     0.062131 |
|   31 |       2 | Accept |      101.09 |     0.38508 |      12.637 |       33.56 |           64 |     0.060891 |
|   32 |       2 | Accept |      14.615 |     0.30312 |      12.637 |       33.56 |           21 |      0.02864 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 32
Total elapsed time: 4.9782 seconds.
Total objective function evaluation time: 16.7735

Best observed feasible point:
    hiddenLayerSize      lr   
    _______________    _______

          20           0.02176

Observed objective function value = 12.6371
Estimated objective function value = 33.5604
Function evaluation time = 0.58979

Best estimated feasible point (according to models):
    hiddenLayerSize      lr   
    _______________    _______

          20           0.02176

Estimated objective function value = 33.5604
Estimated function evaluation time = 0.48995


T =

  1x2 table

    hiddenLayerSize      lr   
    _______________    _______

          20           0.02176

Elapsed time is 10.187453 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Error  |         NaN |      207.59 |         NaN |         NaN |     0.031656 | pureQuadrati |  exponential |   2.4294e+11 |        false |
|    2 |      16 | Accept |       3.897 |      256.59 |         NaN |       3.897 |   0.00027203 |     constant |     matern32 |    1.103e+12 |         true |
|    3 |      15 | Accept |      10.433 |      265.54 |       3.897 |      3.8976 |     0.071955 |       linear |     matern52 |   1.0711e+12 |         true |
|    4 |      15 | Accept |       10.24 |      264.02 |       3.897 |      3.8976 |     0.017425 |       linear |     matern52 |   7.9698e+11 |         true |
|    5 |      15 | Accept |      9.3152 |      269.78 |       3.897 |      3.9093 |       20.961 |       linear |     matern52 |   1.4391e+13 |         true |
|    6 |      16 | Best   |      2.6368 |      398.08 |      2.6368 |      2.6465 |       2.6508 |       linear |  exponential |   3.3987e+12 |        false |
|    7 |      16 | Error  |         NaN |      436.06 |      2.6368 |      2.6465 |    0.0007386 |         none |     matern32 |   3.1211e+12 |        false |
|    8 |      16 | Error  |         NaN |      461.69 |      2.6368 |      2.6465 |   0.00045591 |     constant |     matern32 |   2.1858e+10 |        false |
|    9 |      16 | Accept |      10.808 |      263.82 |      2.6368 |      2.6497 |        26.89 | pureQuadrati |  exponential |   1.0973e+13 |         true |
|   10 |      16 | Accept |      3.9092 |      227.12 |      2.6368 |      2.6514 |       1.5811 |     constant |     matern32 |   2.0732e+10 |         true |
|   11 |      16 | Accept |      3.9093 |       252.8 |      2.6368 |      2.6504 |       51.273 |     constant |     matern52 |   1.0993e+12 |         true |
|   12 |      16 | Accept |       3.909 |      271.68 |      2.6368 |      2.6489 |   0.00011021 |     constant |     matern32 |   2.0571e+13 |         true |
|   13 |      16 | Accept |      10.631 |      261.88 |      2.6368 |      2.6509 |    0.0037524 |       linear |  exponential |   3.2259e+12 |         true |
|   14 |      16 | Error  |         NaN |      361.19 |      2.6368 |      2.6509 |     0.013593 |       linear |  exponential |   2.0474e+13 |        false |
|   15 |      16 | Error  |         NaN |      287.36 |      2.6368 |      2.6509 |        2.647 |         none |  exponential |   1.9473e+12 |        false |
|   16 |      16 | Accept |      3.9091 |      347.56 |      2.6368 |      2.6499 |       14.044 |     constant | rationalquad |   1.0346e+12 |         true |
|   17 |      16 | Accept |      3.9091 |         176 |      2.6368 |      2.6493 |       68.338 |         none |     matern32 |    2.604e+11 |         true |
|   18 |      16 | Best   |      1.4216 |      538.65 |      1.4216 |      1.4351 |     0.055385 |     constant |  exponential |   1.8823e+11 |         true |
|   19 |      16 | Accept |      3.9101 |      270.29 |      1.4216 |      1.4353 |       63.393 |     constant |     matern52 |   1.7631e+11 |        false |
|   20 |      16 | Accept |      3.9089 |      176.26 |      1.4216 |      1.4355 |       36.336 |         none |     matern52 |   1.5088e+13 |         true |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      16 | Accept |      3.9099 |      342.42 |      1.4216 |      1.4357 |       15.022 |     constant | rationalquad |   1.8398e+12 |        false |
|   22 |      16 | Accept |      2.6176 |      571.29 |      1.4216 |       1.435 |       4.6959 |       linear |     matern32 |   1.8285e+12 |        false |
|   23 |      16 | Accept |       3.909 |      254.59 |      1.4216 |      1.4226 |       69.657 |     constant |  exponential |   4.1874e+10 |         true |
|   24 |      16 | Accept |      3.9089 |      246.97 |      1.4216 |      1.4226 |       21.621 |         none | rationalquad |   1.5165e+12 |         true |
|   25 |      16 | Accept |      3.9135 |      241.34 |      1.4216 |      1.4226 |       69.492 |         none |     matern52 |   3.9347e+12 |        false |
|   26 |      16 | Accept |      3.9089 |      259.21 |      1.4216 |      1.4226 |       69.684 |     constant |  exponential |   1.1554e+13 |        false |
|   27 |      16 | Error  |         NaN |      1260.1 |      1.4216 |      1.4226 |   0.00035253 |       linear |  exponential |   2.0768e+10 |        false |
|   28 |      16 | Accept |      1.6814 |      579.88 |      1.4216 |       1.423 |   0.00010215 |     constant |  exponential |    5.076e+11 |         true |
|   29 |      16 | Accept |      3.9091 |      248.43 |      1.4216 |       1.423 |       13.777 |     constant | squaredexpon |   1.6468e+12 |         true |
|   30 |      16 | Error  |         NaN |      494.41 |      1.4216 |       1.423 |   0.00010012 |       linear |     matern32 |   3.6502e+10 |        false |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 1804.5559 seconds.
Total objective function evaluation time: 10492.6632

Best observed feasible point:
     Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    ________    _____________    ______________    ___________    ___________

    0.055385      constant        exponential      1.8823e+11        true    

Observed objective function value = 1.4216
Estimated objective function value = 1.423
Function evaluation time = 538.6549

Best estimated feasible point (according to models):
     Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    ________    _____________    ______________    ___________    ___________

    0.055385      constant        exponential      1.8823e+11        true    

Estimated objective function value = 1.423
Estimated function evaluation time = 538.6021

Elapsed time is 1837.299503 seconds.
Take a copy of the best attributes
Now use these optimum settings to do an exact GPR fit
Elapsed time is 17.903144 seconds.
Train a hyper-parameter optimized Ensemble of Trees model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|    1 |      16 | Best   |      3.3488 |      1.7131 |      3.3488 |      3.3488 |          Bag |           25 |            - |         2357 |          335 |            6 |
|    2 |      15 | Best   |      1.9277 |      2.7433 |      1.9277 |      1.9923 |      LSBoost |           13 |      0.44243 |          645 |            3 |           37 |
|    3 |      15 | Accept |      1.9806 |      1.9959 |      1.9277 |      1.9923 |          Bag |           14 |            - |           78 |           45 |            4 |
|    4 |      12 | Accept |      3.7609 |      7.4473 |      1.9277 |      1.9278 |          Bag |          145 |            - |         3137 |            4 |            2 |
|    5 |      12 | Accept |      2.5248 |      4.2672 |      1.9277 |      1.9278 |          Bag |           31 |            - |         1960 |            3 |           34 |
|    6 |      12 | Accept |       3.858 |      5.7339 |      1.9277 |      1.9278 |      LSBoost |           53 |    0.0067866 |           66 |            4 |            8 |
|    7 |      12 | Accept |       4.339 |       2.223 |      1.9277 |      1.9278 |      LSBoost |           14 |    0.0050409 |         1188 |         5247 |           27 |
|    8 |      11 | Best   |      1.6622 |      10.366 |      1.6622 |      1.6623 |      LSBoost |           59 |      0.84819 |          503 |            3 |           31 |
|    9 |      11 | Accept |      3.5496 |      3.3712 |      1.6622 |      1.6623 |      LSBoost |           14 |     0.039293 |          656 |            4 |           37 |
|   10 |      16 | Accept |      2.0577 |      15.938 |      1.6622 |      1.6623 |          Bag |           96 |            - |          486 |           36 |           15 |
|   11 |      15 | Best   |      1.4413 |      6.8531 |      1.4413 |      1.4414 |          Bag |           10 |            - |           55 |          250 |           33 |
|   12 |      15 | Accept |      1.7037 |       3.945 |      1.4413 |      1.4414 |          Bag |           27 |            - |            4 |         7359 |            2 |
|   13 |      15 | Accept |      3.4622 |      8.8224 |      1.4413 |      1.4413 |          Bag |          146 |            - |         2319 |           15 |            3 |
|   14 |      12 | Accept |      2.2454 |      27.036 |      1.2183 |      1.2184 |          Bag |          102 |            - |          643 |         1310 |           31 |
|   15 |      12 | Accept |      4.3193 |      25.405 |      1.2183 |      1.2184 |      LSBoost |           22 |    0.0033011 |            1 |         1929 |           30 |
|   16 |      12 | Accept |      3.9089 |      11.429 |      1.2183 |      1.2184 |      LSBoost |          311 |      0.99028 |         5223 |          402 |           31 |
|   17 |      12 | Best   |      1.2183 |      9.6548 |      1.2183 |      1.2184 |          Bag |           16 |            - |            5 |          268 |           23 |
|   18 |      12 | Accept |      1.4544 |      17.851 |      1.2183 |      1.2184 |      LSBoost |          139 |     0.024484 |            5 |           17 |            7 |
|   19 |      15 | Accept |      1.5756 |       43.27 |      1.2183 |      1.2158 |      LSBoost |          394 |     0.026369 |          479 |          207 |            7 |
|   20 |      12 | Accept |      2.9635 |      45.549 |      1.2183 |      1.2243 |      LSBoost |          249 |    0.0039295 |           44 |            7 |           21 |
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|   21 |      12 | Accept |        1.73 |      7.0545 |      1.2183 |      1.2243 |      LSBoost |           98 |      0.19993 |           12 |           76 |            1 |
|   22 |      12 | Accept |      2.1627 |      5.5789 |      1.2183 |      1.2243 |      LSBoost |           11 |      0.11759 |            6 |          117 |           27 |
|   23 |      12 | Accept |      1.9887 |      1.2292 |      1.2183 |      1.2243 |      LSBoost |           16 |      0.95807 |           51 |            3 |            5 |
|   24 |      10 | Accept |      1.7009 |      48.677 |      1.2183 |      1.2291 |          Bag |          376 |            - |            5 |           31 |            6 |
|   25 |      10 | Accept |      1.5306 |      27.833 |      1.2183 |      1.2291 |      LSBoost |           29 |      0.95709 |          125 |          452 |           37 |
|   26 |      10 | Accept |      3.3963 |      2.0873 |      1.2183 |      1.2291 |      LSBoost |           26 |     0.024498 |          627 |            5 |            7 |
|   27 |      16 | Accept |      4.3671 |      2.1462 |      1.2183 |       1.235 |      LSBoost |           11 |    0.0047181 |          210 |         7212 |           12 |
|   28 |      16 | Accept |       3.404 |      44.638 |      1.2183 |      1.2385 |      LSBoost |          362 |    0.0016953 |           49 |          226 |            4 |
|   29 |      15 | Accept |      3.2884 |      7.1981 |      1.2183 |      1.2977 |          Bag |          106 |            - |         3422 |          377 |           23 |
|   30 |      15 | Accept |      2.0955 |      3.6984 |      1.2183 |      1.2977 |          Bag |           10 |            - |            1 |            7 |           37 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 72.8022 seconds.
Total objective function evaluation time: 405.7546

Best observed feasible point:
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             16               NaN            5             268                  23         

Observed objective function value = 1.2183
Estimated objective function value = 1.2977
Function evaluation time = 9.6548

Best estimated feasible point (according to models):
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             16               NaN            5             268                  23         

Estimated objective function value = 1.2977
Estimated function evaluation time = 9.6501

Elapsed time is 74.697302 seconds.
Train the super learner model for regression
Copying objective function to workers...
Done copying objective function to workers.
