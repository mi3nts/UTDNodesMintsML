Running calibration scripts for UTD Node: 3
Running on host: compute-1-1-35

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
              R2020a Update 1 (9.8.0.1359463) 64-bit (glnxa64)
                               April 9, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 


    "---------------------MINTS---------------------"

18-Dec-2020 09:47:19

mintsDefinitions = 

  struct with fields:

                dataFolder: '/home/lhw150030/mintsData'
               poolWorkers: 16
                  timeSpan: 30
                  airmarID: '001e0610c0e4'
             binsPerColumn: 500
              numberPerBin: 2
                    pValid: 0.1500
                   nodeIDs: {1x16 cell}
               inputStack1: {1x9 cell}
         mintsInputsStack1: {1x35 cell}
    mintsInputLabelsStack1: {1x35 cell}
               inputStack2: {1x11 cell}
         mintsInputsStack2: {1x35 cell}
    mintsInputLabelsStack2: {1x35 cell}
               inputStack3: {1x10 cell}
         mintsInputsStack3: {1x38 cell}
    mintsInputLabelsStack3: {1x38 cell}
              mintsTargets: {1x10 cell}
         mintsTargetLabels: {1x10 cell}
                     units: {1x10 cell}
               instruments: {1x10 cell}

Starting parallel pool (parpool) using the 'local' profile ...
Connected to the parallel pool (number of workers: 16).

ans = 

 ProcessPool with properties: 

            Connected: true
           NumWorkers: 16
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


airmarFolder = 

    "/home/lhw150030/mintsData/referenceMats/airmar"

UTD_Rsl_All_2020_12_18_09_49_43


UTD_Rsl_All_Daily


Super Learner All Inputs




    "Data Folder Located @:/home/lhw150030/mintsData"

    "Raw Data Located @: /home/lhw150030/mintsData"

    "Raw DotMat Data Located @ :/home/lhw150030/mintsData/rawMats"

    "UTD Nodes DotMat Data Located @ :/home/lhw150030/mintsData/rawMats/UTDNodes"

    "Reference Data Located @: /home/lhw150030/mintsData/reference"

    "Reference DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats"

    "Palas Raw Data Located @ :/home/lhw150030/mintsData/reference/palasStream"

    "Palas DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats/palas"

    "Car GPS Files Located @ :/home/lhw150030/mintsData/referenceMats/carMintsGPS"

    "Loading Palas Files"

    "Loading GPS Files"

    "Loading Airmar Files"

    "Aligning GPS data with Palas Data"

    "WSTC Palas Data"

    "Palas With Airmar"

    "Analysis"

    "Save merged data for calibration: 001e06318cd1"



    "Creating Training Data Sets for Node: 001e06318cd1"



    "Gainin Data set for Node 001e06318cd1 with target output pm1_palas @ 18-Dec-2020 09:51:01"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 320 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 70 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 211 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 151 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 98 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 54 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 26 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 15 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 10 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 7 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 370 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 303 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 262 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 171 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        6881


ans =

        1214

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |      10 | Accept |      12.698 |      9.0568 |       11.89 |      38.635 |           53 |      0.63491 |
|    2 |      10 | Accept |      46.983 |      9.0061 |       11.89 |      38.635 |           48 |    0.0029512 |
|    3 |      10 | Accept |      67.104 |      8.7664 |       11.89 |      38.635 |           57 |     0.011788 |
|    4 |      10 | Accept |      97.545 |      10.031 |       11.89 |      38.635 |          100 |     0.004509 |
|    5 |      10 | Accept |      19.105 |      8.8742 |       11.89 |      38.635 |           20 |     0.011734 |
|    6 |      10 | Accept |      15.118 |      8.8467 |       11.89 |      38.635 |           11 |      0.57762 |
|    7 |      10 | Best   |       11.89 |      8.5174 |       11.89 |      38.635 |           51 |    0.0043921 |
|    8 |       8 | Best   |      11.554 |      12.043 |      11.554 |      22.336 |           93 |      0.26336 |
|    9 |       8 | Accept |      34.723 |      12.264 |      11.554 |      22.336 |           48 |      0.01128 |
|   10 |       8 | Accept |      17.747 |      14.286 |      11.554 |      22.336 |           55 |      0.10098 |
|   11 |       8 | Accept |       55.75 |      12.531 |      11.554 |      22.336 |           32 |     0.013059 |
|   12 |       8 | Accept |      79.112 |      11.943 |      11.554 |      22.336 |           89 |    0.0016643 |
|   13 |       8 | Accept |      46.275 |       12.39 |      11.554 |      22.336 |           36 |     0.041827 |
|   14 |       8 | Accept |      41.238 |      11.169 |      11.554 |      22.336 |           46 |     0.048563 |
|   15 |       8 | Accept |      41.181 |      9.3943 |      11.554 |      22.336 |           32 |      0.32311 |
|   16 |       8 | Accept |      155.81 |       11.87 |      11.554 |      22.336 |           89 |    0.0031903 |
|   17 |      10 | Best   |      8.2353 |     0.95849 |      8.2353 |       15.22 |            7 |      0.99731 |
|   18 |      10 | Accept |        59.5 |      0.7409 |      8.2353 |       15.22 |           50 |     0.047714 |
|   19 |      10 | Accept |      38.437 |      1.2844 |      8.2353 |       15.22 |           65 |      0.09594 |
|   20 |      10 | Accept |      14.681 |     0.76521 |      8.2353 |       15.22 |           26 |    0.0071329 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |      10 | Accept |      32.689 |      1.2402 |      8.2353 |       15.22 |           69 |      0.10982 |
|   22 |      10 | Accept |      17.127 |      1.5859 |      8.2353 |       15.22 |           19 |    0.0031753 |
|   23 |      10 | Accept |      109.88 |      1.4194 |      8.2353 |       15.22 |           77 |     0.027071 |
|   24 |       5 | Accept |      13.061 |      1.1563 |      8.2353 |      12.101 |           77 |      0.75507 |
|   25 |       5 | Accept |      10.969 |     0.73218 |      8.2353 |      12.101 |           13 |      0.24812 |
|   26 |       5 | Accept |      14.804 |      1.5514 |      8.2353 |      12.101 |           93 |      0.57974 |
|   27 |       5 | Accept |      27.114 |     0.96843 |      8.2353 |      12.101 |           36 |       0.1197 |
|   28 |       5 | Accept |      9.7584 |      1.3817 |      8.2353 |      12.101 |           35 |    0.0027593 |
|   29 |       5 | Accept |      24.929 |      1.8808 |      8.2353 |      12.101 |           93 |    0.0016497 |
|   30 |       5 | Accept |      13.054 |      1.5526 |      8.2353 |      12.101 |           35 |      0.06424 |
|   31 |       5 | Accept |      117.34 |     0.91942 |      8.2353 |      12.101 |           89 |     0.073033 |
|   32 |       5 | Accept |      62.708 |      1.0961 |      8.2353 |      12.101 |           58 |    0.0013574 |
|   33 |       5 | Accept |       12.11 |     0.34688 |      8.2353 |      12.101 |            6 |      0.03052 |
|   34 |       5 | Accept |      9.3115 |     0.54357 |      8.2353 |      12.101 |           70 |       0.9876 |
|   35 |       5 | Accept |      34.325 |     0.45186 |      8.2353 |      12.101 |           33 |      0.76792 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 35
Total elapsed time: 41.337 seconds.
Total objective function evaluation time: 191.5665

Best observed feasible point:
    hiddenLayerSize      lr   
    _______________    _______

           7           0.99731

Observed objective function value = 8.2353
Estimated objective function value = 17.39
Function evaluation time = 0.95849

Best estimated feasible point (according to models):
    hiddenLayerSize      lr   
    _______________    _______

          77           0.75507

Estimated objective function value = 12.101
Estimated function evaluation time = 2.9227


T =

  1x2 table

    hiddenLayerSize      lr   
    _______________    _______

          77           0.75507

Elapsed time is 4058.445812 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Starting parallel pool (parpool) using the 'local' profile ...
Connected to the parallel pool (number of workers: 12).
IdleTimeout has been reached.
Parallel pool using the 'local' profile is shutting down.
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      12 | Best   |      4.2773 |       488.1 |      4.2773 |      4.2773 |       2.1165 | pureQuadrati |     matern52 |   8.9824e+09 |        false |
|    2 |      12 | Best   |      3.3085 |      949.04 |      3.3085 |       3.347 |       1.2088 |         none |  exponential |   2.1345e+11 |         true |
|    3 |      12 | Best   |      1.4419 |      2330.8 |      1.4419 |      2.3006 |      0.17177 |         none |  exponential |   5.6154e+10 |         true |
|    4 |      12 | Accept |      2.2591 |      2387.6 |      1.4419 |      1.4422 |     0.082399 |         none |  exponential |    1.754e+12 |         true |
|    5 |      12 | Accept |      1.4422 |      2431.9 |      1.4419 |      1.4423 |      0.13372 |         none |  exponential |   5.4557e+10 |         true |
|    6 |      12 | Accept |       3.309 |      6121.6 |      1.4419 |      1.4422 |   0.00043269 |     constant |     matern52 |   3.9314e+11 |         true |
|    7 |      12 | Accept |      1.4732 |      2362.4 |      1.4419 |       1.441 |      0.27547 |         none |  exponential |   2.4702e+11 |         true |
|    8 |      12 | Best   |      1.4403 |      2210.8 |      1.4403 |       1.436 |       0.1464 |         none |  exponential |   7.7516e+09 |         true |
|    9 |      12 | Accept |      3.3085 |      910.68 |      1.4403 |      1.4362 |      0.20862 |         none |     matern32 |    9.989e+10 |         true |
|   10 |      12 | Accept |      1.5307 |      2240.4 |      1.4403 |      1.4265 |      0.19437 |         none |  exponential |   3.9697e+11 |         true |
|   11 |      12 | Accept |      3.3085 |      540.58 |      1.4403 |      1.4406 |      0.42426 |         none |  exponential |   3.4267e+12 |         true |
|   12 |      12 | Accept |      3.3085 |      1796.4 |      1.4403 |      1.4406 |      0.20554 |         none |  exponential |   1.0901e+12 |        false |
|   13 |      12 | Accept |      1.4511 |      2346.4 |      1.4403 |        1.44 |       0.1906 |         none |  exponential |   1.5848e+11 |         true |
|   14 |      12 | Accept |      1.4479 |      2217.8 |      1.4403 |      1.4404 |     0.037006 |         none |  exponential |   9.6701e+10 |         true |
|   15 |      12 | Accept |      19.727 |       14704 |      1.4403 |      1.4251 |    0.0014545 | pureQuadrati |     matern52 |   1.1768e+12 |        false |
|   16 |      12 | Best   |      1.4401 |      2239.2 |      1.4401 |      1.4243 |      0.23337 |         none |  exponential |   8.1331e+09 |         true |
|   17 |      12 | Accept |      1.4406 |      2093.6 |      1.4401 |      1.4235 |     0.017387 |         none |  exponential |   2.4244e+10 |         true |
|   18 |      12 | Accept |      3.3085 |      2005.3 |      1.4401 |      1.4238 |   0.00030814 |         none |     matern32 |   1.2065e+10 |         true |
|   19 |      12 | Accept |      3.3216 |      1750.1 |      1.4401 |      1.4242 |   0.00024985 |         none |  exponential |   1.2064e+11 |        false |
|   20 |      12 | Accept |      3.3086 |      879.42 |      1.4401 |      1.4245 |       0.2773 |     constant |     matern52 |    5.999e+12 |         true |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      12 | Accept |      3.3126 |      439.24 |      1.4401 |      1.4245 |       51.096 | pureQuadrati |     matern52 |   2.5382e+10 |        false |
|   22 |      12 | Accept |      3.3091 |      870.43 |      1.4401 |      1.4249 |       48.411 |     constant |     matern52 |   9.1271e+09 |         true |
|   23 |      12 | Accept |      3.3163 |      459.74 |      1.4401 |      1.4252 |       50.186 |         none |  exponential |   8.2105e+09 |        false |
|   24 |      12 | Accept |      3.3089 |      421.93 |      1.4401 |      1.4255 |       51.225 |         none |     matern32 |   3.1138e+12 |         true |
|   25 |      12 | Accept |      3.3095 |      935.97 |      1.4401 |      1.4262 |       0.1305 |     constant |     matern32 |   1.7808e+11 |         true |
|   26 |      11 | Best   |      1.4401 |       15774 |      1.4401 |       1.425 |      0.05988 |         none |  exponential |   8.0101e+09 |         true |
|   27 |      11 | Error  |         NaN |      1673.3 |      1.4401 |       1.425 |     0.022307 |         none |     matern32 |   5.5935e+10 |        false |
|   28 |      12 | Accept |      3.3083 |       881.9 |      1.4401 |      1.4254 |        49.51 |     constant |     matern32 |   6.5422e+12 |         true |
|   29 |      12 | Accept |      3.3085 |        5880 |      1.4401 |      1.4258 |   0.00010946 |     constant |     matern32 |   6.3713e+10 |         true |
|   30 |      12 | Accept |       1.452 |       15580 |      1.4401 |      1.4255 |   0.00010014 |         none |  exponential |   1.6341e+11 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 30496.767 seconds.
Total objective function evaluation time: 95922.7354

Best observed feasible point:
     Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    _______    _____________    ______________    ___________    ___________

    0.05988        none          exponential      8.0101e+09        true    

Observed objective function value = 1.4401
Estimated objective function value = 1.4413
Function evaluation time = 15773.7754

Best estimated feasible point (according to models):
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    0.1906        none          exponential      1.5848e+11        true    

Estimated objective function value = 1.4255
Estimated function evaluation time = 2114.3769

Elapsed time is 30824.925225 seconds.
Take a copy of the best attributes
Now use these optimum settings to do an exact GPR fit
Elapsed time is 57.824650 seconds.
Train a hyper-parameter optimized Ensemble of Trees model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|    1 |      12 | Best   |      3.8148 |      3.9744 |      3.8148 |      3.8148 |      LSBoost |           11 |    0.0053456 |           17 |            5 |           27 |
|    2 |      11 | Accept |      2.9088 |      6.4685 |      1.9752 |      2.1196 |          Bag |           29 |            - |          947 |         2359 |           18 |
|    3 |      11 | Best   |      1.9752 |      6.3878 |      1.9752 |      2.1196 |          Bag |           13 |            - |           42 |           20 |           28 |
|    4 |       8 | Accept |      2.4928 |      15.699 |      1.9752 |      1.9754 |      LSBoost |           10 |      0.63143 |          389 |            2 |           22 |
|    5 |       8 | Accept |      3.8128 |      23.119 |      1.9752 |      1.9754 |      LSBoost |           17 |    0.0036971 |           13 |           12 |            7 |
|    6 |       8 | Accept |      3.8789 |      23.533 |      1.9752 |      1.9754 |      LSBoost |           18 |    0.0012069 |            2 |            1 |           14 |
|    7 |       8 | Accept |      2.3103 |      16.511 |      1.9752 |      1.9754 |      LSBoost |          143 |     0.032938 |            5 |           11 |            9 |
|    8 |      10 | Accept |      1.7892 |      33.269 |      1.3154 |      1.3155 |          Bag |           18 |            - |           66 |          513 |           35 |
|    9 |      10 | Accept |      2.4698 |      38.843 |      1.3154 |      1.3155 |      LSBoost |          255 |     0.093848 |         1609 |         3050 |           27 |
|   10 |      10 | Best   |      1.3154 |       40.75 |      1.3154 |      1.3155 |          Bag |           24 |            - |            1 |         2527 |            9 |
|   11 |       8 | Accept |      2.0308 |      13.068 |      1.3154 |      1.3155 |          Bag |           11 |            - |           40 |           20 |           30 |
|   12 |       8 | Accept |      3.3085 |      4.0924 |      1.3154 |      1.3155 |      LSBoost |           60 |      0.99386 |         2925 |          856 |           28 |
|   13 |       8 | Accept |      3.6338 |      4.2994 |      1.3154 |      1.3155 |      LSBoost |           62 |    0.0060072 |         1176 |           29 |            2 |
|   14 |      12 | Best   |      1.3142 |      61.364 |      1.3142 |      1.3145 |      LSBoost |          201 |     0.016891 |            4 |          131 |           16 |
|   15 |      12 | Accept |      3.0861 |       22.31 |      1.3142 |      1.3146 |          Bag |           91 |            - |            1 |         1869 |            3 |
|   16 |      10 | Best   |      1.2017 |      69.335 |      1.2017 |       1.202 |          Bag |           24 |            - |            5 |         6560 |           24 |
|   17 |      10 | Accept |      1.8597 |      58.394 |      1.2017 |       1.202 |      LSBoost |          331 |      0.58408 |           39 |            2 |           16 |
|   18 |      10 | Accept |      2.0027 |      52.611 |      1.2017 |       1.202 |      LSBoost |          186 |      0.12364 |          642 |         1137 |           21 |
|   19 |       9 | Accept |      1.4782 |      92.978 |      1.2017 |      1.2019 |      LSBoost |           65 |      0.66368 |           75 |           10 |           29 |
|   20 |       9 | Accept |      3.6134 |      97.807 |      1.2017 |      1.2019 |      LSBoost |          129 |     0.001728 |          491 |         3434 |           12 |
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|   21 |       8 | Accept |      1.9026 |      113.88 |      1.1913 |      1.1914 |          Bag |          301 |            - |           49 |           47 |           24 |
|   22 |       8 | Best   |      1.1913 |      88.834 |      1.1913 |      1.1914 |          Bag |           84 |            - |            1 |         6358 |           15 |
|   23 |      12 | Best   |      1.1643 |      10.673 |      1.1643 |      1.1641 |          Bag |           19 |            - |            3 |          981 |           23 |
|   24 |      11 | Accept |      1.7208 |      20.766 |      1.1643 |      1.1642 |      LSBoost |           83 |      0.33782 |           22 |            4 |           24 |
|   25 |      11 | Accept |      2.3618 |      27.021 |      1.1643 |      1.1642 |      LSBoost |          142 |      0.19441 |            1 |            3 |           10 |
|   26 |       7 | Accept |      3.0487 |      216.49 |      1.1643 |      1.1643 |          Bag |          372 |            - |         2689 |          236 |           17 |
|   27 |       7 | Accept |      1.4446 |      207.26 |      1.1643 |      1.1643 |      LSBoost |          326 |    0.0057189 |            6 |          257 |           32 |
|   28 |       7 | Accept |      2.8107 |      154.44 |      1.1643 |      1.1643 |      LSBoost |          300 |     0.032039 |         1002 |          626 |            9 |
|   29 |       7 | Accept |      1.3159 |      40.001 |      1.1643 |      1.1643 |          Bag |           66 |            - |            1 |          341 |           24 |
|   30 |       7 | Accept |      1.6724 |      48.634 |      1.1643 |      1.1643 |          Bag |           33 |            - |            4 |           55 |           28 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 226.3818 seconds.
Total objective function evaluation time: 1612.8162

Best observed feasible point:
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             19               NaN            3             981                  23         

Observed objective function value = 1.1643
Estimated objective function value = 1.1643
Function evaluation time = 10.6727

Best estimated feasible point (according to models):
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             19               NaN            3             981                  23         

Estimated objective function value = 1.1643
Estimated function evaluation time = 21.0655

Elapsed time is 233.932627 seconds.
Train the super learner model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      12 | Best   |      3.5362 |      1028.9 |      3.5362 |      3.5362 |      0.30466 |         none |  exponential |   3.8243e+11 |        false |
|    2 |      12 | Accept |       20.87 |        1602 |      3.5362 |      4.2255 |       1.3406 | pureQuadrati |     matern32 |   9.7208e+09 |        false |
|    3 |      12 | Best   |      3.2766 |      2367.5 |      3.2766 |      3.3769 |     0.016611 |         none |  exponential |   2.2916e+12 |        false |
|    4 |      12 | Accept |      3.9117 |      2211.2 |      3.2766 |      3.3239 |   0.00017071 |         none |     matern32 |   6.8627e+12 |        false |
|    5 |      12 | Accept |      3.3091 |      7882.1 |      3.2766 |      3.3193 |   0.00018664 |     constant | rationalquad |   1.4248e+12 |         true |
|    6 |      12 | Accept |      5.9163 |      1972.3 |      3.2766 |      3.3267 |   0.00023413 |     constant |  exponential |   5.0875e+12 |        false |
|    7 |      12 | Accept |      3.4199 |      2183.3 |      3.2766 |      3.3827 |   0.00010395 |     constant |     matern32 |   7.0144e+12 |        false |
|    8 |      12 | Accept |      3.3082 |      945.69 |      3.2766 |       3.385 |   0.00018825 |     constant |     matern52 |   1.0358e+12 |         true |
|    9 |      12 | Accept |      5.6283 |      2228.6 |      3.2766 |      3.3894 |   0.00012752 |     constant |     matern52 |    1.461e+12 |        false |
|   10 |      12 | Accept |        3.31 |      887.18 |      3.2766 |      3.3953 |    0.0001319 |     constant |     matern32 |    3.198e+12 |         true |
|   11 |      12 | Accept |      3.3085 |      1881.1 |      3.2766 |      3.3911 |   0.00011447 |         none |     matern32 |   6.2851e+12 |         true |
|   12 |      12 | Accept |      3.3085 |      2199.5 |      3.2766 |      3.3923 |   0.00013309 |         none |     matern52 |   3.9563e+12 |         true |
|   13 |      12 | Accept |      4.1816 |       21649 |      3.2766 |      3.3973 |   0.00011066 |     constant | rationalquad |   4.4833e+12 |        false |
|   14 |      12 | Accept |      3.3085 |      2142.8 |      3.2766 |      3.3986 |   0.00018207 |         none | rationalquad |   2.0186e+12 |         true |
|   15 |      12 | Error  |         NaN |       15660 |      3.2766 |      3.3986 |   0.00012738 |         none |  exponential |   4.7724e+12 |         true |
|   16 |      12 | Accept |      3.7917 |      3307.2 |      3.2766 |       3.403 |   0.00016013 |         none | rationalquad |    2.867e+12 |        false |
|   17 |      12 | Accept |      3.3085 |      1549.9 |      3.2766 |      3.3765 |   0.00017491 |         none | squaredexpon |   2.2298e+12 |         true |
|   18 |      12 | Accept |      3.3083 |      891.26 |      3.2766 |      3.3818 |   0.00025913 |     constant | squaredexpon |   1.4442e+12 |         true |
|   19 |      12 | Best   |      1.4425 |      6236.9 |      1.4425 |      1.4444 |   0.00011586 |       linear |     matern52 |   4.2484e+12 |         true |
|   20 |      12 | Accept |      3.3491 |      2081.3 |      1.4425 |      1.4484 |   0.00016408 |         none | squaredexpon |   1.8676e+12 |        false |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 31809.0076 seconds.
Total objective function evaluation time: 80908.1773

Best observed feasible point:
      Sigma       BasisFunction    KernelFunction    KernelScale    Standardize
    __________    _____________    ______________    ___________    ___________

    0.00011586       linear           matern52       4.2484e+12        true    

Observed objective function value = 1.4425
Estimated objective function value = 1.4484
Function evaluation time = 6236.9487

Best estimated feasible point (according to models):
      Sigma       BasisFunction    KernelFunction    KernelScale    Standardize
    __________    _____________    ______________    ___________    ___________

    0.00011586       linear           matern52       4.2484e+12        true    

Estimated objective function value = 1.4484
Estimated function evaluation time = 2278.3538

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 90)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 31881.053982 seconds.
Train the super learner error model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      12 | Best   |      9.1402 |      651.69 |      9.1402 |      9.1402 |        834.9 |         none | squaredexpon |   2.7943e+12 |        false |
|    2 |      12 | Best   |      3.1564 |      737.42 |      3.1564 |      3.3943 |       621.66 |       linear |     matern52 |   6.2948e+11 |        false |
|    3 |      10 | Accept |      9.8336 |      859.34 |      1.3139 |      1.3152 |       108.99 |       linear | squaredexpon |   2.4239e+12 |        false |
|    4 |      10 | Accept |      9.2407 |      1001.4 |      1.3139 |      1.3152 |     0.028943 |       linear |     matern52 |   3.9154e+12 |         true |
|    5 |      10 | Best   |      1.3139 |      1017.3 |      1.3139 |      1.3152 |     0.004931 |         none |     matern32 |    6.474e+12 |        false |
|    6 |      12 | Best   |     0.54624 |      725.72 |     0.54624 |     0.55773 |       6.6228 |       linear |     matern52 |   1.6735e+11 |        false |
|    7 |      12 | Accept |     0.96681 |      768.43 |     0.54624 |     0.54737 |   0.00015022 |         none |     matern32 |   5.3767e+12 |        false |
|    8 |      12 | Accept |      9.1402 |      702.49 |     0.54624 |     0.54736 |       230.48 |         none |     matern32 |   7.1935e+12 |        false |
|    9 |      12 | Accept |      9.1402 |      2567.2 |     0.54624 |     0.54742 |        178.5 |         none |     matern32 |   2.7984e+11 |         true |
|   10 |      12 | Accept |     0.98439 |      1311.8 |     0.54624 |     0.54742 |    0.0051102 |         none |     matern32 |   8.9634e+11 |        false |
|   11 |      11 | Accept |      2.5112 |      1639.7 |     0.54624 |     0.54756 |     0.033989 |       linear |     matern52 |    4.128e+10 |        false |
|   12 |      11 | Accept |      5.3436 |      934.83 |     0.54624 |     0.54756 |       1.5782 |       linear |     matern52 |   7.7673e+09 |        false |
|   13 |      11 | Accept |      4.1521 |      2417.4 |     0.54624 |     0.54759 |    0.0001027 |       linear |     matern52 |   8.7573e+11 |        false |
|   14 |      11 | Accept |      9.1403 |      4759.8 |     0.54624 |      0.5478 |        15.92 |         none |     matern32 |   3.3929e+12 |         true |
|   15 |      12 | Accept |      5.3048 |      938.49 |     0.54624 |     0.54779 |   0.00061553 |         none |     matern32 |   7.2889e+09 |        false |
|   16 |      12 | Accept |       1.395 |      806.97 |     0.54624 |     0.54799 |   0.00011216 |         none |     matern32 |   9.0443e+11 |        false |
|   17 |      12 | Accept |      3.4518 |      945.85 |     0.54624 |      1.2217 |       4.5091 |       linear |     matern52 |   3.8883e+11 |        false |
|   18 |      12 | Accept |      7.9332 |      1173.3 |     0.54624 |      3.5098 |   0.00083925 |         none |     matern32 |   2.0959e+12 |        false |
|   19 |      12 | Accept |      5.9438 |      2273.2 |     0.54624 |       3.649 |      0.62538 |       linear |     matern52 |   3.2024e+11 |        false |
|   20 |      12 | Accept |       1.463 |       989.1 |     0.54624 |      3.6223 |    0.0011854 |         none |     matern52 |   1.0411e+12 |        false |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 7330.7452 seconds.
Total objective function evaluation time: 27221.3382

Best observed feasible point:
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    6.6228       linear           matern52       1.6735e+11        false   

Observed objective function value = 0.54624
Estimated objective function value = 3.8099
Function evaluation time = 725.7187

Best estimated feasible point (according to models):
      Sigma       BasisFunction    KernelFunction    KernelScale    Standardize
    __________    _____________    ______________    ___________    ___________

    0.00083925        none            matern32       2.0959e+12        false   

Estimated objective function value = 3.6223
Estimated function evaluation time = 1022.5785

Elapsed time is 7405.133972 seconds.
Elapsed time is 7405.154719 seconds.
Use the hyper-parameter optimized NN model for regression
Elapsed time is 0.176435 seconds.
Use the hyper-parameter optimized GPR model for regression
Elapsed time is 1.101504 seconds.
Use the hyper-parameter optimized Ensemble of Trees model for regression
Elapsed time is 0.074420 seconds.
Use the super learner model for regression
Elapsed time is 1.612857 seconds.
Use the error estimate to update the Super Learner Estimate
Elapsed time is 1.656422 seconds.
Use the hyper-parameter optimized NN model for regression
Elapsed time is 0.048702 seconds.
Use the hyper-parameter optimized GPR model for regression
Elapsed time is 0.095931 seconds.
Use the hyper-parameter optimized Ensemble of Trees model for regression
Elapsed time is 0.044449 seconds.
Use the super learner model for regression
Elapsed time is 0.109135 seconds.
Use the error estimate to update the Super Learner Estimate
Elapsed time is 0.136481 seconds.



combinedFigDaily = 

    "/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e06318cd1/UTD_Rsl_All_Daily_001e06318cd1_pm1_palas.png"


combinedFig = 

    "/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e06318cd1/UTD_Rsl_All_2020_12_18_09_49_43/UTD_Rsl_All_2020_12_18_09_49_43_001e06318cd1_pm1_palas.png"

    "Creating Folder @: '/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e06318cd1/UTD_Rsl_All_2020_12_18_09_49_43'"


plot3 = 

  Line with properties:

              Color: [0.9290 0.6940 0.1250]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x6881 double]
              YData: [1x6881 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot4 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot6 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot3 = 

  Line with properties:

              Color: [0.9290 0.6940 0.1250]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x6881 double]
              YData: [1x6881 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot4 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot6 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties

    "Saving Model Files for Node: 001e06318cd1 & target :PM_{1}"


modelsSaveNameDaily = 

    "/home/lhw150030/mintsData/modelsMats/UTDNodes/001e06318cd1/daily_Mdl_001e06318cd1_pm1_palas.mat"


modelsSaveName = 

    "/home/lhw150030/mintsData/modelsMats/UTDNodes/001e06318cd1/UTD_Rsl_All_2020_12_18_09_49_43/UTD_Rsl_All_2020_12_18_09_49_43_001e06318cd1_pm1_palas.mat"


resultsSaveName = 

    "/home/lhw150030/mintsData/modelsMats/UTDNodes/001e06318cd1/daily_Mdl_001e06318cd1_pm1_palas.csv"

    "Creating Folder @: '/home/lhw150030/mintsData/modelsMats/UTDNodes/001e06318cd1/UTD_Rsl_All_2020_12_18_09_49_43'"






trainingSaveNameDaily = 

    "/home/lhw150030/mintsData/trainingMats/UTDNodes/001e06318cd1/UTD_Rsl_All_Daily_001e06318cd1_pm1_palas.mat"


trainingSaveName = 

    "/home/lhw150030/mintsData/trainingMats/UTDNodes/001e06318cd1/UTD_Rsl_All_2020_12_18_09_49_43/UTD_Rsl_All_2020_12_18_09_49_43_001e06318cd1_pm1_palas.mat"

    "Creating Folder @: '/home/lhw150030/mintsData/trainingMats/UTDNodes/001e06318cd1/UTD_Rsl_All_2020_12_18_09_49_43'"



    "Gainin Data set for Node 001e06318cd1 with target output pm2_5_palas @ 19-Dec-2020 06:38:59"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 320 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 70 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 211 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 151 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 98 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 54 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 26 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 15 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 10 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 7 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 370 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 303 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 262 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 171 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        6825


ans =

        1204

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |      11 | Accept |      37.842 |      4.8331 |      33.698 |      33.993 |           41 |    0.0010012 |
|    2 |      11 | Best   |      33.698 |      4.7787 |      33.698 |      33.993 |           21 |     0.069646 |
|    3 |       8 | Accept |      117.99 |       5.238 |      29.486 |      48.381 |           77 |    0.0028038 |
|    4 |       8 | Accept |      74.228 |      5.2267 |      29.486 |      48.381 |           66 |      0.21611 |
|    5 |       8 | Accept |      71.602 |      4.8455 |      29.486 |      48.381 |           76 |    0.0020623 |
|    6 |       8 | Best   |      29.486 |      5.5123 |      29.486 |      48.381 |           93 |      0.69295 |
|    7 |      12 | Accept |      48.607 |     0.55284 |      29.486 |      47.232 |            6 |     0.072985 |
|    8 |       8 | Accept |      239.83 |     0.78869 |      23.216 |      68.555 |           95 |      0.97455 |
|    9 |       8 | Best   |      23.216 |     0.75764 |      23.216 |      68.555 |           74 |      0.66562 |
|   10 |       8 | Accept |      35.681 |     0.68841 |      23.216 |      68.555 |           42 |      0.21477 |
|   11 |       8 | Accept |      33.677 |     0.67556 |      23.216 |      68.555 |           52 |     0.001574 |
|   12 |       8 | Accept |      76.819 |     0.84661 |      23.216 |      68.555 |           72 |     0.069178 |
|   13 |      11 | Accept |       22.99 |      13.044 |      8.3954 |      61.004 |           33 |     0.032288 |
|   14 |      11 | Best   |      8.3954 |     0.27766 |      8.3954 |      61.004 |           22 |      0.09334 |
|   15 |       6 | Accept |       27.95 |      0.5159 |      8.3954 |      27.741 |            5 |    0.0010039 |
|   16 |       6 | Accept |      9.0502 |     0.72635 |      8.3954 |      27.741 |           30 |    0.0087257 |
|   17 |       6 | Accept |      14.397 |      15.752 |      8.3954 |      27.741 |           14 |     0.017934 |
|   18 |       6 | Accept |      71.128 |     0.76806 |      8.3954 |      27.741 |           76 |    0.0052153 |
|   19 |       6 | Accept |      26.196 |      2.4096 |      8.3954 |      27.741 |           21 |     0.061891 |
|   20 |       6 | Accept |      92.808 |     0.74352 |      8.3954 |      27.741 |           73 |       0.4811 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       8 | Accept |      159.11 |      16.326 |      8.3954 |      29.319 |           84 |     0.074759 |
|   22 |       8 | Accept |      46.147 |       15.81 |      8.3954 |      29.319 |           34 |     0.005291 |
|   23 |       8 | Accept |      59.477 |      16.197 |      8.3954 |      29.319 |           33 |      0.25386 |
|   24 |       8 | Accept |      39.908 |       15.27 |      8.3954 |      29.319 |           68 |      0.97325 |
|   25 |       8 | Accept |      15.049 |     0.29895 |      8.3954 |      29.319 |           43 |      0.98659 |
|   26 |       6 | Accept |      14.123 |      1.3153 |      8.3954 |       29.43 |           26 |    0.0010015 |
|   27 |       6 | Accept |      34.215 |      1.3093 |      8.3954 |       29.43 |           25 |     0.087633 |
|   28 |       6 | Accept |       37.53 |     0.25166 |      8.3954 |       29.43 |           63 |      0.22798 |
|   29 |       6 | Accept |      80.674 |     0.30833 |      8.3954 |       29.43 |           52 |      0.33544 |
|   30 |       6 | Accept |      105.16 |     0.33197 |      8.3954 |       29.43 |           78 |     0.012959 |
|   31 |       6 | Accept |       29.38 |      1.3145 |      8.3954 |       29.43 |           86 |      0.00304 |
|   32 |       6 | Accept |        16.6 |     0.32874 |      8.3954 |       29.43 |           64 |      0.63575 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 32
Total elapsed time: 20.2154 seconds.
Total objective function evaluation time: 138.0423

Best observed feasible point:
    hiddenLayerSize      lr   
    _______________    _______

          22           0.09334

Observed objective function value = 8.3954
Estimated objective function value = 29.1537
Function evaluation time = 0.27766

Best estimated feasible point (according to models):
    hiddenLayerSize       lr    
    _______________    _________

          26           0.0010015

Estimated objective function value = 29.4297
Estimated function evaluation time = 1.6999


T =

  1x2 table

    hiddenLayerSize       lr    
    _______________    _________

          26           0.0010015

Elapsed time is 93.218586 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      12 | Best   |      16.675 |      845.76 |      16.675 |      16.675 |      0.71984 |       linear |     matern32 |   2.9345e+12 |         true |
|    2 |      12 | Best   |      4.0525 |      944.09 |      4.0525 |      4.5544 |       5.6869 |     constant |     matern52 |   8.3526e+11 |         true |
|    3 |      12 | Accept |       15.03 |      1236.1 |      4.0525 |      4.5321 |       7.7882 |       linear | rationalquad |   1.5724e+11 |        false |
|    4 |      12 | Best   |      4.0522 |        2006 |      4.0522 |      4.0571 |     0.010424 |         none |     matern52 |    1.453e+12 |         true |
|    5 |      12 | Accept |      4.0523 |      923.36 |      4.0522 |      4.0528 |      0.11957 |     constant |     matern52 |   3.0062e+12 |         true |
|    6 |      12 | Accept |      4.0527 |      853.19 |      4.0522 |      4.0527 |        59.89 |     constant |     matern52 |   2.6527e+12 |         true |
|    7 |      12 | Accept |      4.0522 |      1732.7 |      4.0522 |      4.0527 |    0.0034026 |         none |     matern32 |   5.0126e+11 |         true |
|    8 |      12 | Accept |      4.0526 |      554.64 |      4.0522 |      4.0526 |       72.523 |         none |     matern52 |   7.3108e+09 |         true |
|    9 |      12 | Best   |      4.0519 |      1277.8 |      4.0519 |      4.0526 |       1.4415 |     constant | rationalquad |   2.0377e+12 |         true |
|   10 |      12 | Accept |      4.1189 |      2019.5 |      4.0519 |      4.0526 |      0.39436 |     constant |     matern52 |   1.8808e+12 |        false |
|   11 |      12 | Accept |      4.0522 |      1687.9 |      4.0519 |      4.0526 |   0.00025088 |         none | rationalquad |   2.0097e+12 |         true |
|   12 |      12 | Accept |      4.0525 |      4880.5 |      4.0519 |      4.0526 |       1.5995 |     constant | squaredexpon |   2.6192e+12 |         true |
|   13 |      12 | Accept |      9.2139 |      2142.6 |      4.0519 |      4.0526 |      0.40067 |         none |     matern52 |   1.3061e+11 |        false |
|   14 |      12 | Accept |      4.0522 |      858.47 |      4.0519 |      4.0526 |    0.0046894 |         none | squaredexpon |   1.9717e+12 |         true |
|   15 |      12 | Accept |      4.0525 |        6168 |      4.0519 |      4.0526 |       36.842 |     constant |     matern32 |   6.8208e+12 |         true |
|   16 |      12 | Accept |      6.8745 |      1819.4 |      4.0519 |      4.0526 |     0.051648 |     constant |     matern32 |   1.3446e+12 |        false |
|   17 |      12 | Accept |      4.2846 |      2719.3 |      4.0519 |      4.0526 |    0.0043287 |     constant | rationalquad |   3.2879e+12 |        false |
|   18 |      12 | Best   |      1.7104 |        2204 |      1.7104 |      1.7108 |     0.057525 |         none |  exponential |   4.4745e+11 |         true |
|   19 |      12 | Accept |      15.847 |      905.25 |      1.7104 |      1.7109 |    0.0026365 |       linear | squaredexpon |   7.1901e+10 |         true |
|   20 |      12 | Accept |      4.1558 |      1857.3 |      1.7104 |      1.7109 |     0.017732 |         none | squaredexpon |   2.3186e+12 |        false |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      12 | Accept |      11.293 |      1140.7 |      1.7104 |      1.7109 |    0.0029678 |         none |  exponential |   4.0778e+11 |        false |
|   22 |      12 | Accept |      4.0531 |      6268.5 |      1.7104 |      1.7109 |   0.00041214 |     constant |  exponential |   5.9412e+12 |         true |
|   23 |      12 | Accept |       4.042 |       13148 |      1.7104 |      1.7109 |       0.1311 |     constant | squaredexpon |   2.7511e+12 |        false |
|   24 |      12 | Accept |      10.491 |       18608 |      1.7104 |      1.7109 |      0.71194 |         none | rationalquad |   1.1595e+10 |        false |
