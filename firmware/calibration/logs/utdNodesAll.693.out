Running calibration scripts for UTD Node: 12
Running on host: compute-1-2-4

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
              R2020a Update 1 (9.8.0.1359463) 64-bit (glnxa64)
                               April 9, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 


    "---------------------MINTS---------------------"

18-Dec-2020 09:47:10

mintsDefinitions = 

  struct with fields:

                dataFolder: '/home/lhw150030/mintsData'
               poolWorkers: 16
                  timeSpan: 30
                  airmarID: '001e0610c0e4'
             binsPerColumn: 500
              numberPerBin: 2
                    pValid: 0.1500
                   nodeIDs: {1x16 cell}
               inputStack1: {1x9 cell}
         mintsInputsStack1: {1x35 cell}
    mintsInputLabelsStack1: {1x35 cell}
               inputStack2: {1x11 cell}
         mintsInputsStack2: {1x35 cell}
    mintsInputLabelsStack2: {1x35 cell}
               inputStack3: {1x10 cell}
         mintsInputsStack3: {1x38 cell}
    mintsInputLabelsStack3: {1x38 cell}
              mintsTargets: {1x10 cell}
         mintsTargetLabels: {1x10 cell}
                     units: {1x10 cell}
               instruments: {1x10 cell}

Starting parallel pool (parpool) using the 'local' profile ...
Connected to the parallel pool (number of workers: 16).

ans = 

 ProcessPool with properties: 

            Connected: true
           NumWorkers: 16
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


airmarFolder = 

    "/home/lhw150030/mintsData/referenceMats/airmar"

UTD_Rsl_All_2020_12_18_09_47_35


UTD_Rsl_All_Daily


Super Learner All Inputs




    "Data Folder Located @:/home/lhw150030/mintsData"

    "Raw Data Located @: /home/lhw150030/mintsData"

    "Raw DotMat Data Located @ :/home/lhw150030/mintsData/rawMats"

    "UTD Nodes DotMat Data Located @ :/home/lhw150030/mintsData/rawMats/UTDNodes"

    "Reference Data Located @: /home/lhw150030/mintsData/reference"

    "Reference DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats"

    "Palas Raw Data Located @ :/home/lhw150030/mintsData/reference/palasStream"

    "Palas DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats/palas"

    "Car GPS Files Located @ :/home/lhw150030/mintsData/referenceMats/carMintsGPS"

    "Loading Palas Files"

    "Loading GPS Files"

    "Loading Airmar Files"

    "Aligning GPS data with Palas Data"

    "WSTC Palas Data"

    "Palas With Airmar"

    "Analysis"

    "Save merged data for calibration: 001e063239e6"



    "Creating Training Data Sets for Node: 001e063239e6"



    "Gainin Data set for Node 001e063239e6 with target output pm1_palas @ 18-Dec-2020 09:47:44"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 328 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 75 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 318 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 81 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 59 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 38 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 19 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 8 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 473 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 320 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 189 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 37 and choosing a representative sample. Choosing 149 bins for this column. With 2 members per bin.
Going through column 38 and choosing a representative sample. Choosing 290 bins for this column. With 2 members per bin.
Going through column 39 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

       11512


ans =

        2031

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |       1 | Accept |      35.417 |      2.7948 |      6.2535 |      5.8855 |           10 |      0.41671 |
|    2 |       1 | Accept |      9.8677 |      2.8171 |      6.2535 |      5.8855 |           18 |    0.0095933 |
|    3 |       1 | Accept |      25.311 |      2.9147 |      6.2535 |      5.8855 |           67 |     0.002461 |
|    4 |       1 | Accept |      85.375 |      3.0032 |      6.2535 |      5.8855 |           68 |      0.29925 |
|    5 |       1 | Best   |      6.2535 |      2.7532 |      6.2535 |      5.8855 |            7 |      0.10214 |
|    6 |       1 | Accept |      33.062 |      2.8116 |      6.2535 |      5.8855 |           48 |     0.017989 |
|    7 |       1 | Accept |      32.743 |      2.7951 |      6.2535 |      5.8855 |           40 |      0.54045 |
|    8 |       1 | Accept |      55.763 |      2.8653 |      6.2535 |      5.8855 |           78 |      0.15137 |
|    9 |       1 | Accept |      44.487 |      2.8513 |      6.2535 |      5.8855 |           50 |     0.013172 |
|   10 |       1 | Accept |      12.215 |      2.7323 |      6.2535 |      5.8855 |           19 |      0.12825 |
|   11 |       1 | Accept |      6.2712 |      2.7258 |      6.2535 |      5.8855 |            9 |     0.089015 |
|   12 |       1 | Accept |      63.084 |      2.8409 |      6.2535 |      5.8855 |           80 |     0.026947 |
|   13 |       1 | Accept |      30.114 |      2.7909 |      6.2535 |      5.8855 |           46 |      0.92163 |
|   14 |       1 | Accept |      14.821 |      2.7515 |      6.2535 |      5.8855 |           27 |    0.0055398 |
|   15 |       1 | Accept |      53.226 |      2.8229 |      6.2535 |      5.8855 |           67 |      0.01349 |
|   16 |       1 | Accept |      7.6704 |      2.7214 |      6.2535 |      5.8855 |           21 |      0.12232 |
|   17 |       2 | Accept |      41.303 |      0.6231 |      6.2535 |      19.975 |           22 |     0.044967 |
|   18 |       2 | Accept |      8.6444 |     0.65791 |      6.2535 |      19.975 |           25 |      0.21444 |
|   19 |       2 | Accept |      27.911 |     0.62228 |      6.2535 |      19.975 |           53 |      0.13607 |
|   20 |       2 | Accept |      53.495 |     0.64134 |      6.2535 |      19.975 |           51 |    0.0084158 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       2 | Accept |      81.642 |     0.65259 |      6.2535 |      19.975 |           75 |     0.011299 |
|   22 |       2 | Accept |      51.357 |     0.57315 |      6.2535 |      19.975 |           44 |     0.065094 |
|   23 |       2 | Accept |      23.324 |     0.61188 |      6.2535 |      19.975 |           38 |     0.015166 |
|   24 |       2 | Accept |      11.624 |     0.58089 |      6.2535 |      19.975 |           22 |      0.00296 |
|   25 |       2 | Accept |      66.732 |     0.61518 |      6.2535 |      19.975 |           40 |     0.010446 |
|   26 |       2 | Accept |      37.882 |     0.56301 |      6.2535 |      19.975 |           12 |       0.7505 |
|   27 |       2 | Accept |      14.771 |     0.64449 |      6.2535 |      19.975 |           34 |     0.044492 |
|   28 |       2 | Accept |      18.019 |     0.65375 |      6.2535 |      19.975 |           60 |      0.69695 |
|   29 |       2 | Accept |      33.166 |     0.76658 |      6.2535 |      19.975 |           89 |     0.008059 |
|   30 |       2 | Accept |      56.763 |      0.6989 |      6.2535 |      19.975 |           93 |    0.0011109 |
|   31 |       2 | Accept |       20.11 |     0.55582 |      6.2535 |      19.975 |           16 |     0.081573 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 31
Total elapsed time: 14.1941 seconds.
Total objective function evaluation time: 54.4528

Best observed feasible point:
    hiddenLayerSize      lr   
    _______________    _______

           7           0.10214

Observed objective function value = 6.2535
Estimated objective function value = 19.8291
Function evaluation time = 2.7532

Best estimated feasible point (according to models):
    hiddenLayerSize       lr    
    _______________    _________

          18           0.0095933

Estimated objective function value = 19.9753
Estimated function evaluation time = 1.3618


T =

  1x2 table

    hiddenLayerSize       lr    
    _______________    _________

          18           0.0095933

Elapsed time is 20.493188 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Error  |         NaN |      248.56 |         NaN |         NaN |    0.0023764 |       linear |  exponential |   6.7402e+10 |        false |
|    2 |      16 | Accept |      7.1296 |      288.77 |         NaN |      7.1296 |        9.227 | pureQuadrati |     matern32 |     5.25e+10 |         true |
|    3 |      16 | Accept |      3.0092 |      400.56 |         NaN |      5.0694 |     0.080063 |         none |     matern32 |   9.6006e+11 |         true |
|    4 |      16 | Error  |         NaN |      428.87 |         NaN |      5.0694 |   0.00016531 |         none |     matern32 |   3.3499e+12 |        false |
|    5 |      16 | Accept |      3.0092 |      568.09 |      3.0092 |       3.011 |   0.00014321 |         none |     matern52 |   1.2327e+13 |         true |
|    6 |      16 | Accept |       3.011 |      294.36 |      3.0092 |       3.011 |      0.10788 |     constant |     matern52 |   1.3112e+12 |         true |
|    7 |      16 | Best   |      1.0483 |      621.18 |      1.0483 |       1.086 |    0.0065778 |     constant |  exponential |   2.5067e+11 |         true |
|    8 |      16 | Error  |         NaN |      676.05 |      1.0483 |       1.086 |   0.00046408 |       linear |     matern32 |   4.8229e+10 |        false |
|    9 |      16 | Accept |      2.4077 |      682.11 |      1.0483 |      1.0999 |       2.7078 |       linear |     matern52 |   8.1851e+12 |        false |
|   10 |      16 | Accept |      6.7949 |      278.09 |      1.0483 |      1.0847 |       11.017 | pureQuadrati |     matern32 |   5.3355e+10 |         true |
|   11 |      16 | Accept |      9.5323 |      289.59 |      1.0483 |      1.0486 |       6.5996 | pureQuadrati |     matern32 |   5.9449e+10 |         true |
|   12 |      16 | Error  |         NaN |       747.3 |      1.0483 |      1.0486 |   0.00013233 | pureQuadrati | rationalquad |   1.0338e+11 |        false |
|   13 |      16 | Accept |      2.8675 |      835.39 |      1.0483 |      1.0486 |       2.9978 |     constant | rationalquad |   8.0828e+11 |        false |
|   14 |      16 | Accept |       9.225 |      628.57 |      1.0483 |      1.0486 |     0.011151 |       linear |     matern32 |   1.8305e+11 |         true |
|   15 |      16 | Accept |      3.0093 |      272.28 |      1.0483 |      2.3603 |       9.7965 |     constant |  exponential |   2.0214e+13 |         true |
|   16 |      16 | Accept |        3.01 |      289.68 |      1.0483 |      2.5405 |       42.526 |     constant |  exponential |   2.0674e+10 |         true |
|   17 |      16 | Accept |      6.5677 |      555.66 |      1.0483 |      2.5728 |   0.00018243 |         none |     matern52 |    1.275e+13 |        false |
|   18 |      16 | Accept |      3.0111 |      596.92 |      1.0483 |      2.5702 |     0.030996 |     constant |     matern32 |    1.169e+12 |         true |
|   19 |      16 | Accept |      1.5141 |      545.32 |      1.0483 |      2.2963 |   0.00010569 |     constant |  exponential |   1.0914e+12 |         true |
|   20 |      16 | Accept |      1.0595 |      570.26 |      1.0483 |        1.52 |    0.0036843 |     constant |  exponential |   2.9548e+11 |         true |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      16 | Best   |      1.0237 |      641.12 |      1.0237 |      1.2727 |   0.00014737 |     constant |  exponential |   3.5479e+10 |         true |
|   22 |      16 | Accept |      1.0594 |      615.76 |      1.0237 |      1.2747 |     0.014865 |     constant |  exponential |   2.7542e+11 |         true |
|   23 |      16 | Error  |         NaN |      461.16 |      1.0237 |      1.2747 |   0.00011713 |       linear |     matern52 |   5.5037e+10 |        false |
|   24 |      16 | Accept |      1.0541 |      618.55 |      1.0237 |      1.2055 |    0.0044279 |     constant |  exponential |   2.2014e+11 |         true |
|   25 |      16 | Accept |       1.046 |       595.1 |      1.0237 |      1.1494 |    0.0093037 |     constant |  exponential |   1.9754e+11 |         true |
|   26 |      16 | Accept |      3.0094 |      180.02 |      1.0237 |      1.1923 |       43.877 |         none |     matern52 |   1.7888e+13 |         true |
|   27 |      16 | Accept |      3.0093 |      302.47 |      1.0237 |      1.1883 |       42.867 |     constant |     matern52 |   7.0106e+10 |        false |
|   28 |      16 | Accept |      10.183 |      613.85 |      1.0237 |      1.0596 |    0.0052604 |       linear |     matern52 |   1.9732e+13 |        false |
|   29 |      16 | Accept |       9.127 |      283.25 |      1.0237 |      1.0599 |       43.881 |       linear |     matern52 |   3.8102e+11 |         true |
|   30 |      16 | Accept |      3.0094 |       208.9 |      1.0237 |      1.0599 |       42.215 |         none |  exponential |   4.3043e+11 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 1763.8437 seconds.
Total objective function evaluation time: 14337.8005

Best observed feasible point:
      Sigma       BasisFunction    KernelFunction    KernelScale    Standardize
    __________    _____________    ______________    ___________    ___________

    0.00014737      constant        exponential      3.5479e+10        true    

Observed objective function value = 1.0237
Estimated objective function value = 1.0938
Function evaluation time = 641.1248

Best estimated feasible point (according to models):
      Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    _________    _____________    ______________    ___________    ___________

    0.0044279      constant        exponential      2.2014e+11        true    

Estimated objective function value = 1.0599
Estimated function evaluation time = 604.4565

Elapsed time is 1824.947786 seconds.
Take a copy of the best attributes
Now use these optimum settings to do an exact GPR fit
Elapsed time is 27.702398 seconds.
Train a hyper-parameter optimized Ensemble of Trees model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|    1 |      16 | Best   |      2.5345 |      1.9608 |      2.5345 |      2.5345 |          Bag |           12 |            - |           43 |            1 |           14 |
|    2 |      16 | Accept |      3.4864 |      2.7822 |      2.5345 |      3.0094 |      LSBoost |           36 |    0.0012919 |           12 |            1 |            2 |
|    3 |      13 | Accept |      2.3226 |      7.7459 |      2.0807 |      2.0808 |          Bag |           56 |            - |         1124 |         5347 |           15 |
|    4 |      13 | Accept |      3.4559 |      7.4713 |      2.0807 |      2.0808 |      LSBoost |           42 |    0.0010622 |           29 |          972 |            4 |
|    5 |      13 | Best   |      2.0807 |      6.6812 |      2.0807 |      2.0808 |      LSBoost |           59 |      0.91053 |           65 |            1 |           19 |
|    6 |      13 | Accept |      3.0091 |      5.3736 |      2.0807 |      2.0808 |          Bag |           80 |            - |         5289 |          217 |           27 |
|    7 |      14 | Best   |      1.3434 |      13.019 |      1.3434 |      1.3436 |          Bag |           21 |            - |          153 |        11187 |           37 |
|    8 |      14 | Accept |      1.6355 |      2.1524 |      1.3434 |      1.3436 |      LSBoost |           13 |      0.90726 |            3 |            3 |           24 |
|    9 |      13 | Accept |      1.2119 |       14.85 |      1.1856 |      1.1857 |          Bag |           76 |            - |            5 |         1189 |            3 |
|   10 |      13 | Best   |      1.1856 |      6.6854 |      1.1856 |      1.1857 |      LSBoost |           11 |      0.88317 |            6 |          305 |           14 |
|   11 |      12 | Accept |      2.8949 |      19.959 |      1.1856 |      1.1857 |      LSBoost |           72 |     0.005444 |          128 |          272 |           15 |
|   12 |      12 | Accept |      2.8378 |      12.594 |      1.1856 |      1.1857 |          Bag |          231 |            - |            7 |            1 |            1 |
|   13 |      11 | Accept |      2.6239 |      25.524 |      1.1856 |      1.1857 |      LSBoost |          305 |    0.0039926 |         2485 |         1682 |           28 |
|   14 |      11 | Accept |      2.3407 |     0.71173 |      1.1856 |      1.1857 |      LSBoost |           10 |      0.89064 |           64 |            1 |            7 |
|   15 |      16 | Accept |      1.6048 |      16.606 |      1.1856 |      1.1857 |          Bag |           38 |            - |            1 |            9 |           38 |
|   16 |      15 | Accept |     0.96168 |      40.177 |     0.69769 |     0.69754 |      LSBoost |          102 |     0.040609 |           97 |           29 |           25 |
|   17 |      15 | Best   |     0.69769 |      12.013 |     0.69769 |     0.69754 |          Bag |           10 |            - |            6 |        11246 |           35 |
|   18 |      15 | Accept |     0.89925 |      8.5524 |     0.69769 |      0.6975 |      LSBoost |           10 |      0.43907 |           99 |          490 |           36 |
|   19 |      13 | Accept |        2.48 |      51.491 |     0.69769 |     0.69763 |          Bag |          364 |            - |           83 |            1 |           35 |
|   20 |      13 | Accept |      3.2583 |      15.391 |     0.69769 |     0.69763 |      LSBoost |          222 |    0.0012712 |         2073 |            3 |           10 |
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|   21 |      13 | Accept |      3.0091 |      8.8048 |     0.69769 |     0.69763 |      LSBoost |          198 |      0.83108 |         4999 |        11338 |            3 |
|   22 |      13 | Accept |     0.85856 |      57.881 |     0.69769 |     0.69278 |          Bag |          201 |            - |            5 |         3934 |            5 |
|   23 |      13 | Accept |        1.95 |      58.397 |     0.69769 |     0.69278 |      LSBoost |          270 |    0.0068919 |           52 |            4 |           24 |
|   24 |      16 | Accept |      1.4252 |      57.637 |     0.69769 |      0.6976 |      LSBoost |          480 |      0.95718 |           14 |            3 |           14 |
|   25 |      16 | Accept |      1.1341 |      11.376 |     0.69769 |     0.69763 |      LSBoost |           15 |      0.12282 |           47 |           68 |           38 |
|   26 |      15 | Accept |       1.501 |      23.239 |     0.69769 |     0.69771 |      LSBoost |           16 |     0.077352 |            2 |        10998 |           37 |
|   27 |      15 | Accept |     0.70283 |      20.453 |     0.69769 |     0.69771 |          Bag |           23 |            - |            1 |        11337 |           21 |
|   28 |      15 | Accept |        1.05 |      90.887 |     0.69769 |     0.69771 |      LSBoost |          245 |     0.024843 |          269 |          129 |           22 |
|   29 |      16 | Accept |      3.2117 |      1.3742 |     0.69769 |     0.69769 |      LSBoost |           14 |     0.019369 |         2654 |            1 |           35 |
|   30 |      15 | Accept |      1.8699 |      70.524 |     0.69769 |     0.69768 |          Bag |          473 |            - |          342 |         6324 |            8 |
|   31 |      15 | Accept |      1.5988 |      38.737 |     0.69769 |     0.69768 |      LSBoost |          159 |     0.069843 |           32 |            2 |           38 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 31
Total elapsed time: 111.9636 seconds.
Total objective function evaluation time: 711.0504

Best observed feasible point:
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             10               NaN            6            11246                 35         

Observed objective function value = 0.69769
Estimated objective function value = 0.69768
Function evaluation time = 12.013

Best estimated feasible point (according to models):
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             10               NaN            6            11246                 35         

Estimated objective function value = 0.69768
Estimated function evaluation time = 12.1132

Elapsed time is 115.058145 seconds.
Train the super learner model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      2.9732 |      186.96 |      2.9732 |      2.9732 |       17.963 |         none |     matern32 |   7.3085e+10 |        false |
|    2 |      16 | Accept |      3.0093 |      267.74 |      2.9732 |      2.9747 |     0.057771 |     constant | squaredexpon |   3.3579e+10 |         true |
|    3 |      16 | Best   |   0.0089622 |      281.58 |   0.0089622 |     0.13016 |       2.8401 | pureQuadrati | squaredexpon |   7.5277e+11 |         true |
|    4 |      16 | Accept |      3.0099 |       287.4 |   0.0089622 |      0.1314 |       23.363 |     constant |  exponential |   2.2439e+10 |         true |
|    5 |      16 | Accept |    0.022142 |      279.86 |   0.0089622 |    0.015731 |       28.424 | pureQuadrati | squaredexpon |   3.1928e+12 |         true |
|    6 |      16 | Accept |    0.046349 |      282.31 |   0.0089622 |    0.025979 |       13.291 | pureQuadrati | squaredexpon |   2.0459e+11 |         true |
|    7 |      16 | Best   |   0.0042504 |      582.77 |   0.0042504 |   0.0045535 |    0.0050688 |       linear |  exponential |   1.9216e+13 |         true |
|    8 |      16 | Accept |    0.015023 |      600.89 |   0.0042504 |   0.0044507 |    0.0019081 | pureQuadrati | squaredexpon |    3.493e+12 |         true |
|    9 |      16 | Accept |   0.0091597 |      618.38 |   0.0042504 |    0.023164 |   0.00011996 |       linear |     matern52 |   1.1766e+12 |         true |
|   10 |      16 | Error  |         NaN |      487.51 |   0.0042504 |    0.023164 |       1.1625 |         none |     matern32 |   4.3882e+11 |        false |
|   11 |      16 | Error  |         NaN |      835.21 |   0.0042504 |    0.023164 |      0.93769 | pureQuadrati | rationalquad |   1.9021e+11 |        false |
|   12 |      16 | Best   |   0.0019331 |      598.32 |   0.0019331 |   0.0020649 |   0.00035398 |       linear | squaredexpon |   2.0088e+12 |         true |
|   13 |      16 | Accept |      3.8809 |      601.08 |   0.0019331 |   0.0020956 |    0.0001081 | pureQuadrati | squaredexpon |   1.5685e+13 |        false |
|   14 |      16 | Accept |    0.053617 |      604.21 |   0.0019331 |   0.0020736 |    0.0051861 | pureQuadrati |  exponential |   1.0382e+12 |         true |
|   15 |      16 | Accept |     0.02469 |      600.71 |   0.0019331 |   0.0020718 |   0.00070544 |       linear |     matern32 |   5.2947e+12 |         true |
|   16 |      16 | Best   |  3.1473e-05 |      281.76 |  3.1473e-05 |  0.00016256 |   0.00012512 |       linear | squaredexpon |   1.8899e+13 |        false |
|   17 |      16 | Best   |  3.1365e-05 |      291.61 |  3.1365e-05 |  0.00015625 |    0.0047498 |       linear |  exponential |   1.8846e+13 |        false |
|   18 |      16 | Accept |     0.01289 |      817.17 |  3.1365e-05 |  0.00015185 |   0.00011053 |       linear | rationalquad |   1.1938e+13 |         true |
|   19 |      16 | Accept |    0.019893 |      834.92 |  3.1365e-05 |  0.00014846 |    0.0001695 | pureQuadrati | rationalquad |   1.6893e+13 |         true |
|   20 |      16 | Accept |    0.030442 |      610.39 |  3.1365e-05 |  0.00014585 |    0.0057752 | pureQuadrati |     matern32 |   1.1241e+12 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 1807.7571 seconds.
Total objective function evaluation time: 9950.8089

Best observed feasible point:
      Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    _________    _____________    ______________    ___________    ___________

    0.0047498       linear         exponential      1.8846e+13        false   

Observed objective function value = 3.1365e-05
Estimated objective function value = 0.00014585
Function evaluation time = 291.6061

Best estimated feasible point (according to models):
      Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    _________    _____________    ______________    ___________    ___________

    0.0047498       linear         exponential      1.8846e+13        false   

Estimated objective function value = 0.00014585
Estimated function evaluation time = 291.681

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 90)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 1983.799518 seconds.
Train the super learner error model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |   3.121e-05 |       273.4 |   3.121e-05 |   3.121e-05 |    0.0025032 | pureQuadrati | squaredexpon |   3.9576e+11 |        false |
|    2 |      16 | Accept |   3.157e-05 |       296.3 |   3.121e-05 |    3.13e-05 |     0.050467 |       linear |     matern52 |   8.9418e+12 |        false |
|    3 |      16 | Accept |  3.1292e-05 |      303.97 |   3.121e-05 |  3.1393e-05 |     0.043588 |       linear |     matern52 |   2.0308e+13 |        false |
|    4 |      16 | Accept |  3.1215e-05 |      381.96 |   3.121e-05 |  3.1381e-05 |   0.00012773 |         none | rationalquad |   2.1936e+10 |         true |
|    5 |      16 | Best   |  3.1106e-05 |       472.3 |  3.1106e-05 |  3.1365e-05 |   0.00013598 |     constant |     matern52 |   8.4783e+11 |        false |
