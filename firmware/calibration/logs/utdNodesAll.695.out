Running calibration scripts for UTD Node: 14
Running on host: compute-1-2-6

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
              R2020a Update 1 (9.8.0.1359463) 64-bit (glnxa64)
                               April 9, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 


    "---------------------MINTS---------------------"

18-Dec-2020 09:47:16

mintsDefinitions = 

  struct with fields:

                dataFolder: '/home/lhw150030/mintsData'
               poolWorkers: 16
                  timeSpan: 30
                  airmarID: '001e0610c0e4'
             binsPerColumn: 500
              numberPerBin: 2
                    pValid: 0.1500
                   nodeIDs: {1x16 cell}
               inputStack1: {1x9 cell}
         mintsInputsStack1: {1x35 cell}
    mintsInputLabelsStack1: {1x35 cell}
               inputStack2: {1x11 cell}
         mintsInputsStack2: {1x35 cell}
    mintsInputLabelsStack2: {1x35 cell}
               inputStack3: {1x10 cell}
         mintsInputsStack3: {1x38 cell}
    mintsInputLabelsStack3: {1x38 cell}
              mintsTargets: {1x10 cell}
         mintsTargetLabels: {1x10 cell}
                     units: {1x10 cell}
               instruments: {1x10 cell}

Starting parallel pool (parpool) using the 'local' profile ...
Connected to the parallel pool (number of workers: 16).

ans = 

 ProcessPool with properties: 

            Connected: true
           NumWorkers: 16
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


airmarFolder = 

    "/home/lhw150030/mintsData/referenceMats/airmar"

UTD_Rsl_All_2020_12_18_09_47_42


UTD_Rsl_All_Daily


Super Learner All Inputs




    "Data Folder Located @:/home/lhw150030/mintsData"

    "Raw Data Located @: /home/lhw150030/mintsData"

    "Raw DotMat Data Located @ :/home/lhw150030/mintsData/rawMats"

    "UTD Nodes DotMat Data Located @ :/home/lhw150030/mintsData/rawMats/UTDNodes"

    "Reference Data Located @: /home/lhw150030/mintsData/reference"

    "Reference DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats"

    "Palas Raw Data Located @ :/home/lhw150030/mintsData/reference/palasStream"

    "Palas DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats/palas"

    "Car GPS Files Located @ :/home/lhw150030/mintsData/referenceMats/carMintsGPS"

    "Loading Palas Files"

    "Loading GPS Files"

    "Loading Airmar Files"

    "Aligning GPS data with Palas Data"

    "WSTC Palas Data"

    "Palas With Airmar"

    "Analysis"

    "Save merged data for calibration: 001e06318cee"



    "Creating Training Data Sets for Node: 001e06318cee"



    "Gainin Data set for Node 001e06318cee with target output pm1_palas @ 18-Dec-2020 09:47:51"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 298 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 73 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 254 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 125 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 95 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 64 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 37 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 26 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 17 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 11 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 8 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 5 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 5 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 164 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 259 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 282 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 167 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 37 and choosing a representative sample. Choosing 136 bins for this column. With 2 members per bin.
Going through column 38 and choosing a representative sample. Choosing 278 bins for this column. With 2 members per bin.
Going through column 39 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        9413


ans =

        1661

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |       1 | Best   |      5.9084 |      3.2159 |      5.9084 |       5.917 |           10 |    0.0013465 |
|    2 |       1 | Accept |      39.415 |      3.3361 |      5.9084 |       5.917 |           43 |    0.0093656 |
|    3 |       1 | Accept |      13.582 |      3.2266 |      5.9084 |       5.917 |           47 |      0.39448 |
|    4 |       1 | Accept |      73.848 |      3.3172 |      5.9084 |       5.917 |           88 |      0.13806 |
|    5 |       1 | Accept |      16.822 |      3.1139 |      5.9084 |       5.917 |           46 |      0.21606 |
|    6 |       1 | Accept |        8.92 |      3.1311 |      5.9084 |       5.917 |           25 |    0.0044113 |
|    7 |       1 | Accept |      34.384 |      3.2381 |      5.9084 |       5.917 |           80 |    0.0019008 |
|    8 |       1 | Accept |      15.192 |      3.1285 |      5.9084 |       5.917 |           12 |    0.0016149 |
|    9 |       1 | Accept |      26.185 |      3.2217 |      5.9084 |       5.917 |           79 |    0.0010336 |
|   10 |       1 | Accept |      6.7085 |      3.1011 |      5.9084 |       5.917 |           15 |      0.12432 |
|   11 |       1 | Accept |      48.283 |      3.2366 |      5.9084 |       5.917 |           91 |       0.3042 |
|   12 |       1 | Accept |      48.284 |      3.1255 |      5.9084 |       5.917 |           21 |      0.14062 |
|   13 |       1 | Accept |      13.753 |      3.1393 |      5.9084 |       5.917 |           31 |    0.0025476 |
|   14 |       1 | Accept |      30.933 |      2.9654 |      5.9084 |       5.917 |           21 |      0.61741 |
|   15 |       1 | Accept |      92.961 |      3.1809 |      5.9084 |       5.917 |           79 |     0.075108 |
|   16 |       1 | Accept |      14.877 |      3.0278 |      5.9084 |       5.917 |           36 |     0.043038 |
|   17 |       3 | Accept |      27.916 |     0.55701 |      5.9084 |      20.749 |            9 |      0.10804 |
|   18 |       3 | Accept |      26.659 |     0.57313 |      5.9084 |      20.749 |           15 |      0.28042 |
|   19 |       3 | Accept |      6.4669 |     0.54092 |      5.9084 |      20.749 |            6 |      0.10396 |
|   20 |       3 | Accept |      105.04 |     0.62174 |      5.9084 |      20.749 |           77 |    0.0021152 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       3 | Accept |      55.429 |     0.66808 |      5.9084 |      20.749 |           79 |     0.033851 |
|   22 |       3 | Accept |       19.25 |     0.64721 |      5.9084 |      20.749 |           51 |      0.87746 |
|   23 |       3 | Accept |      49.057 |     0.65557 |      5.9084 |      20.749 |           34 |    0.0013185 |
|   24 |       3 | Accept |      18.632 |     0.61668 |      5.9084 |      20.749 |           38 |     0.073391 |
|   25 |       3 | Accept |      18.412 |     0.61558 |      5.9084 |      20.749 |           37 |     0.034242 |
|   26 |       3 | Accept |      27.152 |     0.57586 |      5.9084 |      20.749 |           33 |     0.069095 |
|   27 |       3 | Accept |       74.62 |     0.68137 |      5.9084 |      20.749 |           97 |    0.0014802 |
|   28 |       3 | Accept |      35.523 |     0.58183 |      5.9084 |      20.749 |           28 |    0.0049272 |
|   29 |       3 | Accept |      15.211 |     0.62542 |      5.9084 |      20.749 |            9 |     0.042568 |
|   30 |       3 | Accept |      19.235 |     0.57455 |      5.9084 |      20.749 |           42 |      0.10589 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 14.9554 seconds.
Total objective function evaluation time: 59.2404

Best observed feasible point:
    hiddenLayerSize       lr    
    _______________    _________

          10           0.0013465

Observed objective function value = 5.9084
Estimated objective function value = 19.7196
Function evaluation time = 3.2159

Best estimated feasible point (according to models):
    hiddenLayerSize      lr   
    _______________    _______

          15           0.12432

Estimated objective function value = 20.7491
Estimated function evaluation time = 1.4665


T =

  1x2 table

    hiddenLayerSize      lr   
    _______________    _______

          15           0.12432

Elapsed time is 46.206320 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      3.1156 |      140.19 |      3.1156 |      3.1156 |       2.4378 | pureQuadrati | squaredexpon |   3.6396e+10 |        false |
|    2 |      16 | Accept |      3.1172 |       157.3 |      3.1156 |       3.116 |       2.8141 |         none |     matern32 |   7.1063e+11 |         true |
|    3 |      16 | Accept |      3.1678 |      248.61 |      3.1156 |      3.1323 |     0.053305 |       linear |     matern52 |   2.0314e+12 |         true |
|    4 |      16 | Accept |      3.1158 |      144.07 |      3.1156 |      3.1157 |       3.7972 | pureQuadrati | squaredexpon |   5.2579e+10 |        false |
|    5 |      16 | Accept |      3.1172 |      408.91 |      3.1156 |      3.1157 |     0.075029 |         none |     matern32 |   9.6368e+09 |         true |
|    6 |      16 | Accept |      3.7949 |      504.69 |      3.1156 |      3.1157 |   0.00090088 |         none |     matern52 |   6.7994e+11 |        false |
|    7 |      16 | Accept |      6.1095 |      236.39 |      3.1156 |      3.1157 |        6.412 | pureQuadrati | squaredexpon |   6.7541e+11 |         true |
|    8 |      16 | Accept |       3.223 |      250.91 |      3.1156 |      3.1157 |      0.10341 |       linear |     matern32 |   1.8378e+11 |         true |
|    9 |      16 | Error  |         NaN |      524.93 |      3.1156 |      3.1157 |      0.26979 | pureQuadrati | squaredexpon |   7.9042e+09 |        false |
|   10 |      16 | Accept |      6.1339 |      817.44 |      3.1156 |      3.1158 |      0.63342 |     constant | rationalquad |   1.2354e+10 |        false |
|   11 |      16 | Best   |      2.3544 |      734.04 |      2.3544 |      2.3545 |       1.0773 |       linear | rationalquad |   2.0991e+12 |        false |
|   12 |      16 | Accept |      3.1172 |      165.16 |      2.3544 |      2.3545 |      0.38446 |         none |  exponential |   2.5998e+11 |         true |
|   13 |      16 | Accept |      5.2935 |       520.2 |      2.3544 |      2.3545 |   0.00017359 |       linear | squaredexpon |   1.1601e+10 |        false |
|   14 |      16 | Accept |      3.1172 |      413.54 |      2.3544 |      2.3545 |     0.079542 |         none |     matern52 |   1.0011e+12 |         true |
|   15 |      16 | Accept |      3.1178 |      230.37 |      2.3544 |      2.3545 |      0.63376 |     constant |     matern32 |   2.0347e+12 |         true |
|   16 |      16 | Accept |      3.2677 |      240.21 |      2.3544 |      2.3545 |      0.47178 |       linear | rationalquad |   2.1117e+12 |         true |
|   17 |      16 | Accept |       3.162 |      240.07 |      2.3544 |      2.3545 |      0.19838 |       linear |  exponential |   2.4218e+12 |         true |
|   18 |      16 | Accept |      3.1175 |      235.39 |      2.3544 |      2.3545 |      0.49836 |     constant |  exponential |   1.3742e+12 |         true |
|   19 |      16 | Accept |      4.3769 |      438.22 |      2.3544 |      2.3545 |      0.37134 |       linear |     matern52 |   2.0208e+12 |        false |
|   20 |      16 | Accept |      9.0899 |      505.41 |      2.3544 |      2.3545 |      0.11046 |         none |     matern32 |   2.0717e+10 |        false |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      16 | Accept |      3.1176 |      251.91 |      2.3544 |      2.3545 |       0.1492 |     constant |     matern52 |   1.1766e+12 |         true |
|   22 |      16 | Accept |        2.52 |      248.47 |      2.3544 |      2.3545 |      0.17075 |         none |  exponential |   3.8415e+11 |        false |
|   23 |      16 | Accept |      3.1172 |      308.38 |      2.3544 |      2.3545 |      0.36177 |         none | rationalquad |   1.6119e+12 |         true |
|   24 |      16 | Accept |      5.4012 |      254.99 |      2.3544 |      2.3545 |      0.21014 | pureQuadrati |     matern52 |   6.2566e+12 |         true |
|   25 |      16 | Accept |      3.1172 |      151.88 |      2.3544 |      2.3545 |      0.71282 |         none | squaredexpon |   9.8566e+10 |         true |
|   26 |      16 | Accept |       4.155 |      240.89 |      2.3544 |      2.3545 |      0.17937 | pureQuadrati |  exponential |   5.9065e+10 |         true |
|   27 |      16 | Accept |      2.5196 |       471.6 |      2.3544 |      2.3545 |      0.43482 |     constant |  exponential |   8.1275e+10 |        false |
|   28 |      16 | Accept |      3.0972 |      917.81 |      2.3544 |      2.3545 |       1.0293 | pureQuadrati | rationalquad |    4.214e+11 |        false |
|   29 |      16 | Accept |      3.1175 |      218.88 |      2.3544 |      2.3545 |      0.48905 |     constant | squaredexpon |    7.403e+11 |         true |
|   30 |      16 | Accept |      4.1639 |      569.12 |      2.3544 |      2.3545 |       0.2213 |       linear |  exponential |   2.3629e+12 |        false |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 2077.9442 seconds.
Total objective function evaluation time: 10789.9929

Best observed feasible point:
    Sigma     BasisFunction     KernelFunction      KernelScale    Standardize
    ______    _____________    _________________    ___________    ___________

    1.0773       linear        rationalquadratic    2.0991e+12        false   

Observed objective function value = 2.3544
Estimated objective function value = 2.3545
Function evaluation time = 734.0401

Best estimated feasible point (according to models):
    Sigma     BasisFunction     KernelFunction      KernelScale    Standardize
    ______    _____________    _________________    ___________    ___________

    1.0773       linear        rationalquadratic    2.0991e+12        false   

Estimated objective function value = 2.3545
Estimated function evaluation time = 733.9731

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 29)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 2107.161320 seconds.
Take a copy of the best attributes
Now use these optimum settings to do an exact GPR fit
[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In fitrsuperOptimized (line 51)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 7.609782 seconds.
Train a hyper-parameter optimized Ensemble of Trees model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|    1 |      15 | Best   |      2.5745 |      2.3427 |      2.5745 |       2.588 |          Bag |           17 |            - |         2289 |            2 |           17 |
|    2 |      15 | Accept |      2.7972 |       2.337 |      2.5745 |       2.588 |          Bag |           22 |            - |           17 |            2 |            3 |
|    3 |      12 | Accept |       3.356 |      2.8111 |      1.8392 |      1.8421 |      LSBoost |           11 |     0.023184 |          455 |            2 |           28 |
|    4 |      12 | Accept |       2.737 |      5.1971 |      1.8392 |      1.8421 |          Bag |           64 |            - |            4 |            2 |            4 |
|    5 |      12 | Best   |      1.8392 |      4.6343 |      1.8392 |      1.8421 |          Bag |           11 |            - |          261 |           97 |           32 |
|    6 |      12 | Accept |      2.7123 |      2.7173 |      1.8392 |      1.8421 |      LSBoost |           11 |       0.0691 |            1 |            5 |           16 |
|    7 |      11 | Accept |      2.2034 |      9.2965 |      1.8392 |      1.8394 |          Bag |           48 |            - |          600 |         2582 |           22 |
|    8 |      11 | Accept |      2.5749 |      1.3421 |      1.8392 |      1.8394 |          Bag |           16 |            - |         2704 |           18 |           16 |
|    9 |      16 | Best   |      1.3915 |      15.366 |      1.3915 |      1.3961 |          Bag |           67 |            - |           10 |           67 |           12 |
|   10 |      14 | Accept |      2.3733 |      16.779 |      1.3915 |      1.3917 |      LSBoost |          346 |       0.2358 |         2122 |            1 |            7 |
|   11 |      14 | Accept |      1.3997 |      16.598 |      1.3915 |      1.3917 |          Bag |           43 |            - |           72 |          356 |           19 |
|   12 |      14 | Accept |      2.4605 |      18.377 |      1.3915 |      1.3917 |      LSBoost |          299 |    0.0066018 |            1 |            6 |            2 |
|   13 |      15 | Accept |      2.4038 |      4.7745 |      1.3915 |      1.3917 |          Bag |           59 |            - |           69 |           54 |            1 |
|   14 |      14 | Accept |      1.8543 |      11.353 |      1.3915 |      1.3917 |      LSBoost |           72 |     0.033955 |          214 |          704 |            9 |
|   15 |      14 | Accept |      3.1172 |      4.2696 |      1.3915 |      1.3917 |      LSBoost |          109 |      0.83461 |         4379 |            1 |           37 |
|   16 |      13 | Accept |      1.4054 |      15.185 |      1.3915 |      1.3918 |      LSBoost |          174 |     0.094151 |            6 |          333 |            1 |
|   17 |      13 | Accept |      3.6111 |      7.2323 |      1.3915 |      1.3918 |      LSBoost |           64 |    0.0010207 |            1 |            1 |           34 |
|   18 |      10 | Accept |      2.3628 |      33.973 |     0.83542 |     0.83548 |      LSBoost |          331 |    0.0028295 |           13 |          146 |            3 |
|   19 |      10 | Accept |      2.6908 |      19.354 |     0.83542 |     0.83548 |      LSBoost |           39 |     0.015721 |           85 |         6164 |           32 |
|   20 |      10 | Best   |     0.83542 |      20.557 |     0.83542 |     0.83548 |          Bag |           21 |            - |            5 |         5358 |           33 |
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|   21 |      10 | Accept |      2.8293 |      2.2218 |     0.83542 |     0.83548 |          Bag |           39 |            - |         3650 |          126 |           15 |
|   22 |      16 | Accept |      2.6127 |      40.899 |     0.83542 |     0.83551 |      LSBoost |           69 |    0.0094281 |           82 |         3314 |           38 |
|   23 |      15 | Accept |       2.334 |      2.6145 |     0.83542 |     0.83549 |          Bag |           17 |            - |            5 |            4 |           12 |
|   24 |      15 | Accept |      3.2718 |      2.0964 |     0.83542 |     0.83549 |      LSBoost |           16 |     0.019866 |           61 |            6 |            9 |
|   25 |      14 | Accept |      1.2719 |      45.706 |     0.83542 |     0.83549 |          Bag |          113 |            - |           42 |          107 |           21 |
|   26 |      14 | Accept |      3.6081 |      10.032 |     0.83542 |     0.83549 |      LSBoost |           31 |    0.0017754 |          384 |          420 |           33 |
|   27 |      14 | Accept |      1.2647 |      11.901 |     0.83542 |     0.83553 |          Bag |           40 |            - |            3 |           97 |           16 |
|   28 |      14 | Accept |      1.4779 |      19.703 |     0.83542 |     0.83553 |      LSBoost |           81 |      0.94765 |            1 |          215 |            7 |
|   29 |      16 | Accept |     0.86369 |       21.15 |     0.83542 |     0.83547 |          Bag |           25 |            - |            1 |          809 |           30 |
|   30 |      16 | Accept |      1.0633 |      56.082 |     0.83542 |     0.83543 |          Bag |          183 |            - |           18 |          259 |           13 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 75.6218 seconds.
Total objective function evaluation time: 426.9029

Best observed feasible point:
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             21               NaN            5             5358                 33         

Observed objective function value = 0.83542
Estimated objective function value = 0.83543
Function evaluation time = 20.5569

Best estimated feasible point (according to models):
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             21               NaN            5             5358                 33         

Estimated objective function value = 0.83543
Estimated function evaluation time = 20.5597

Elapsed time is 78.987521 seconds.
Train the super learner model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      3.1163 |      145.16 |      3.1163 |      3.1163 |       3.2347 |         none | squaredexpon |   7.5878e+11 |        false |
|    2 |      16 | Accept |      12.365 |      225.84 |      3.1163 |       3.484 |   0.00024408 |     constant |  exponential |   2.1475e+11 |        false |
|    3 |      16 | Best   |     0.24271 |      236.35 |     0.24271 |     0.54741 |     0.050667 |       linear |     matern32 |   1.9258e+10 |         true |
|    4 |      16 | Accept |      1.5298 |      263.39 |     0.24271 |     0.46508 |     0.077361 | pureQuadrati |     matern52 |   3.7073e+10 |         true |
|    5 |      16 | Accept |     0.29052 |      263.36 |     0.24271 |     0.32027 |      0.13739 | pureQuadrati |     matern52 |   5.3423e+10 |         true |
|    6 |      16 | Best   |     0.22616 |      301.24 |     0.22616 |     0.29873 |      0.01403 |       linear | rationalquad |   9.7914e+11 |         true |
|    7 |      16 | Accept |     0.24117 |      214.26 |     0.22616 |     0.27046 |       1.1598 |       linear |     matern32 |   1.2106e+11 |         true |
|    8 |      16 | Accept |      0.2341 |      227.05 |     0.22616 |     0.25196 |   0.00061435 |       linear |     matern32 |   7.5013e+10 |         true |
|    9 |      16 | Accept |      7.0662 |      535.13 |     0.22616 |      0.2557 |     0.077103 |     constant |     matern52 |   6.1253e+10 |        false |
|   10 |      15 | Accept |      1.1326 |      262.65 |     0.22616 |     0.24988 |       4.8694 | pureQuadrati |     matern52 |   5.0709e+11 |         true |
|   11 |      15 | Accept |      1.1374 |      230.45 |     0.22616 |     0.24988 |     0.010883 | pureQuadrati |     matern52 |   1.5452e+12 |         true |
|   12 |      16 | Accept |      3.1172 |       554.7 |     0.22616 |     0.25116 |     0.050494 |         none | rationalquad |   9.3583e+10 |         true |
|   13 |      16 | Accept |     0.25393 |      568.09 |     0.22616 |     0.25014 |      0.18723 |       linear | squaredexpon |   2.0572e+12 |        false |
|   14 |      16 | Accept |     0.22844 |      231.16 |     0.22616 |     0.24943 |      0.63146 |       linear |     matern52 |   8.4076e+11 |         true |
|   15 |      16 | Accept |      6.1955 |      492.86 |     0.22616 |     0.30162 |      0.09858 |         none | squaredexpon |   1.7734e+11 |        false |
|   16 |      16 | Accept |      2.8494 |      227.46 |     0.22616 |     0.30788 |   0.00019039 | pureQuadrati |     matern32 |   1.5123e+12 |         true |
|   17 |      16 | Accept |     0.22805 |      219.26 |     0.22616 |     0.30452 |     0.009453 |       linear | squaredexpon |   9.6082e+11 |         true |
|   18 |      16 | Accept |     0.24097 |      222.42 |     0.22616 |       0.302 |    0.0062475 |       linear |  exponential |   5.9494e+10 |         true |
|   19 |      16 | Accept |     0.71011 |      301.57 |     0.22616 |     0.30183 |    0.0045598 | pureQuadrati | rationalquad |   3.0227e+12 |         true |
|   20 |      16 | Accept |     0.22642 |      255.21 |     0.22616 |     0.30016 |       0.9681 |       linear |     matern52 |    6.736e+11 |        false |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 949.628 seconds.
Total objective function evaluation time: 5977.61

Best observed feasible point:
     Sigma     BasisFunction     KernelFunction      KernelScale    Standardize
    _______    _____________    _________________    ___________    ___________

    0.01403       linear        rationalquadratic    9.7914e+11        true    

Observed objective function value = 0.22616
Estimated objective function value = 0.39982
Function evaluation time = 301.2425

Best estimated feasible point (according to models):
      Sigma       BasisFunction    KernelFunction    KernelScale    Standardize
    __________    _____________    ______________    ___________    ___________

    0.00061435       linear           matern32       7.5013e+10        true    

Estimated objective function value = 0.30016
Estimated function evaluation time = 278.3934

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 90)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 956.815124 seconds.
Train the super learner error model for regression
Copying objective function to workers...
Done copying objective function to workers.
