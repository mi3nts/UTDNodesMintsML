Running calibration scripts for UTD Node: 4
Running on host: compute-1-1-4

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
              R2020a Update 1 (9.8.0.1359463) 64-bit (glnxa64)
                               April 9, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 


    "---------------------MINTS---------------------"

30-Dec-2020 11:24:05

mintsDefinitions = 

  struct with fields:

                dataFolder: '/home/lhw150030/mintsData'
               poolWorkers: 16
                  timeSpan: 30
                  airmarID: '001e0610c0e4'
             binsPerColumn: 500
              numberPerBin: 2
                    pValid: 0.1500
                   nodeIDs: {1x16 cell}
               inputStack1: {1x9 cell}
         mintsInputsStack1: {1x35 cell}
    mintsInputLabelsStack1: {1x35 cell}
               inputStack2: {1x11 cell}
         mintsInputsStack2: {1x35 cell}
    mintsInputLabelsStack2: {1x35 cell}
               inputStack3: {1x10 cell}
         mintsInputsStack3: {1x38 cell}
    mintsInputLabelsStack3: {1x38 cell}
              mintsTargets: {1x10 cell}
         mintsTargetLabels: {1x10 cell}
                     units: {1x10 cell}
               instruments: {1x10 cell}

Starting parallel pool (parpool) using the 'local' profile ...
Connected to the parallel pool (number of workers: 16).

ans = 

 ProcessPool with properties: 

            Connected: true
           NumWorkers: 16
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


airmarFolder = 

    "/home/lhw150030/mintsData/referenceMats/airmar"

UTD_Rsl_All_2020_12_30_11_26_18


UTD_Rsl_All_Daily


Super Learner All Inputs




    "Data Folder Located @:/home/lhw150030/mintsData"

    "Raw Data Located @: /home/lhw150030/mintsData"

    "Raw DotMat Data Located @ :/home/lhw150030/mintsData/rawMats"

    "UTD Nodes DotMat Data Located @ :/home/lhw150030/mintsData/rawMats/UTDNodes"

    "Reference Data Located @: /home/lhw150030/mintsData/reference"

    "Reference DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats"

    "Palas Raw Data Located @ :/home/lhw150030/mintsData/reference/palasStream"

    "Palas DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats/palas"

    "Car GPS Files Located @ :/home/lhw150030/mintsData/referenceMats/carMintsGPS"

    "Loading Palas Files"

    "Loading GPS Files"

    "Loading Airmar Files"

    "Aligning GPS data with Palas Data"

    "WSTC Palas Data"

    "Palas With Airmar"

    "Analysis"

    "Save merged data for calibration: 001e06305a61"



    "Creating Training Data Sets for Node: 001e06305a61"



    "Gainin Data set for Node 001e06305a61 with target output pm1_palas @ 30-Dec-2020 11:26:34"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 324 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 74 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 248 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 159 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 100 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 47 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 22 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 10 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 8 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 5 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 5 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 246 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 277 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 270 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 157 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        7810


ans =

        1378

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |      11 | Accept |      44.736 |      8.0755 |      11.384 |      18.021 |           30 |      0.79485 |
|    2 |      11 | Best   |      11.384 |      7.9587 |      11.384 |      18.021 |           17 |     0.010832 |
|    3 |      11 | Accept |      63.005 |       8.277 |      11.384 |      18.021 |           79 |    0.0010721 |
|    4 |      11 | Accept |      17.382 |      7.9093 |      11.384 |      18.021 |           83 |      0.87305 |
|    5 |      11 | Accept |      63.069 |      8.0236 |      11.384 |      18.021 |           67 |    0.0068166 |
|    6 |      11 | Accept |      37.482 |      7.8411 |      11.384 |      18.021 |           61 |    0.0015389 |
|    7 |      12 | Accept |      75.492 |      14.995 |      11.384 |      42.201 |           91 |     0.023597 |
|    8 |      12 | Accept |      28.835 |      15.409 |      11.384 |      42.201 |           78 |    0.0021836 |
|    9 |      12 | Accept |       28.03 |      11.612 |      11.384 |      42.201 |           36 |      0.41361 |
|   10 |      12 | Accept |       45.95 |      10.926 |      11.384 |      42.201 |           64 |     0.050023 |
|   11 |      12 | Accept |      48.851 |      9.1803 |      11.384 |      42.201 |           92 |    0.0026886 |
|   12 |       2 | Accept |       26.54 |      15.428 |      8.1514 |      20.895 |           39 |    0.0025511 |
|   13 |       2 | Accept |      82.898 |      15.319 |      8.1514 |      20.895 |           53 |     0.024644 |
|   14 |       2 | Accept |      35.578 |      15.903 |      8.1514 |      20.895 |           85 |    0.0011945 |
|   15 |       2 | Accept |      17.955 |      15.532 |      8.1514 |      20.895 |           38 |     0.068662 |
|   16 |       2 | Accept |      21.586 |      15.428 |      8.1514 |      20.895 |           66 |    0.0062927 |
|   17 |       2 | Accept |      15.263 |     0.83904 |      8.1514 |      20.895 |           15 |    0.0075422 |
|   18 |       2 | Accept |      50.901 |       1.529 |      8.1514 |      20.895 |           74 |    0.0024022 |
|   19 |       2 | Best   |      8.1514 |     0.75699 |      8.1514 |      20.895 |           12 |      0.58191 |
|   20 |       2 | Accept |      24.567 |      1.5068 |      8.1514 |      20.895 |           15 |     0.064559 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       2 | Accept |      19.892 |     0.85505 |      8.1514 |      20.895 |           76 |      0.23869 |
|   22 |       2 | Accept |      21.286 |      1.2423 |      8.1514 |      20.895 |           17 |      0.25908 |
|   23 |      16 | Accept |      104.92 |     0.65335 |      8.1514 |      18.116 |          100 |      0.99758 |
|   24 |       6 | Accept |      30.456 |     0.46365 |       8.099 |      20.183 |           13 |     0.099256 |
|   25 |       6 | Accept |      16.462 |      2.2445 |       8.099 |      20.183 |           32 |     0.020708 |
|   26 |       6 | Accept |      31.285 |       1.215 |       8.099 |      20.183 |           41 |    0.0010129 |
|   27 |       6 | Accept |      45.551 |       2.392 |       8.099 |      20.183 |           33 |      0.16511 |
|   28 |       6 | Accept |      47.113 |      1.3996 |       8.099 |      20.183 |           80 |      0.14743 |
|   29 |       6 | Accept |      35.155 |      1.9597 |       8.099 |      20.183 |           80 |      0.66308 |
|   30 |       6 | Accept |      34.364 |      1.1442 |       8.099 |      20.183 |           71 |      0.13861 |
|   31 |       6 | Accept |      46.768 |      1.1707 |       8.099 |      20.183 |           95 |    0.0021481 |
|   32 |       6 | Best   |       8.099 |      1.1586 |       8.099 |      20.183 |           24 |      0.33193 |
|   33 |       6 | Accept |      21.006 |      1.2755 |       8.099 |      20.183 |           74 |     0.078974 |
|   34 |       6 | Accept |      82.046 |     0.97315 |       8.099 |      20.183 |           67 |      0.37616 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 34
Total elapsed time: 34.4626 seconds.
Total objective function evaluation time: 210.5976

Best observed feasible point:
    hiddenLayerSize      lr   
    _______________    _______

          24           0.33193

Observed objective function value = 8.099
Estimated objective function value = 22.9949
Function evaluation time = 1.1586

Best estimated feasible point (according to models):
    hiddenLayerSize       lr   
    _______________    ________

          15           0.064559

Estimated objective function value = 20.1828
Estimated function evaluation time = 1.5065


T =

  1x2 table

    hiddenLayerSize       lr   
    _______________    ________

          15           0.064559

Elapsed time is 67.913599 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |       18.94 |      3715.8 |       18.94 |       18.94 |      0.69808 | pureQuadrati |     matern52 |   9.7842e+12 |         true |
|    2 |      16 | Best   |      3.7238 |      6057.8 |      3.7238 |      4.3288 |    0.0032243 |         none |     matern32 |   9.1371e+10 |         true |
|    3 |      16 | Best   |      3.7238 |      3863.4 |      3.7238 |      3.7248 |    0.0045917 |         none |     matern52 |   6.5633e+10 |         true |
|    4 |      16 | Accept |      3.7238 |      3132.2 |      3.7238 |      3.7241 |    0.0024356 |         none |     matern32 |   9.5205e+11 |         true |
|    5 |      16 | Accept |      6.5084 |       10328 |      3.7238 |      3.7241 |      0.02743 |       linear |     matern52 |   5.0443e+10 |         true |
|    6 |      16 | Accept |      3.7239 |      1754.8 |      3.7238 |       3.724 |    0.0027533 |     constant |     matern32 |   2.9409e+12 |         true |
|    7 |      16 | Best   |      3.7238 |      3339.7 |      3.7238 |       3.724 |      0.15061 |         none |     matern52 |   1.5523e+12 |         true |
|    8 |      16 | Accept |      8.6921 |      2639.7 |      3.7238 |       3.724 |    0.0045974 |       linear |     matern32 |   3.6561e+11 |         true |
|    9 |      16 | Accept |      3.7242 |      1536.2 |      3.7238 |       3.724 |    0.0035183 |     constant |     matern52 |   6.1622e+11 |         true |
|   10 |      16 | Error  |         NaN |      2937.7 |      3.7238 |       3.724 |    0.0014894 |         none |     matern32 |    2.907e+11 |        false |
|   11 |      16 | Accept |      6.7356 |        3371 |      3.7238 |       3.724 |     0.020683 |     constant |     matern32 |   7.9309e+12 |        false |
|   12 |      16 | Best   |      3.7238 |      3543.1 |      3.7238 |       3.724 |     0.029106 |         none | rationalquad |    1.197e+13 |         true |
|   13 |      16 | Accept |      4.7111 |       18797 |      3.7238 |       3.724 |   0.00083344 |         none |     matern52 |   2.4388e+11 |        false |
|   14 |      16 | Accept |      7.8328 |       19404 |      3.7238 |       3.724 |    0.0045951 |         none | squaredexpon |   1.2114e+13 |        false |
|   15 |      16 | Error  |         NaN |      6883.8 |      3.7238 |       3.724 |    0.0047914 |     constant |     matern52 |   4.0151e+10 |        false |
|   16 |      16 | Accept |       3.724 |      1765.9 |      3.7238 |       3.724 |    0.0055253 |     constant | rationalquad |   6.1499e+10 |         true |
|   17 |      16 | Best   |      1.5745 |      3913.5 |      1.5745 |      1.5749 |    0.0031833 |     constant |  exponential |   2.3581e+11 |         true |
|   18 |      16 | Accept |      3.7245 |      1516.3 |      1.5745 |      1.5749 |   0.00095346 |     constant | squaredexpon |   2.5264e+10 |         true |
|   19 |      16 | Accept |       7.657 |      1813.3 |      1.5745 |      1.5749 |     0.054953 |       linear | rationalquad |    2.039e+11 |         true |
|   20 |      16 | Error  |         NaN |      1631.5 |      1.5745 |      1.5749 |     0.005968 |     constant |  exponential |   8.8545e+10 |        false |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      16 | Accept |      3.7238 |      1763.6 |      1.5745 |      1.5749 |      0.02584 |         none | squaredexpon |   3.9686e+10 |         true |
|   22 |      16 | Accept |      9.1007 |        1501 |      1.5745 |       1.575 |   0.00021907 |       linear | squaredexpon |   2.6169e+11 |         true |
|   23 |      16 | Accept |      6.3684 |      3906.9 |      1.5745 |       1.575 |   0.00015352 |       linear |     matern52 |   8.7762e+12 |        false |
|   24 |      16 | Error  |         NaN |      5098.1 |      1.5745 |       1.575 |    0.0011956 |     constant | rationalquad |   3.0148e+10 |        false |
|   25 |      16 | Accept |      4.5858 |      3173.7 |      1.5745 |      1.5749 |   0.00016777 |     constant | squaredexpon |   1.0694e+12 |        false |
|   26 |      16 | Best   |      1.5404 |       19710 |      1.5404 |      1.5408 |    0.0017077 |         none |  exponential |   1.4026e+11 |         true |
|   27 |      16 | Error  |         NaN |      7947.4 |      1.5404 |      1.5408 |      0.68791 |         none |  exponential |   1.3946e+11 |        false |
|   28 |      16 | Accept |      7.3058 |       28614 |      1.5404 |      1.5409 |    0.0086681 |         none | rationalquad |   7.6908e+11 |        false |
|   29 |      16 | Accept |       4.105 |       19362 |      1.5404 |      1.5408 |    0.0007416 |       linear |  exponential |   2.1279e+10 |         true |
|   30 |      16 | Accept |      18.808 |      9216.5 |      1.5404 |      1.5409 |    0.0018554 | pureQuadrati |  exponential |   1.3455e+11 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 76274.532 seconds.
Total objective function evaluation time: 202237.1136

Best observed feasible point:
      Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    _________    _____________    ______________    ___________    ___________

    0.0017077        none          exponential      1.4026e+11        true    

Observed objective function value = 1.5404
Estimated objective function value = 1.5409
Function evaluation time = 19709.6442

Best estimated feasible point (according to models):
      Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    _________    _____________    ______________    ___________    ___________

    0.0017077        none          exponential      1.4026e+11        true    

Estimated objective function value = 1.5409
Estimated function evaluation time = 4471.8652

Elapsed time is 76567.077991 seconds.
Take a copy of the best attributes
Now use these optimum settings to do an exact GPR fit
Elapsed time is 157.848502 seconds.
Train a hyper-parameter optimized Ensemble of Trees model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|    1 |      15 | Best   |      3.4059 |       9.219 |      3.4059 |      3.4143 |          Bag |           54 |            - |         2239 |         2609 |            8 |
|    2 |      15 | Accept |      3.4895 |      8.2581 |      3.4059 |      3.4143 |          Bag |           12 |            - |          262 |           98 |            2 |
|    3 |       6 | Accept |      4.3638 |      13.055 |      2.0511 |      2.0512 |      LSBoost |           11 |     0.001985 |            2 |          382 |           34 |
|    4 |       6 | Accept |      3.4709 |      96.301 |      2.0511 |      2.0512 |      LSBoost |           93 |    0.0064272 |           24 |           58 |            5 |
|    5 |       6 | Accept |      3.7241 |      35.834 |      2.0511 |      2.0512 |          Bag |           14 |            - |         3885 |         1406 |           17 |
|    6 |       6 | Accept |      3.4064 |      56.262 |      2.0511 |      2.0512 |          Bag |          335 |            - |          101 |         7665 |            2 |
|    7 |       6 | Accept |       2.481 |       89.59 |      2.0511 |      2.0512 |          Bag |           59 |            - |            4 |           17 |           11 |
|    8 |       6 | Accept |      3.2851 |      26.931 |      2.0511 |      2.0512 |      LSBoost |          172 |      0.40129 |         2410 |            4 |            9 |
|    9 |       6 | Accept |      3.3098 |      10.931 |      2.0511 |      2.0512 |          Bag |           56 |            - |         2848 |           94 |           20 |
|   10 |       6 | Accept |      3.4187 |      84.861 |      2.0511 |      2.0512 |      LSBoost |           50 |     0.016092 |            3 |            3 |           32 |
|   11 |       6 | Accept |      2.1513 |      96.028 |      2.0511 |      2.0512 |      LSBoost |           73 |     0.018209 |            1 |         3101 |           30 |
|   12 |       6 | Best   |      2.0511 |      53.221 |      2.0511 |      2.0512 |      LSBoost |          269 |      0.20794 |          112 |            5 |            7 |
|   13 |      16 | Accept |      3.2953 |       4.052 |      2.0511 |      2.0512 |          Bag |           55 |            - |         1409 |         2086 |            9 |
|   14 |       7 | Accept |      4.1001 |      15.854 |      1.5602 |      1.5605 |      LSBoost |           45 |    0.0045893 |          637 |           85 |           32 |
|   15 |       7 | Accept |      3.1912 |      33.145 |      1.5602 |      1.5605 |          Bag |           17 |            - |         1540 |           32 |           30 |
|   16 |       7 | Best   |      1.5602 |      52.512 |      1.5602 |      1.5605 |          Bag |          146 |            - |            9 |          314 |            6 |
|   17 |       7 | Accept |      4.1311 |      43.729 |      1.5602 |      1.5605 |      LSBoost |           85 |    0.0026122 |         2357 |           36 |           10 |
|   18 |       7 | Accept |      4.1163 |      13.903 |      1.5602 |      1.5605 |      LSBoost |           29 |    0.0054762 |            7 |          177 |            9 |
|   19 |       7 | Accept |      1.9245 |      6.5066 |      1.5602 |      1.5605 |      LSBoost |           14 |      0.27658 |           23 |           21 |            9 |
|   20 |       7 | Accept |      1.6467 |      45.168 |      1.5602 |      1.5605 |      LSBoost |           74 |     0.036677 |           46 |           29 |           33 |
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|   21 |       7 | Accept |      2.3946 |      50.361 |      1.5602 |      1.5605 |          Bag |           32 |            - |            7 |           10 |           26 |
|   22 |       7 | Accept |      1.9051 |      18.946 |      1.5602 |      1.5605 |          Bag |           29 |            - |            4 |           70 |           16 |
|   23 |       7 | Accept |       1.835 |      10.033 |      1.5602 |      1.5605 |      LSBoost |           15 |      0.32234 |            2 |           23 |            7 |
|   24 |      16 | Accept |      2.2429 |      18.116 |      1.5602 |      1.5605 |          Bag |           75 |            - |            1 |           20 |           15 |
|   25 |       8 | Accept |      4.0386 |       128.5 |      1.2762 |      1.2763 |      LSBoost |          123 |    0.0027217 |            1 |           16 |            3 |
|   26 |       8 | Best   |      1.2762 |      59.642 |      1.2762 |      1.2763 |      LSBoost |          115 |     0.091529 |            4 |           73 |           16 |
|   27 |       8 | Accept |      2.9228 |      45.208 |      1.2762 |      1.2763 |          Bag |           20 |            - |           49 |            7 |           14 |
|   28 |       8 | Accept |      2.7903 |      25.687 |      1.2762 |      1.2763 |      LSBoost |           99 |      0.64647 |            2 |            2 |            5 |
|   29 |       8 | Accept |      3.5678 |      63.829 |      1.2762 |      1.2763 |          Bag |          424 |            - |          418 |         1945 |            3 |
|   30 |       8 | Accept |      2.7858 |      17.312 |      1.2762 |      1.2763 |      LSBoost |           54 |      0.12938 |          416 |            5 |            4 |
|   31 |       8 | Accept |      2.1153 |      39.641 |      1.2762 |      1.2763 |          Bag |           73 |            - |            2 |           40 |           17 |
|   32 |       8 | Accept |      2.9458 |      18.256 |      1.2762 |      1.2763 |      LSBoost |           81 |     0.079252 |         1605 |         6973 |           17 |
|   33 |       8 | Accept |      2.8539 |      16.906 |      1.2762 |      1.2763 |          Bag |           46 |            - |          269 |            4 |           12 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 33
Total elapsed time: 267.3104 seconds.
Total objective function evaluation time: 1307.7996

Best observed feasible point:
    Method     NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    _______    _________________    _________    ___________    ____________    ____________________

    LSBoost           115           0.091529          4              73                  16         

Observed objective function value = 1.2762
Estimated objective function value = 1.2763
Function evaluation time = 59.6417

Best estimated feasible point (according to models):
    Method     NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    _______    _________________    _________    ___________    ____________    ____________________

    LSBoost           115           0.091529          4              73                  16         

Estimated objective function value = 1.2763
Estimated function evaluation time = 58.3529

Elapsed time is 277.143998 seconds.
Train the super learner model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |       3.722 |      1665.5 |       3.722 |       3.722 |       10.566 |         none |     matern32 |   1.1445e+13 |        false |
|    2 |      16 | Best   |      1.8264 |        2467 |      1.8264 |      1.9018 |   0.00049302 |       linear |     matern52 |   6.8627e+11 |         true |
