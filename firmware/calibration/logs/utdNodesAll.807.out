Running calibration scripts for UTD Node: 12
Running on host: compute-1-1-12

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
              R2020a Update 1 (9.8.0.1359463) 64-bit (glnxa64)
                               April 9, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 


    "---------------------MINTS---------------------"

30-Dec-2020 11:23:56

mintsDefinitions = 

  struct with fields:

                dataFolder: '/home/lhw150030/mintsData'
               poolWorkers: 16
                  timeSpan: 30
                  airmarID: '001e0610c0e4'
             binsPerColumn: 500
              numberPerBin: 2
                    pValid: 0.1500
                   nodeIDs: {1x16 cell}
               inputStack1: {1x9 cell}
         mintsInputsStack1: {1x35 cell}
    mintsInputLabelsStack1: {1x35 cell}
               inputStack2: {1x11 cell}
         mintsInputsStack2: {1x35 cell}
    mintsInputLabelsStack2: {1x35 cell}
               inputStack3: {1x10 cell}
         mintsInputsStack3: {1x38 cell}
    mintsInputLabelsStack3: {1x38 cell}
              mintsTargets: {1x10 cell}
         mintsTargetLabels: {1x10 cell}
                     units: {1x10 cell}
               instruments: {1x10 cell}

Starting parallel pool (parpool) using the 'local' profile ...
Connected to the parallel pool (number of workers: 16).

ans = 

 ProcessPool with properties: 

            Connected: true
           NumWorkers: 16
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


airmarFolder = 

    "/home/lhw150030/mintsData/referenceMats/airmar"

UTD_Rsl_All_2020_12_30_11_24_21


UTD_Rsl_All_Daily


Super Learner All Inputs




    "Data Folder Located @:/home/lhw150030/mintsData"

    "Raw Data Located @: /home/lhw150030/mintsData"

    "Raw DotMat Data Located @ :/home/lhw150030/mintsData/rawMats"

    "UTD Nodes DotMat Data Located @ :/home/lhw150030/mintsData/rawMats/UTDNodes"

    "Reference Data Located @: /home/lhw150030/mintsData/reference"

    "Reference DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats"

    "Palas Raw Data Located @ :/home/lhw150030/mintsData/reference/palasStream"

    "Palas DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats/palas"

    "Car GPS Files Located @ :/home/lhw150030/mintsData/referenceMats/carMintsGPS"

    "Loading Palas Files"

    "Loading GPS Files"

    "Loading Airmar Files"

    "Aligning GPS data with Palas Data"

    "WSTC Palas Data"

    "Palas With Airmar"

    "Analysis"

    "Save merged data for calibration: 001e063239e6"



    "Creating Training Data Sets for Node: 001e063239e6"



    "Gainin Data set for Node 001e063239e6 with target output pm1_palas @ 30-Dec-2020 11:24:30"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 330 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 75 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 318 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 81 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 59 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 38 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 19 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 8 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 487 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 321 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 191 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 37 and choosing a representative sample. Choosing 149 bins for this column. With 2 members per bin.
Going through column 38 and choosing a representative sample. Choosing 291 bins for this column. With 2 members per bin.
Going through column 39 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

       11617


ans =

        2050

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |       1 | Best   |      6.4613 |      2.7938 |      6.4613 |      25.754 |           15 |    0.0011685 |
|    2 |       1 | Accept |      10.839 |      2.8398 |      6.4613 |      25.754 |           43 |      0.58905 |
|    3 |       1 | Accept |      80.878 |      2.7993 |      6.4613 |      25.754 |           38 |    0.0096602 |
|    4 |       1 | Accept |      19.884 |      3.0422 |      6.4613 |      25.754 |           72 |     0.035507 |
|    5 |       1 | Accept |       50.09 |      2.9405 |      6.4613 |      25.754 |           86 |    0.0020014 |
|    6 |       1 | Accept |      24.257 |      2.8711 |      6.4613 |      25.754 |           77 |     0.019256 |
|    7 |       1 | Accept |      48.862 |       2.888 |      6.4613 |      25.754 |           72 |     0.009567 |
|    8 |       1 | Accept |      29.925 |      2.7853 |      6.4613 |      25.754 |            7 |     0.035287 |
|    9 |       1 | Accept |      82.038 |      2.8007 |      6.4613 |      25.754 |           64 |     0.059271 |
|   10 |       1 | Accept |      59.068 |       2.853 |      6.4613 |      25.754 |           75 |      0.16385 |
|   11 |       1 | Accept |      30.675 |      2.7594 |      6.4613 |      25.754 |           46 |      0.19826 |
|   12 |       1 | Accept |      7.4812 |      2.7469 |      6.4613 |      25.754 |           16 |     0.011813 |
|   13 |       1 | Accept |      8.6081 |      2.6948 |      6.4613 |      25.754 |            6 |     0.094786 |
|   14 |       1 | Accept |      14.845 |      2.7254 |      6.4613 |      25.754 |           36 |     0.014186 |
|   15 |       1 | Accept |      45.229 |      2.7899 |      6.4613 |      25.754 |           83 |    0.0064574 |
|   16 |       1 | Accept |      15.894 |      2.6823 |      6.4613 |      25.754 |           31 |      0.67998 |
|   17 |      16 | Accept |      13.447 |     0.58209 |      6.4613 |      22.601 |           21 |      0.92923 |
|   18 |       2 | Accept |      34.313 |     0.64758 |      6.4613 |      23.417 |           59 |      0.10477 |
|   19 |       2 | Accept |      16.841 |     0.72418 |      6.4613 |      23.417 |           78 |      0.45664 |
|   20 |       2 | Accept |      10.545 |      0.6396 |      6.4613 |      23.417 |           46 |    0.0030086 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       2 | Accept |      35.448 |     0.70908 |      6.4613 |      23.417 |           84 |      0.19968 |
|   22 |       2 | Accept |      62.076 |      0.6223 |      6.4613 |      23.417 |           58 |     0.014919 |
|   23 |       2 | Accept |      22.611 |     0.64535 |      6.4613 |      23.417 |           27 |     0.027439 |
|   24 |       2 | Accept |      26.512 |     0.64497 |      6.4613 |      23.417 |           42 |    0.0057405 |
|   25 |       2 | Accept |      60.312 |     0.72884 |      6.4613 |      23.417 |           93 |      0.23837 |
|   26 |       2 | Accept |      51.155 |     0.69248 |      6.4613 |      23.417 |           79 |      0.95983 |
|   27 |       2 | Accept |       14.71 |     0.72784 |      6.4613 |      23.417 |           94 |     0.033758 |
|   28 |       2 | Accept |      83.024 |     0.69807 |      6.4613 |      23.417 |           76 |     0.046003 |
|   29 |       2 | Accept |      20.426 |       0.691 |      6.4613 |      23.417 |           63 |     0.031917 |
|   30 |       2 | Accept |      39.563 |      0.6194 |      6.4613 |      23.417 |           35 |     0.001364 |
|   31 |       2 | Accept |      38.898 |     0.71005 |      6.4613 |      23.417 |           63 |    0.0035224 |
|   32 |       2 | Accept |       31.19 |     0.66915 |      6.4613 |      23.417 |           72 |      0.12584 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 32
Total elapsed time: 15.342 seconds.
Total objective function evaluation time: 55.7644

Best observed feasible point:
    hiddenLayerSize       lr    
    _______________    _________

          15           0.0011685

Observed objective function value = 6.4613
Estimated objective function value = 23.3267
Function evaluation time = 2.7938

Best estimated feasible point (according to models):
    hiddenLayerSize       lr   
    _______________    ________

          16           0.011813

Estimated objective function value = 23.4169
Estimated function evaluation time = 1.3732


T =

  1x2 table

    hiddenLayerSize       lr   
    _______________    ________

          16           0.011813

Elapsed time is 24.877757 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      2.9611 |      181.75 |      2.9611 |      2.9611 |       6.5891 |         none |     matern52 |   8.6775e+10 |        false |
|    2 |      16 | Accept |      3.0005 |      259.57 |      2.9611 |      2.9802 |       3.3326 |         none | rationalquad |   4.6474e+10 |         true |
|    3 |      16 | Accept |      2.9797 |      466.68 |      2.9611 |        2.98 |       8.1118 | pureQuadrati | rationalquad |   1.6296e+12 |        false |
|    4 |      16 | Accept |      3.0005 |      486.57 |      2.9611 |      2.9846 |      0.11157 |         none |  exponential |   1.0405e+13 |         true |
|    5 |      16 | Accept |      14.026 |      527.44 |      2.9611 |      3.1603 |      0.51618 |         none |     matern52 |   1.1507e+12 |        false |
|    6 |      16 | Accept |       7.176 |      611.05 |      2.9611 |       3.245 |   0.00033114 |       linear |  exponential |   1.7143e+13 |         true |
|    7 |      16 | Error  |         NaN |      684.32 |      2.9611 |       3.245 |   0.00020209 |     constant |     matern52 |   2.3075e+10 |        false |
|    8 |      16 | Accept |      3.0102 |      170.31 |      2.9611 |      2.9609 |       36.115 |         none |     matern52 |    1.118e+11 |        false |
|    9 |      16 | Accept |      12.858 |      727.94 |      2.9611 |      2.9608 |   0.00034733 |       linear | squaredexpon |   1.6861e+11 |        false |
|   10 |      16 | Accept |      3.0113 |      168.02 |      2.9611 |      2.9856 |       36.714 |         none |     matern52 |   9.0645e+10 |        false |
|   11 |      16 | Accept |      2.9939 |      569.08 |      2.9611 |      2.9854 |       27.236 |         none |     matern52 |   2.2149e+10 |        false |
|   12 |      16 | Accept |      3.0005 |      197.17 |      2.9611 |      2.9835 |         1.31 |         none |  exponential |   1.0057e+13 |         true |
|   13 |      16 | Accept |       3.256 |      507.96 |      2.9611 |      3.0492 |       2.0421 |         none |     matern52 |   8.7672e+10 |        false |
|   14 |      16 | Accept |      3.0005 |      195.67 |      2.9611 |      3.0428 |       3.3061 |         none |  exponential |   1.2445e+12 |         true |
|   15 |      16 | Accept |      3.0005 |      364.49 |      2.9611 |      3.0314 |    0.0028823 |         none | rationalquad |   1.4099e+11 |         true |
|   16 |      16 | Accept |      3.0005 |      221.43 |      2.9611 |      3.0125 |       33.103 |         none | rationalquad |   2.0762e+10 |         true |
|   17 |      16 | Error  |         NaN |      715.98 |      2.9611 |      3.0125 |     0.072177 | pureQuadrati | rationalquad |   2.1812e+10 |        false |
|   18 |      16 | Accept |      3.0005 |      371.03 |      2.9611 |      3.0093 |    0.0030186 |         none | rationalquad |   3.2183e+12 |         true |
|   19 |      16 | Accept |      9.2435 |      287.15 |      2.9611 |      3.0068 |       3.8054 |       linear |  exponential |   2.1162e+10 |         true |
|   20 |      16 | Accept |      8.3339 |      289.58 |      2.9611 |       3.001 |        27.64 |       linear |  exponential |   4.4914e+11 |         true |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      16 | Accept |      3.0005 |      266.67 |      2.9611 |      2.9834 |       2.9239 |         none | rationalquad |   7.7496e+11 |         true |
|   22 |      16 | Accept |      6.2977 |      772.95 |      2.9611 |      2.9906 |     0.095728 | pureQuadrati | rationalquad |   4.4067e+11 |        false |
|   23 |      16 | Error  |         NaN |      543.37 |      2.9611 |      2.9906 |   0.00011026 |         none |  exponential |     3.36e+12 |         true |
|   24 |      16 | Accept |      2.9995 |      903.63 |      2.9611 |      2.9827 |        29.25 | pureQuadrati | rationalquad |   5.3355e+12 |        false |
|   25 |      16 | Best   |      1.0143 |       612.3 |      1.0143 |      1.0198 |     0.010524 |         none |  exponential |   1.5701e+11 |         true |
|   26 |      16 | Accept |      3.0005 |      193.84 |      1.0143 |      1.0196 |       3.1928 |         none |     matern52 |   2.1372e+10 |         true |
|   27 |      16 | Accept |      3.0005 |      198.61 |      1.0143 |      1.0196 |       3.9375 |         none |     matern52 |   5.5337e+12 |         true |
|   28 |      16 | Accept |      3.0005 |       181.8 |      1.0143 |      1.0333 |       35.751 |         none |  exponential |   8.6929e+10 |         true |
|   29 |      16 | Accept |      3.0005 |      192.23 |      1.0143 |      1.0347 |       2.7016 |         none |     matern52 |   1.9632e+11 |         true |
|   30 |      16 | Accept |      3.0006 |      187.02 |      1.0143 |      1.0343 |        39.46 |         none |     matern32 |    3.135e+11 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 2017.7711 seconds.
Total objective function evaluation time: 12055.634

Best observed feasible point:
     Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    ________    _____________    ______________    ___________    ___________

    0.010524        none          exponential      1.5701e+11        true    

Observed objective function value = 1.0143
Estimated objective function value = 1.0343
Function evaluation time = 612.298

Best estimated feasible point (according to models):
     Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    ________    _____________    ______________    ___________    ___________

    0.010524        none          exponential      1.5701e+11        true    

Estimated objective function value = 1.0343
Estimated function evaluation time = 612.2632

Elapsed time is 2057.540081 seconds.
Take a copy of the best attributes
Now use these optimum settings to do an exact GPR fit
Elapsed time is 26.657695 seconds.
Train a hyper-parameter optimized Ensemble of Trees model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|    1 |      16 | Best   |      1.8426 |      4.1287 |      1.8426 |      1.8426 |      LSBoost |           14 |      0.12124 |            3 |            7 |           26 |
|    2 |      16 | Accept |      3.2246 |      5.7812 |      1.8426 |       2.047 |      LSBoost |           20 |    0.0099026 |            3 |            4 |           24 |
|    3 |      14 | Best   |      1.2868 |       10.72 |      1.2868 |      1.2869 |      LSBoost |           73 |     0.031379 |            6 |         2885 |            2 |
|    4 |      14 | Accept |      1.4022 |      7.9104 |      1.2868 |      1.2869 |      LSBoost |           42 |      0.74289 |           69 |            2 |           25 |
|    5 |      14 | Accept |      2.6044 |      6.8026 |      1.2868 |      1.2869 |      LSBoost |          117 |     0.015645 |         1376 |          119 |            1 |
|    6 |      14 | Accept |      2.0435 |      3.0845 |      1.2868 |      1.3204 |      LSBoost |           14 |      0.12171 |            5 |            4 |           22 |
|    7 |      14 | Accept |      3.3816 |      14.364 |      1.2868 |      1.2867 |      LSBoost |           36 |    0.0021784 |            2 |           25 |           26 |
|    8 |      14 | Accept |      2.4783 |      18.342 |      1.2868 |      1.2869 |          Bag |          193 |            - |           20 |            1 |           15 |
|    9 |      14 | Accept |      2.4311 |      6.2524 |      1.2868 |      1.2867 |      LSBoost |           18 |     0.041006 |          116 |           11 |           31 |
|   10 |      14 | Accept |      3.3231 |      1.0461 |      1.2868 |       1.287 |      LSBoost |           25 |     0.011417 |         5050 |         7841 |           36 |
|   11 |      12 | Best   |      1.1883 |      27.507 |      1.1883 |      1.1982 |      LSBoost |          117 |     0.067352 |          468 |          942 |           17 |
|   12 |      12 | Accept |      1.8698 |      27.003 |      1.1883 |      1.1982 |          Bag |          108 |            - |          551 |           36 |           24 |
|   13 |      12 | Accept |      1.8804 |      9.6684 |      1.1883 |      1.1982 |      LSBoost |          149 |      0.45549 |         2663 |         4052 |           15 |
|   14 |      12 | Accept |      1.7126 |      2.3142 |      1.1883 |      1.2129 |      LSBoost |           21 |      0.07553 |           15 |        11133 |            2 |
|   15 |      11 | Accept |      2.4782 |        37.5 |      1.1883 |      1.1884 |          Bag |          399 |            - |           74 |            1 |           16 |
|   16 |      11 | Accept |      2.9529 |      9.8324 |      1.1883 |      1.1884 |          Bag |          189 |            - |         3943 |        11498 |            3 |
|   17 |      15 | Best   |     0.84598 |      39.339 |     0.84598 |     0.84614 |          Bag |           86 |            - |           14 |          919 |           14 |
|   18 |      15 | Accept |      1.3705 |      35.683 |     0.84598 |     0.84614 |          Bag |          101 |            - |           16 |           21 |           24 |
|   19 |      12 | Accept |      1.5617 |      25.177 |     0.84598 |     0.84613 |      LSBoost |          328 |      0.95313 |            2 |           31 |            2 |
|   20 |      12 | Accept |      1.6947 |      5.7425 |     0.84598 |     0.84613 |      LSBoost |           57 |     0.090959 |            1 |            4 |            6 |
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|   21 |      12 | Accept |      2.2269 |      4.0808 |     0.84598 |     0.84613 |      LSBoost |           30 |     0.056074 |         1546 |            3 |           29 |
|   22 |      12 | Accept |      2.8131 |      2.7284 |     0.84598 |     0.84613 |          Bag |           43 |            - |         4432 |          822 |           10 |
|   23 |      11 | Accept |      2.2509 |      18.957 |     0.84598 |     0.84617 |      LSBoost |          348 |     0.066506 |          672 |         1097 |            2 |
|   24 |      11 | Accept |      1.1587 |      52.797 |     0.84598 |     0.84617 |      LSBoost |          305 |      0.15799 |          524 |            7 |           14 |
|   25 |      11 | Accept |       2.846 |      10.085 |     0.84598 |     0.84617 |      LSBoost |           31 |     0.014043 |          254 |           14 |           25 |
|   26 |      16 | Best   |     0.72417 |      11.933 |     0.72417 |      0.7242 |          Bag |           21 |            - |            1 |          395 |           20 |
|   27 |      13 | Accept |      1.9985 |      17.035 |     0.72417 |      0.7242 |          Bag |          133 |            - |            1 |            4 |            8 |
|   28 |      13 | Accept |        3.27 |      63.281 |     0.72417 |      0.7242 |      LSBoost |          114 |    0.0011653 |            2 |         9447 |           13 |
|   29 |      13 | Accept |      2.1925 |      4.3147 |     0.72417 |      0.7242 |          Bag |           25 |            - |         1825 |           28 |           35 |
|   30 |      13 | Accept |      2.7182 |      5.7208 |     0.72417 |      0.7242 |      LSBoost |          125 |     0.017342 |         2848 |           94 |            1 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 69.2451 seconds.
Total objective function evaluation time: 489.1328

Best observed feasible point:
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             21               NaN            1             395                  20         

Observed objective function value = 0.72417
Estimated objective function value = 0.7242
Function evaluation time = 11.9331

Best estimated feasible point (according to models):
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             21               NaN            1             395                  20         

Estimated objective function value = 0.7242
Estimated function evaluation time = 11.934

Elapsed time is 72.383948 seconds.
Train the super learner model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      2.9781 |      161.51 |      2.9781 |      2.9781 |       12.046 |         none |     matern52 |   1.7213e+13 |        false |
|    2 |      16 | Accept |      2.9957 |      174.12 |      2.9781 |      2.9788 |       30.872 | pureQuadrati |     matern52 |   1.2653e+11 |        false |
