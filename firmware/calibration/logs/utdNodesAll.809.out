Running calibration scripts for UTD Node: 14
Running on host: compute-1-1-14

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
              R2020a Update 1 (9.8.0.1359463) 64-bit (glnxa64)
                               April 9, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 


    "---------------------MINTS---------------------"

30-Dec-2020 11:24:02

mintsDefinitions = 

  struct with fields:

                dataFolder: '/home/lhw150030/mintsData'
               poolWorkers: 16
                  timeSpan: 30
                  airmarID: '001e0610c0e4'
             binsPerColumn: 500
              numberPerBin: 2
                    pValid: 0.1500
                   nodeIDs: {1x16 cell}
               inputStack1: {1x9 cell}
         mintsInputsStack1: {1x35 cell}
    mintsInputLabelsStack1: {1x35 cell}
               inputStack2: {1x11 cell}
         mintsInputsStack2: {1x35 cell}
    mintsInputLabelsStack2: {1x35 cell}
               inputStack3: {1x10 cell}
         mintsInputsStack3: {1x38 cell}
    mintsInputLabelsStack3: {1x38 cell}
              mintsTargets: {1x10 cell}
         mintsTargetLabels: {1x10 cell}
                     units: {1x10 cell}
               instruments: {1x10 cell}

Starting parallel pool (parpool) using the 'local' profile ...
Connected to the parallel pool (number of workers: 16).

ans = 

 ProcessPool with properties: 

            Connected: true
           NumWorkers: 16
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


airmarFolder = 

    "/home/lhw150030/mintsData/referenceMats/airmar"

UTD_Rsl_All_2020_12_30_11_24_28


UTD_Rsl_All_Daily


Super Learner All Inputs




    "Data Folder Located @:/home/lhw150030/mintsData"

    "Raw Data Located @: /home/lhw150030/mintsData"

    "Raw DotMat Data Located @ :/home/lhw150030/mintsData/rawMats"

    "UTD Nodes DotMat Data Located @ :/home/lhw150030/mintsData/rawMats/UTDNodes"

    "Reference Data Located @: /home/lhw150030/mintsData/reference"

    "Reference DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats"

    "Palas Raw Data Located @ :/home/lhw150030/mintsData/reference/palasStream"

    "Palas DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats/palas"

    "Car GPS Files Located @ :/home/lhw150030/mintsData/referenceMats/carMintsGPS"

    "Loading Palas Files"

    "Loading GPS Files"

    "Loading Airmar Files"

    "Aligning GPS data with Palas Data"

    "WSTC Palas Data"

    "Palas With Airmar"

    "Analysis"

    "Save merged data for calibration: 001e06318cee"



    "Creating Training Data Sets for Node: 001e06318cee"



    "Gainin Data set for Node 001e06318cee with target output pm1_palas @ 30-Dec-2020 11:24:38"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 298 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 74 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 254 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 125 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 95 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 64 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 37 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 26 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 17 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 11 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 8 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 5 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 5 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 174 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 269 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 282 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 171 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 37 and choosing a representative sample. Choosing 144 bins for this column. With 2 members per bin.
Going through column 38 and choosing a representative sample. Choosing 279 bins for this column. With 2 members per bin.
Going through column 39 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        9376


ans =

        1655

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |       1 | Accept |      23.196 |      3.1948 |      7.5227 |      13.154 |           27 |     0.001529 |
|    2 |       1 | Accept |      40.492 |      3.2443 |      7.5227 |      13.154 |           48 |     0.091406 |
|    3 |       1 | Accept |      22.972 |      3.3612 |      7.5227 |      13.154 |           89 |      0.93138 |
|    4 |       1 | Accept |      31.346 |      3.3097 |      7.5227 |      13.154 |           33 |    0.0022331 |
|    5 |       1 | Accept |      13.244 |      3.2976 |      7.5227 |      13.154 |           83 |    0.0019744 |
|    6 |       1 | Best   |      7.5227 |      3.1355 |      7.5227 |      13.154 |           10 |     0.040147 |
|    7 |       1 | Accept |      19.424 |      3.0969 |      7.5227 |      13.154 |            7 |      0.34816 |
|    8 |       1 | Accept |        10.7 |      3.1378 |      7.5227 |      13.154 |           28 |    0.0018553 |
|    9 |       1 | Accept |      59.753 |      3.1973 |      7.5227 |      13.154 |           65 |     0.013762 |
|   10 |       1 | Accept |      35.711 |      3.1062 |      7.5227 |      13.154 |           11 |    0.0052673 |
|   11 |       1 | Accept |       30.16 |      3.0883 |      7.5227 |      13.154 |           32 |    0.0074776 |
|   12 |       1 | Accept |      51.318 |      3.1977 |      7.5227 |      13.154 |           61 |     0.018922 |
|   13 |       1 | Accept |       17.56 |      3.1862 |      7.5227 |      13.154 |           99 |     0.091972 |
|   14 |       1 | Accept |      57.061 |      3.1213 |      7.5227 |      13.154 |           35 |     0.028722 |
|   15 |       1 | Accept |      18.369 |      3.0907 |      7.5227 |      13.154 |           56 |      0.22458 |
|   16 |       1 | Accept |      21.948 |      3.0652 |      7.5227 |      13.154 |           10 |      0.18507 |
|   17 |      16 | Accept |      19.155 |     0.51358 |      7.5227 |      14.767 |            7 |     0.048055 |
|   18 |       2 | Accept |      68.316 |     0.72836 |      7.2756 |      24.482 |           83 |    0.0015094 |
|   19 |       2 | Accept |      77.795 |     0.66958 |      7.2756 |      24.482 |           93 |     0.030398 |
|   20 |       2 | Accept |       26.86 |     0.64184 |      7.2756 |      24.482 |           39 |      0.04902 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       2 | Accept |      34.149 |     0.65231 |      7.2756 |      24.482 |           77 |      0.74018 |
|   22 |       2 | Accept |      39.443 |     0.66465 |      7.2756 |      24.482 |           50 |      0.18868 |
|   23 |       2 | Accept |      104.62 |     0.70617 |      7.2756 |      24.482 |           89 |     0.094705 |
|   24 |       2 | Best   |      7.2756 |     0.56541 |      7.2756 |      24.482 |            6 |     0.013042 |
|   25 |       2 | Accept |      20.689 |     0.56389 |      7.2756 |      24.482 |           13 |      0.15478 |
|   26 |       2 | Accept |      33.738 |     0.68478 |      7.2756 |      24.482 |           67 |    0.0081014 |
|   27 |       2 | Accept |       19.82 |     0.54088 |      7.2756 |      24.482 |           14 |    0.0033477 |
|   28 |       2 | Accept |      10.645 |     0.55161 |      7.2756 |      24.482 |           35 |      0.91167 |
|   29 |       2 | Accept |      56.315 |     0.67133 |      7.2756 |      24.482 |           52 |     0.062081 |
|   30 |       2 | Accept |      28.966 |     0.66686 |      7.2756 |      24.482 |           61 |      0.03477 |
|   31 |       2 | Accept |      47.102 |     0.69261 |      7.2756 |      24.482 |           93 |    0.0023671 |
|   32 |       2 | Accept |      16.469 |     0.65326 |      7.2756 |      24.482 |           87 |     0.023974 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 32
Total elapsed time: 16.481 seconds.
Total objective function evaluation time: 60.9979

Best observed feasible point:
    hiddenLayerSize       lr   
    _______________    ________

           6           0.013042

Observed objective function value = 7.2756
Estimated objective function value = 23.9679
Function evaluation time = 0.56541

Best estimated feasible point (according to models):
    hiddenLayerSize      lr   
    _______________    _______

          13           0.15478

Estimated objective function value = 24.482
Estimated function evaluation time = 1.4168


T =

  1x2 table

    hiddenLayerSize      lr   
    _______________    _______

          13           0.15478

Elapsed time is 42.660916 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      3.1336 |      160.01 |      3.1336 |      3.1336 |      0.46244 |         none |     matern32 |    2.364e+10 |         true |
|    2 |      16 | Accept |      4.5381 |      223.04 |      3.1336 |      3.1895 |   0.00039875 | pureQuadrati |     matern32 |   2.6261e+12 |         true |
|    3 |      16 | Accept |      4.7333 |      233.61 |      3.1336 |      3.1351 |      0.54424 | pureQuadrati |     matern52 |   5.3751e+10 |         true |
|    4 |      16 | Accept |      3.1338 |      239.43 |      3.1336 |       3.134 |      0.29506 |     constant |     matern32 |   1.8503e+11 |         true |
|    5 |      16 | Best   |      3.1336 |      243.12 |      3.1336 |      3.1337 |      0.13724 |         none |     matern32 |   3.5722e+10 |         true |
|    6 |      16 | Best   |      3.1335 |      250.91 |      3.1335 |      3.1337 |       3.6578 |     constant |     matern32 |   7.0338e+11 |         true |
|    7 |      16 | Accept |      6.0422 |      256.27 |      3.1335 |      3.1337 |      0.11828 | pureQuadrati |     matern52 |    3.072e+12 |         true |
|    8 |      16 | Best   |      3.0479 |      297.57 |      3.0479 |      3.0479 |     0.015203 |       linear | rationalquad |   2.9185e+10 |         true |
|    9 |      16 | Accept |      3.1337 |      150.27 |      3.0479 |      3.0479 |       23.768 |         none |     matern32 |   7.7088e+10 |         true |
|   10 |      16 | Accept |      3.1338 |      241.94 |      3.0479 |      3.0479 |       36.753 |     constant |  exponential |   4.3532e+12 |         true |
|   11 |      16 | Accept |      3.4548 |      541.26 |      3.0479 |      3.0479 |    0.0046444 | pureQuadrati |     matern52 |   6.5679e+12 |        false |
|   12 |      16 | Accept |       3.366 |      544.15 |      3.0479 |      3.0479 |     0.053664 |       linear |     matern52 |   4.4393e+12 |        false |
|   13 |      16 | Accept |      3.1336 |      315.97 |      3.0479 |      3.0479 |     0.065585 |         none |     matern52 |   2.9143e+10 |         true |
|   14 |      16 | Accept |      3.3218 |      296.74 |      3.0479 |      3.0479 |     0.001905 |       linear | rationalquad |   7.2016e+12 |         true |
|   15 |      16 | Best   |       3.045 |      233.35 |       3.045 |       3.045 |      0.32802 |       linear | squaredexpon |   2.7099e+10 |         true |
|   16 |      16 | Accept |      6.7465 |      424.06 |       3.045 |       3.045 |      0.54213 |         none |     matern32 |   2.3467e+10 |        false |
|   17 |      16 | Accept |      3.1336 |      158.01 |       3.045 |       3.045 |       2.3942 |         none |     matern52 |   7.1082e+12 |         true |
|   18 |      16 | Accept |      5.6343 |      474.07 |       3.045 |       3.045 |   0.00010572 |     constant |     matern32 |   3.4996e+11 |        false |
|   19 |      16 | Accept |      3.1336 |      217.33 |       3.045 |       3.045 |       4.9621 |         none | rationalquad |   2.9836e+10 |         true |
|   20 |      16 | Best   |      1.0465 |      533.16 |      1.0465 |      1.0468 |      0.44164 |         none |  exponential |   1.4319e+10 |         true |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      16 | Accept |      3.3219 |      215.44 |      1.0465 |      1.0468 |   0.00020102 |       linear | squaredexpon |   7.2619e+12 |         true |
|   22 |      16 | Accept |      9.4271 |      673.28 |      1.0465 |      1.0468 |     0.002055 |     constant | rationalquad |   1.0381e+10 |        false |
|   23 |      16 | Accept |      3.1346 |      247.22 |      1.0465 |      1.0468 |      0.22181 |     constant |     matern52 |   1.1139e+11 |         true |
|   24 |      16 | Accept |      2.3778 |      332.65 |      1.0465 |      1.0468 |       4.5211 |       linear | rationalquad |   2.9645e+10 |        false |
|   25 |      16 | Accept |      4.7184 |      242.06 |      1.0465 |      1.0468 |       15.762 | pureQuadrati | squaredexpon |    2.665e+10 |         true |
|   26 |      16 | Accept |      3.1336 |      158.94 |      1.0465 |      1.0472 |       1.0613 |         none |  exponential |   2.7965e+12 |         true |
|   27 |      16 | Accept |      3.2716 |      220.86 |      1.0465 |      1.0472 |    0.0064803 |       linear |     matern52 |   7.8588e+09 |         true |
|   28 |      16 | Accept |      3.1336 |      290.71 |      1.0465 |      1.0472 |      0.33777 |         none | squaredexpon |   2.5214e+10 |         true |
|   29 |      16 | Best   |      1.0426 |      556.34 |      1.0426 |       1.043 |     0.092087 |     constant |  exponential |   7.2774e+09 |         true |
|   30 |      16 | Accept |      3.4902 |       215.5 |      1.0426 |       1.043 |   0.00077297 |       linear |     matern32 |   7.4043e+09 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 1181.388 seconds.
Total objective function evaluation time: 9187.2715

Best observed feasible point:
     Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    ________    _____________    ______________    ___________    ___________

    0.092087      constant        exponential      7.2774e+09        true    

Observed objective function value = 1.0426
Estimated objective function value = 1.043
Function evaluation time = 556.3375

Best estimated feasible point (according to models):
     Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    ________    _____________    ______________    ___________    ___________

    0.092087      constant        exponential      7.2774e+09        true    

Estimated objective function value = 1.043
Estimated function evaluation time = 447.3917

Elapsed time is 1205.478320 seconds.
Take a copy of the best attributes
Now use these optimum settings to do an exact GPR fit
Elapsed time is 9.381884 seconds.
Train a hyper-parameter optimized Ensemble of Trees model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|    1 |      15 | Accept |      3.6545 |      3.5453 |      3.1337 |       3.162 |      LSBoost |           13 |    0.0019022 |           66 |            3 |           37 |
|    2 |      15 | Best   |      3.1337 |      3.6556 |      3.1337 |       3.162 |      LSBoost |           73 |     0.081055 |         3950 |         6383 |           30 |
|    3 |      10 | Accept |      3.6301 |       5.082 |      2.0815 |      2.0816 |      LSBoost |           14 |    0.0023885 |           11 |         2965 |           10 |
|    4 |      10 | Accept |      3.5694 |      6.3409 |      2.0815 |      2.0816 |      LSBoost |           70 |    0.0013397 |           50 |            1 |           17 |
|    5 |      10 | Best   |      2.0815 |      5.1605 |      2.0815 |      2.0816 |      LSBoost |           30 |     0.078763 |          130 |            3 |           24 |
|    6 |      10 | Accept |      3.0029 |      5.7178 |      2.0815 |      2.0816 |      LSBoost |           84 |      0.01588 |         1959 |           78 |           10 |
|    7 |      10 | Accept |      3.6646 |      5.7484 |      2.0815 |      2.0816 |      LSBoost |           12 |      0.00123 |           44 |          219 |           19 |
|    8 |      10 | Accept |       2.821 |      4.1335 |      2.0815 |      2.0816 |          Bag |           53 |            - |          101 |            2 |            3 |
|    9 |      15 | Accept |      2.6011 |      8.4489 |      2.0815 |      2.0816 |          Bag |          131 |            - |         3328 |         6604 |           15 |
|   10 |      15 | Accept |      2.3626 |      3.7078 |      2.0815 |      2.0816 |      LSBoost |           57 |      0.11075 |         2221 |         6740 |           23 |
|   11 |      12 | Best   |      1.5821 |      14.001 |      1.5821 |      1.6644 |      LSBoost |           88 |      0.20385 |          841 |            4 |           25 |
|   12 |      12 | Accept |      1.7564 |      1.9483 |      1.5821 |      1.6644 |      LSBoost |           14 |      0.14165 |           65 |           18 |            9 |
|   13 |      12 | Accept |      3.1484 |      3.2821 |      1.5821 |      1.6644 |      LSBoost |           11 |     0.026884 |            6 |          914 |            8 |
|   14 |      12 | Accept |      3.1336 |     0.94835 |      1.5821 |      1.6644 |          Bag |           14 |            - |         3787 |            2 |            4 |
|   15 |      13 | Accept |      2.0337 |      3.4979 |      1.5821 |      1.6493 |      LSBoost |           11 |      0.10443 |          110 |          222 |           20 |
|   16 |      11 | Best   |      1.2986 |      8.4981 |      1.2986 |      1.3175 |      LSBoost |           47 |      0.43926 |          449 |            8 |           18 |
|   17 |      11 | Accept |      3.1337 |      1.5529 |      1.2986 |      1.3175 |      LSBoost |           43 |      0.48342 |         3845 |            1 |            2 |
|   18 |      11 | Accept |      2.3992 |      2.3605 |      1.2986 |      1.3175 |      LSBoost |           40 |      0.39233 |          740 |            1 |            9 |
|   19 |      16 | Accept |      1.4397 |      24.622 |      1.2986 |      1.2989 |      LSBoost |          123 |     0.017247 |           59 |          171 |            9 |
|   20 |      13 | Best   |      1.0235 |      15.851 |      1.0235 |       1.024 |      LSBoost |           76 |     0.056782 |           79 |         4579 |           11 |
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|   21 |      13 | Accept |      1.2321 |      15.182 |      1.0235 |       1.024 |          Bag |           30 |            - |           15 |           62 |           34 |
|   22 |      13 | Accept |      2.5741 |      4.6098 |      1.0235 |       1.024 |      LSBoost |           86 |      0.31346 |           44 |            1 |           10 |
|   23 |      13 | Accept |      2.8671 |      1.4001 |      1.0235 |       1.024 |      LSBoost |           20 |     0.045349 |         3183 |         4294 |           15 |
|   24 |      12 | Accept |      2.5162 |      32.618 |      1.0235 |      1.0239 |      LSBoost |          188 |    0.0043625 |            2 |           27 |           13 |
|   25 |      12 | Accept |      2.8322 |      7.0196 |      1.0235 |      1.0239 |      LSBoost |           32 |     0.020569 |           18 |           13 |           19 |
|   26 |      12 | Accept |      1.7616 |      30.048 |      1.0235 |      1.0237 |          Bag |          165 |            - |          133 |          544 |           12 |
|   27 |      12 | Accept |      2.4798 |      3.1952 |      1.0235 |      1.0237 |      LSBoost |           18 |     0.042269 |           74 |          121 |            7 |
|   28 |      12 | Accept |       1.626 |      16.592 |      1.0235 |      1.0237 |          Bag |           44 |            - |          138 |           21 |           31 |
|   29 |      11 | Accept |      1.8911 |      18.295 |      1.0235 |      1.0237 |          Bag |           53 |            - |          330 |         2325 |           35 |
|   30 |      11 | Accept |      2.7693 |      4.1105 |      1.0235 |      1.0237 |      LSBoost |           20 |     0.029663 |          106 |         1494 |           12 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 51.0801 seconds.
Total objective function evaluation time: 261.1738

Best observed feasible point:
    Method     NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    _______    _________________    _________    ___________    ____________    ____________________

    LSBoost           76            0.056782         79             4579                 11         

Observed objective function value = 1.0235
Estimated objective function value = 1.0237
Function evaluation time = 15.851

Best estimated feasible point (according to models):
    Method     NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    _______    _________________    _________    ___________    ____________    ____________________

    LSBoost           76            0.056782         79             4579                 11         

Estimated objective function value = 1.0237
Estimated function evaluation time = 15.8452

Elapsed time is 54.490502 seconds.
Train the super learner model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      3.1331 |      160.38 |      3.1331 |      3.1331 |       10.925 | pureQuadrati |     matern32 |   4.8539e+12 |        false |
|    2 |      16 | Accept |      3.1338 |       234.9 |      3.1331 |      3.1332 |      0.28903 |     constant |  exponential |   3.1214e+10 |         true |
|    3 |      16 | Best   |    0.024788 |         259 |    0.024788 |     0.15112 |      0.15551 |       linear |     matern52 |   5.8818e+11 |         true |
|    4 |      16 | Accept |    0.025482 |      296.38 |    0.024788 |    0.024998 |     0.005149 |       linear | rationalquad |   1.1577e+12 |         true |
|    5 |      16 | Accept |      1.2173 |      301.62 |    0.024788 |    0.025446 |    0.0074679 | pureQuadrati | rationalquad |   3.2163e+10 |         true |
|    6 |      16 | Accept |    0.026396 |      340.67 |    0.024788 |    0.026027 |       2.3124 |       linear | rationalquad |   8.3825e+09 |         true |
