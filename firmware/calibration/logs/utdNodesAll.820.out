Running calibration scripts for UTD Node: 10
Running on host: compute-1-1-25

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
              R2020a Update 1 (9.8.0.1359463) 64-bit (glnxa64)
                               April 9, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 


    "---------------------MINTS---------------------"

30-Dec-2020 11:24:35

mintsDefinitions = 

  struct with fields:

                dataFolder: '/home/lhw150030/mintsData'
               poolWorkers: 16
                  timeSpan: 30
                  airmarID: '001e0610c0e4'
             binsPerColumn: 500
              numberPerBin: 2
                    pValid: 0.1500
                   nodeIDs: {1x16 cell}
               inputStack1: {1x9 cell}
         mintsInputsStack1: {1x35 cell}
    mintsInputLabelsStack1: {1x35 cell}
               inputStack2: {1x11 cell}
         mintsInputsStack2: {1x35 cell}
    mintsInputLabelsStack2: {1x35 cell}
               inputStack3: {1x10 cell}
         mintsInputsStack3: {1x38 cell}
    mintsInputLabelsStack3: {1x38 cell}
              mintsTargets: {1x10 cell}
         mintsTargetLabels: {1x10 cell}
                     units: {1x10 cell}
               instruments: {1x10 cell}

Starting parallel pool (parpool) using the 'local' profile ...
Connected to the parallel pool (number of workers: 16).

ans = 

 ProcessPool with properties: 

            Connected: true
           NumWorkers: 16
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


airmarFolder = 

    "/home/lhw150030/mintsData/referenceMats/airmar"

UTD_Rsl_All_2020_12_30_11_25_01


UTD_Rsl_All_Daily


Super Learner All Inputs




    "Data Folder Located @:/home/lhw150030/mintsData"

    "Raw Data Located @: /home/lhw150030/mintsData"

    "Raw DotMat Data Located @ :/home/lhw150030/mintsData/rawMats"

    "UTD Nodes DotMat Data Located @ :/home/lhw150030/mintsData/rawMats/UTDNodes"

    "Reference Data Located @: /home/lhw150030/mintsData/reference"

    "Reference DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats"

    "Palas Raw Data Located @ :/home/lhw150030/mintsData/reference/palasStream"

    "Palas DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats/palas"

    "Car GPS Files Located @ :/home/lhw150030/mintsData/referenceMats/carMintsGPS"

    "Loading Palas Files"

    "Loading GPS Files"

    "Loading Airmar Files"

    "Aligning GPS data with Palas Data"

    "WSTC Palas Data"

    "Palas With Airmar"

    "Analysis"

    "Save merged data for calibration: 001e063239e3"



    "Creating Training Data Sets for Node: 001e063239e3"



    "Gainin Data set for Node 001e063239e3 with target output pm1_palas @ 30-Dec-2020 11:25:12"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 299 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 76 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 133 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 111 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 60 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 22 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 13 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 11 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 7 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 6 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 155 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 244 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 246 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 148 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        8038


ans =

        1419

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |       2 | Accept |      10.903 |       2.921 |      7.0037 |      8.1996 |           24 |       0.1659 |
|    2 |       2 | Accept |      9.5087 |      2.8998 |      7.0037 |      8.1996 |            9 |    0.0028208 |
|    3 |       2 | Accept |      29.965 |      2.8013 |      7.0037 |      8.1996 |           43 |     0.019788 |
|    4 |       2 | Accept |      42.736 |      2.9179 |      7.0037 |      8.1996 |           84 |    0.0014447 |
|    5 |       2 | Accept |      29.353 |       2.813 |      7.0037 |      8.1996 |           56 |     0.020696 |
|    6 |       2 | Accept |      51.424 |      2.7884 |      7.0037 |      8.1996 |           30 |    0.0015317 |
|    7 |       2 | Accept |      11.997 |       2.754 |      7.0037 |      8.1996 |           34 |     0.073685 |
|    8 |       2 | Accept |      32.058 |      2.8881 |      7.0037 |      8.1996 |          100 |    0.0023815 |
|    9 |       2 | Accept |      8.1308 |      2.7005 |      7.0037 |      8.1996 |           24 |     0.085218 |
|   10 |       2 | Accept |      16.233 |      2.8035 |      7.0037 |      8.1996 |           62 |    0.0063237 |
|   11 |       2 | Accept |      14.467 |      2.7094 |      7.0037 |      8.1996 |           22 |    0.0017766 |
|   12 |       2 | Accept |      29.899 |      2.8327 |      7.0037 |      8.1996 |           78 |      0.71431 |
|   13 |       2 | Accept |       23.14 |      2.7575 |      7.0037 |      8.1996 |           72 |     0.033848 |
|   14 |       2 | Accept |      15.238 |      2.7086 |      7.0037 |      8.1996 |           55 |      0.17535 |
|   15 |       2 | Best   |      7.0037 |      2.6733 |      7.0037 |      8.1996 |            9 |    0.0018544 |
|   16 |      16 | Accept |      79.405 |      3.0304 |      7.0037 |      7.0129 |           96 |       0.9358 |
|   17 |       2 | Accept |      8.5762 |     0.59413 |      7.0037 |      17.249 |           24 |     0.001019 |
|   18 |       2 | Accept |      11.079 |     0.61992 |      7.0037 |      17.249 |           28 |    0.0072207 |
|   19 |       2 | Accept |       10.47 |     0.63698 |      7.0037 |      17.249 |           23 |     0.096716 |
|   20 |       2 | Accept |      36.021 |     0.66452 |      7.0037 |      17.249 |           56 |    0.0045918 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       2 | Accept |       35.18 |     0.68715 |      7.0037 |      17.249 |           90 |     0.088279 |
|   22 |       2 | Accept |       22.54 |     0.63277 |      7.0037 |      17.249 |           64 |    0.0027993 |
|   23 |       2 | Accept |      34.512 |     0.61904 |      7.0037 |      17.249 |           54 |     0.055492 |
|   24 |       2 | Accept |       27.15 |     0.60921 |      7.0037 |      17.249 |            6 |     0.032818 |
|   25 |       2 | Accept |      16.277 |     0.50748 |      7.0037 |      17.249 |            7 |    0.0052382 |
|   26 |       2 | Accept |      53.679 |     0.58037 |      7.0037 |      17.249 |           36 |     0.040434 |
|   27 |       2 | Accept |       46.31 |     0.68297 |      7.0037 |      17.249 |           94 |     0.049221 |
|   28 |       2 | Accept |      96.838 |     0.63116 |      7.0037 |      17.249 |           70 |      0.06392 |
|   29 |       2 | Accept |      8.1551 |     0.58298 |      7.0037 |      17.249 |           14 |      0.15646 |
|   30 |       2 | Accept |      17.909 |     0.62557 |      7.0037 |      17.249 |           44 |     0.018141 |
|   31 |       2 | Accept |      33.717 |     0.67224 |      7.0037 |      17.249 |           46 |     0.015511 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 31
Total elapsed time: 14.7569 seconds.
Total objective function evaluation time: 54.3459

Best observed feasible point:
    hiddenLayerSize       lr    
    _______________    _________

           9           0.0018544

Observed objective function value = 7.0037
Estimated objective function value = 16.7653
Function evaluation time = 2.6733

Best estimated feasible point (according to models):
    hiddenLayerSize      lr   
    _______________    _______

          14           0.15646

Estimated objective function value = 17.2487
Estimated function evaluation time = 1.3542


T =

  1x2 table

    hiddenLayerSize      lr   
    _______________    _______

          14           0.15646

Elapsed time is 21.685637 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      3.6502 |      155.66 |      3.6502 |      3.6502 |      0.32008 |         none |     matern52 |   1.8542e+12 |         true |
|    2 |      16 | Accept |      6.6633 |      225.09 |      3.6502 |        3.77 |   0.00015387 |       linear | squaredexpon |   6.3289e+10 |         true |
|    3 |      16 | Best   |      3.6502 |      230.74 |      3.6502 |      3.7114 |     0.020157 |     constant |     matern32 |   4.8284e+11 |         true |
|    4 |      16 | Best   |      3.1519 |      236.38 |      3.1519 |      3.2135 |       7.1826 |       linear |     matern32 |   4.3934e+11 |         true |
|    5 |      16 | Accept |      3.6507 |      228.92 |      3.1519 |      3.1521 |    0.0011899 |     constant |     matern32 |   3.2084e+10 |         true |
|    6 |      16 | Accept |      5.2795 |      228.77 |      3.1519 |      3.2369 |       10.663 |       linear |     matern32 |   2.5736e+10 |         true |
|    7 |      16 | Error  |         NaN |      475.77 |      3.1519 |      3.2369 |    0.0082959 |       linear |     matern32 |   3.5355e+11 |        false |
|    8 |      16 | Accept |      6.1982 |      534.75 |      3.1519 |      3.1533 |   0.00029846 |       linear |     matern32 |   2.4501e+12 |        false |
|    9 |      16 | Accept |      3.3832 |      542.29 |      3.1519 |       3.249 |      0.35358 |       linear |     matern52 |   5.0466e+11 |        false |
|   10 |      16 | Best   |      3.0075 |      616.44 |      3.0075 |      3.1182 |       3.7465 |       linear |     matern32 |   3.6926e+12 |        false |
|   11 |      16 | Accept |      3.6502 |      152.27 |      3.0075 |      3.0496 |        5.179 |         none |     matern32 |   1.3863e+12 |         true |
|   12 |      16 | Accept |       6.363 |      211.05 |      3.0075 |      4.1976 |      0.60998 |       linear |     matern32 |   5.5162e+11 |         true |
|   13 |      16 | Accept |      3.6502 |      470.97 |      3.0075 |      4.1873 |     0.004043 |         none |     matern52 |   9.8349e+11 |         true |
|   14 |      16 | Accept |      6.9714 |      239.59 |      3.0075 |      3.0077 |     0.050739 |       linear |     matern32 |    3.808e+11 |         true |
|   15 |      16 | Accept |      3.6508 |      235.75 |      3.0075 |      3.0078 |   0.00013225 |     constant |     matern32 |   1.2392e+11 |         true |
|   16 |      16 | Accept |       5.661 |      229.49 |      3.0075 |      4.0113 |       57.789 |       linear |     matern32 |   3.8619e+11 |         true |
|   17 |      16 | Accept |      6.3858 |      227.76 |      3.0075 |      3.9031 |   0.00033055 |       linear |     matern32 |   3.3857e+11 |         true |
|   18 |      16 | Accept |      8.8236 |      235.71 |      3.0075 |      4.1734 |       15.938 |       linear |     matern32 |   7.7698e+11 |         true |
|   19 |      16 | Best   |      2.9938 |       248.1 |      2.9938 |      4.0633 |       47.776 |       linear |     matern52 |   3.0107e+11 |        false |
|   20 |      16 | Best   |      2.9911 |      253.15 |      2.9911 |      4.0204 |       19.288 |       linear |     matern32 |   1.5056e+12 |        false |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      16 | Best   |      2.7287 |      418.24 |      2.7287 |      3.6736 |       1.6896 |       linear |     matern32 |   4.3498e+12 |        false |
|   22 |      16 | Accept |      3.6502 |      222.48 |      2.7287 |      3.6799 |      0.50302 |     constant |     matern52 |   3.9733e+11 |         true |
|   23 |      16 | Accept |      5.6914 |      239.17 |      2.7287 |      3.7051 |       3.0163 |       linear |     matern52 |   3.8576e+11 |         true |
|   24 |      16 | Accept |      2.9932 |      660.92 |      2.7287 |      3.5274 |       4.7747 |       linear |     matern32 |   4.0706e+12 |        false |
|   25 |      16 | Accept |      3.6502 |      531.22 |      2.7287 |      3.4897 |   0.00010165 |         none |     matern32 |    2.158e+12 |         true |
|   26 |      16 | Error  |         NaN |      431.31 |      2.7287 |      3.4897 |      0.29164 |         none |     matern52 |    3.745e+11 |        false |
|   27 |      16 | Accept |      3.6455 |      138.36 |      2.7287 |      3.4943 |       38.113 | pureQuadrati |     matern52 |   5.1877e+11 |        false |
|   28 |      16 | Accept |      4.3284 |      567.32 |      2.7287 |      3.4983 |     0.021511 |       linear |     matern52 |   1.2893e+12 |        false |
|   29 |      16 | Accept |      2.9967 |      332.93 |      2.7287 |       3.489 |        58.82 |       linear | rationalquad |   4.8746e+11 |        false |
|   30 |      16 | Error  |         NaN |      492.93 |      2.7287 |       3.489 |    0.0019459 |     constant |     matern32 |   1.3928e+11 |        false |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 1559.5463 seconds.
Total objective function evaluation time: 10013.5254

Best observed feasible point:
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    1.6896       linear           matern32       4.3498e+12        false   

Observed objective function value = 2.7287
Estimated objective function value = 3.6055
Function evaluation time = 418.236

Best estimated feasible point (according to models):
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    19.288       linear           matern32       1.5056e+12        false   

Estimated objective function value = 3.489
Estimated function evaluation time = 253.1742

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 29)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 1569.139295 seconds.
Take a copy of the best attributes
Now use these optimum settings to do an exact GPR fit
[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In fitrsuperOptimized (line 51)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 7.608980 seconds.
Train a hyper-parameter optimized Ensemble of Trees model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|    1 |      16 | Best   |      1.9418 |      3.4785 |      1.9418 |      1.9418 |      LSBoost |           20 |      0.40378 |          155 |          702 |            7 |
|    2 |      13 | Accept |      2.6476 |      4.4453 |      1.9418 |      2.0019 |          Bag |           38 |            - |           30 |            8 |            7 |
|    3 |      13 | Accept |      3.9848 |      4.5745 |      1.9418 |      2.0019 |      LSBoost |           19 |      0.01477 |            2 |            6 |           32 |
|    4 |      13 | Accept |      2.9764 |      3.5054 |      1.9418 |      2.0019 |          Bag |           40 |            - |          908 |           78 |            7 |
|    5 |      13 | Accept |      3.8639 |      3.4484 |      1.9418 |      2.0019 |      LSBoost |           23 |      0.02052 |          718 |          264 |           15 |
|    6 |      13 | Accept |      3.2376 |       5.498 |      1.9418 |      1.9419 |          Bag |           51 |            - |         1310 |          187 |           18 |
|    7 |      12 | Accept |      2.2269 |      7.7365 |      1.9418 |      1.9419 |          Bag |           26 |            - |           11 |            9 |           34 |
|    8 |      12 | Accept |        3.96 |      7.3544 |      1.9418 |      1.9419 |      LSBoost |          100 |    0.0038697 |         1210 |           10 |           12 |
|    9 |      11 | Accept |       3.325 |      10.124 |      1.4294 |      1.4296 |          Bag |          130 |            - |         2009 |           25 |           20 |
|   10 |      11 | Best   |      1.4294 |      12.315 |      1.4294 |      1.4296 |          Bag |           35 |            - |           33 |          181 |           20 |
|   11 |      14 | Accept |      3.6744 |      15.099 |      1.1659 |       1.174 |      LSBoost |           86 |     0.005881 |            3 |            5 |           27 |
|   12 |      14 | Accept |      3.1459 |      14.145 |      1.1659 |       1.174 |      LSBoost |          127 |     0.012502 |            4 |            2 |           20 |
|   13 |      14 | Best   |      1.1659 |       3.032 |      1.1659 |       1.174 |          Bag |           10 |            - |            1 |         3479 |            9 |
|   14 |      12 | Accept |      4.2231 |      17.318 |      1.1659 |      1.1709 |      LSBoost |           47 |    0.0026003 |           19 |           44 |           33 |
|   15 |      12 | Accept |      4.3168 |      2.1285 |      1.1659 |      1.1709 |      LSBoost |           31 |    0.0033858 |           73 |         3199 |            3 |
|   16 |      12 | Accept |      4.3578 |      3.6984 |      1.1659 |      1.1709 |      LSBoost |           37 |    0.0016113 |          332 |           68 |           10 |
|   17 |      10 | Accept |      3.6879 |      21.858 |      1.1659 |      1.1678 |      LSBoost |           99 |    0.0041427 |            1 |          420 |            9 |
|   18 |      10 | Accept |      1.8557 |      23.199 |      1.1659 |      1.1678 |          Bag |          116 |            - |           63 |          157 |           13 |
|   19 |      10 | Accept |      4.2055 |      5.0255 |      1.1659 |      1.1678 |      LSBoost |           15 |    0.0089784 |           66 |          292 |           24 |
|   20 |      14 | Accept |      2.3284 |      22.555 |      1.1649 |      1.1663 |      LSBoost |          228 |     0.030584 |         1299 |           11 |           29 |
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|   21 |      14 | Best   |      1.1649 |      17.832 |      1.1649 |      1.1663 |      LSBoost |           14 |      0.82213 |            7 |         1006 |           28 |
|   22 |      14 | Accept |      1.2624 |      2.4616 |      1.1649 |      1.1663 |          Bag |           10 |            - |            9 |         1708 |            8 |
|   23 |      12 | Best   |      1.0587 |      10.414 |      1.0587 |      1.0449 |          Bag |           23 |            - |            2 |          425 |           22 |
|   24 |      12 | Accept |      2.5835 |      1.9254 |      1.0587 |      1.0449 |      LSBoost |           21 |      0.58966 |         1186 |            5 |           22 |
|   25 |      12 | Accept |      3.2891 |     0.83594 |      1.0587 |      1.0449 |          Bag |           11 |            - |         2136 |          181 |           27 |
|   26 |      12 | Accept |      1.4136 |      6.0869 |      1.0587 |      1.0956 |          Bag |           19 |            - |            1 |          139 |           20 |
|   27 |      14 | Best   |     0.85552 |      45.473 |     0.85552 |     0.92095 |      LSBoost |           86 |     0.067076 |           40 |          121 |           30 |
|   28 |      14 | Accept |      3.6489 |      20.835 |     0.85552 |     0.89247 |          Bag |          434 |            - |            1 |         1228 |            1 |
|   29 |      12 | Accept |      3.6537 |      38.279 |     0.85552 |     0.90563 |      LSBoost |          204 |    0.0025536 |          573 |         2928 |           35 |
|   30 |      12 | Accept |      3.1678 |      24.321 |     0.85552 |     0.90563 |      LSBoost |          342 |     0.011386 |            2 |            1 |           19 |
|   31 |      12 | Accept |      4.1291 |      23.022 |     0.85552 |     0.90563 |      LSBoost |           26 |     0.006347 |            1 |         7358 |           32 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 31
Total elapsed time: 60.4542 seconds.
Total objective function evaluation time: 382.0235

Best observed feasible point:
    Method     NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    _______    _________________    _________    ___________    ____________    ____________________

    LSBoost           86            0.067076         40             121                  30         

Observed objective function value = 0.85552
Estimated objective function value = 0.90563
Function evaluation time = 45.4731

Best estimated feasible point (according to models):
    Method     NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    _______    _________________    _________    ___________    ____________    ____________________

    LSBoost           86            0.067076         40             121                  30         

Estimated objective function value = 0.90563
Estimated function evaluation time = 45.4608

Elapsed time is 64.535745 seconds.
Train the super learner model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      3.6348 |      143.85 |      3.6348 |      3.6348 |       13.974 |         none |     matern32 |   1.5537e+12 |        false |
|    2 |      16 | Error  |         NaN |      218.95 |         NaN |      3.6348 |      0.41519 |         none |  exponential |   3.7679e+10 |        false |
|    3 |      16 | Accept |      5.3365 |      236.33 |      3.6348 |      4.4505 |      0.16951 |       linear |     matern32 |   4.4257e+11 |         true |
|    4 |      16 | Best   |     0.39634 |      475.52 |     0.39634 |     0.56253 |       33.545 |       linear | rationalquad |    2.215e+10 |        false |
|    5 |      16 | Accept |      3.6501 |      334.51 |     0.39634 |     0.39838 |       59.555 |         none |     matern32 |   1.6715e+12 |         true |
|    6 |      16 | Error  |         NaN |       726.9 |     0.39634 |     0.39838 |    0.0071781 |       linear |     matern32 |   2.5874e+11 |        false |
|    7 |      16 | Best   |     0.37263 |      535.23 |     0.37263 |     0.39061 |    0.0013202 |       linear |     matern52 |   1.6033e+11 |         true |
|    8 |      16 | Accept |      10.138 |      880.14 |     0.37263 |       1.853 |     0.011874 |         none |     matern52 |   2.1857e+12 |        false |
|    9 |      16 | Accept |      6.0954 |      1104.9 |     0.37263 |      1.2142 |     0.052191 | pureQuadrati |     matern52 |   3.0798e+12 |        false |
|   10 |      16 | Best   |     0.36688 |      548.99 |     0.36688 |     0.36998 |   0.00070979 |       linear |     matern52 |   1.3598e+11 |         true |
|   11 |      16 | Accept |     0.36739 |      1435.5 |     0.36688 |     0.36994 |       0.9256 |       linear | squaredexpon |   8.0677e+12 |        false |
|   12 |      16 | Accept |      3.8349 |      545.01 |     0.36688 |      1.9873 |    0.0014082 |       linear |     matern52 |   1.3752e+11 |         true |
|   13 |      16 | Accept |     0.36786 |      1857.5 |     0.36688 |     0.90309 |      0.88938 |       linear | squaredexpon |   2.6666e+11 |        false |
|   14 |      16 | Accept |     0.39841 |      518.91 |     0.36688 |     0.64464 |       11.313 |       linear | squaredexpon |   2.0042e+13 |        false |
|   15 |      16 | Accept |       1.201 |      661.93 |     0.36688 |     0.63994 |   0.00071472 |       linear | rationalquad |    3.331e+10 |         true |
|   16 |      16 | Accept |     0.39695 |      825.74 |     0.36688 |     0.57773 |       34.497 |       linear | rationalquad |   4.9407e+10 |        false |
|   17 |      16 | Accept |     0.65816 |      1777.2 |     0.36688 |     0.54398 |      0.05384 |       linear | rationalquad |   2.0623e+13 |        false |
|   18 |      16 | Accept |      1.7537 |      533.55 |     0.36688 |     0.54823 |         29.3 |       linear | squaredexpon |    3.149e+10 |         true |
|   19 |      16 | Accept |      6.2031 |      1125.6 |     0.36688 |     0.56223 |   0.00010502 | pureQuadrati | squaredexpon |    7.618e+12 |        false |
|   20 |      16 | Accept |        3.65 |      1977.9 |     0.36688 |     0.57831 |       52.968 |         none | rationalquad |   3.3332e+10 |        false |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 2721.9057 seconds.
Total objective function evaluation time: 16464.1923

Best observed feasible point:
      Sigma       BasisFunction    KernelFunction    KernelScale    Standardize
    __________    _____________    ______________    ___________    ___________

    0.00070979       linear           matern52       1.3598e+11        true    

Observed objective function value = 0.36688
Estimated objective function value = 1.6536
Function evaluation time = 548.9919

Best estimated feasible point (according to models):
    Sigma     BasisFunction      KernelFunction      KernelScale    Standardize
    ______    _____________    __________________    ___________    ___________

    0.9256       linear        squaredexponential    8.0677e+12        false   

Estimated objective function value = 0.57831
Estimated function evaluation time = 1435.3026

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 90)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 2760.739830 seconds.
Train the super learner error model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |       4.048 |      502.33 |       4.048 |       4.048 |     0.049253 | pureQuadrati |     matern52 |   4.6231e+10 |         true |
|    2 |      16 | Best   |     0.63848 |       520.1 |     0.63848 |     0.93263 |      0.47264 |       linear |     matern32 |     7.84e+12 |         true |
|    3 |      16 | Best   |      0.3652 |      538.89 |      0.3652 |     0.50948 |      0.16964 |     constant |     matern52 |   3.2343e+11 |         true |
|    4 |      16 | Accept |     0.36529 |      544.62 |      0.3652 |     0.43447 |       3.7559 |     constant |     matern32 |   1.6987e+13 |        false |
|    5 |      16 | Best   |     0.36511 |      763.03 |     0.36511 |     0.42077 |       2.2528 |         none | rationalquad |    4.504e+12 |        false |
|    6 |      16 | Accept |      0.3652 |         444 |     0.36511 |     0.36529 |      0.40026 |     constant |     matern32 |   6.0384e+12 |        false |
|    7 |      16 | Accept |      4.4396 |      1087.2 |     0.36511 |     0.36532 |   0.00023585 | pureQuadrati |     matern32 |   4.0046e+12 |         true |
|    8 |      16 | Accept |      2.7908 |      568.98 |     0.36511 |     0.80261 |     0.073252 |       linear |     matern32 |   1.0897e+13 |         true |
|    9 |      16 | Accept |      2.1139 |      1117.7 |     0.36511 |     0.88914 |    0.0003138 |       linear |     matern32 |   6.4801e+12 |        false |
|   10 |      16 | Accept |     0.36512 |      765.48 |     0.36511 |     0.36519 |       1.0841 |         none | rationalquad |   1.1603e+13 |        false |
|   11 |      16 | Accept |     0.36522 |      1091.7 |     0.36511 |     0.36519 |    0.0046532 |     constant |     matern52 |   4.1735e+11 |         true |
|   12 |      16 | Accept |     0.69724 |      1702.9 |     0.36511 |     0.36518 |   0.00011741 |         none | rationalquad |   2.0574e+12 |        false |
|   13 |      16 | Accept |     0.36533 |       905.3 |     0.36511 |     0.36437 |       4.6148 |     constant |     matern32 |   5.0362e+10 |        false |
|   14 |      16 | Accept |      2.6323 |       547.6 |     0.36511 |      0.4603 |       3.6575 |       linear |     matern32 |   1.5611e+13 |         true |
|   15 |      16 | Accept |      0.3653 |      1068.7 |     0.36511 |     0.45299 |   0.00015525 |     constant |     matern32 |   2.4183e+12 |         true |
|   16 |      16 | Accept |      2.3657 |      1157.2 |     0.36511 |     0.46623 |     0.019618 |     constant |     matern52 |   1.0433e+13 |        false |
|   17 |      16 | Error  |         NaN |      1087.9 |     0.36511 |     0.46623 |    0.0030324 |     constant |     matern32 |   2.1094e+10 |        false |
|   18 |      16 | Accept |      0.3652 |      535.46 |     0.36511 |     0.46021 |      0.76875 |     constant |  exponential |   1.8093e+12 |        false |
|   19 |      16 | Best   |     0.36511 |       551.5 |     0.36511 |     0.45602 |       3.5752 |         none |     matern52 |   2.5893e+10 |         true |
|   20 |      16 | Accept |     0.36526 |      1087.2 |     0.36511 |     0.44237 |     0.028191 |     constant |     matern52 |   4.0163e+10 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 2742.2814 seconds.
Total objective function evaluation time: 16587.9124

Best observed feasible point:
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    3.5752        none            matern52       2.5893e+10        true    

Observed objective function value = 0.36511
Estimated objective function value = 0.56963
Function evaluation time = 551.5042

Best estimated feasible point (according to models):
     Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    _______    _____________    ______________    ___________    ___________

    0.16964      constant          matern52       3.2343e+11        true    

Estimated objective function value = 0.44237
Estimated function evaluation time = 538.9567

Elapsed time is 2758.130266 seconds.
Elapsed time is 2758.134866 seconds.
Use the hyper-parameter optimized NN model for regression
Elapsed time is 0.361181 seconds.
Use the hyper-parameter optimized GPR model for regression
Elapsed time is 0.522771 seconds.
Use the hyper-parameter optimized Ensemble of Trees model for regression
Elapsed time is 0.260279 seconds.
Use the super learner model for regression
Elapsed time is 0.273315 seconds.
Use the error estimate to update the Super Learner Estimate
Elapsed time is 0.370404 seconds.
Use the hyper-parameter optimized NN model for regression
Elapsed time is 0.091120 seconds.
Use the hyper-parameter optimized GPR model for regression
Elapsed time is 0.096694 seconds.
Use the hyper-parameter optimized Ensemble of Trees model for regression
Elapsed time is 0.114751 seconds.
Use the super learner model for regression
Elapsed time is 0.061811 seconds.
Use the error estimate to update the Super Learner Estimate
Elapsed time is 0.085096 seconds.



combinedFigDaily = 

    "/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e063239e3/UTD_Rsl_All_Daily_001e063239e3_pm1_palas.png"


combinedFig = 

    "/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e063239e3/UTD_Rsl_All_2020_12_30_11_25_01/UTD_Rsl_All_2020_12_30_11_25_01_001e063239e3_pm1_palas.png"

    "Creating Folder @: '/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e063239e3/UTD_Rsl_All_2020_12_30_11_25_01'"


plot3 = 

  Line with properties:

              Color: [0.9290 0.6940 0.1250]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x8038 double]
              YData: [1x8038 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot4 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot6 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot3 = 

  Line with properties:

              Color: [0.9290 0.6940 0.1250]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x8038 double]
              YData: [1x8038 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot4 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot6 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties

    "Saving Model Files for Node: 001e063239e3 & target :PM_{1}"


modelsSaveNameDaily = 

    "/home/lhw150030/mintsData/modelsMats/UTDNodes/001e063239e3/daily_Mdl_001e063239e3_pm1_palas.mat"


modelsSaveName = 

    "/home/lhw150030/mintsData/modelsMats/UTDNodes/001e063239e3/UTD_Rsl_All_2020_12_30_11_25_01/UTD_Rsl_All_2020_12_30_11_25_01_001e063239e3_pm1_palas.mat"


resultsSaveName = 

    "/home/lhw150030/mintsData/modelsMats/UTDNodes/001e063239e3/daily_Mdl_001e063239e3_pm1_palas.csv"

    "Creating Folder @: '/home/lhw150030/mintsData/modelsMats/UTDNodes/001e063239e3/UTD_Rsl_All_2020_12_30_11_25_01'"






trainingSaveNameDaily = 

    "/home/lhw150030/mintsData/trainingMats/UTDNodes/001e063239e3/UTD_Rsl_All_Daily_001e063239e3_pm1_palas.mat"


trainingSaveName = 

    "/home/lhw150030/mintsData/trainingMats/UTDNodes/001e063239e3/UTD_Rsl_All_2020_12_30_11_25_01/UTD_Rsl_All_2020_12_30_11_25_01_001e063239e3_pm1_palas.mat"

    "Creating Folder @: '/home/lhw150030/mintsData/trainingMats/UTDNodes/001e063239e3/UTD_Rsl_All_2020_12_30_11_25_01'"



    "Gainin Data set for Node 001e063239e3 with target output pm2_5_palas @ 30-Dec-2020 13:25:41"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 299 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 76 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 133 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 111 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 60 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 22 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 13 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 11 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 7 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 6 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 155 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 244 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 246 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 148 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        7385


ans =

        1303

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |      16 | Best   |      22.361 |     0.92507 |      22.361 |      22.361 |           46 |    0.0034873 |
|    2 |       2 | Accept |      18.544 |      1.8597 |      10.412 |      27.832 |           90 |      0.47279 |
|    3 |       2 | Accept |      135.98 |      2.0017 |      10.412 |      27.832 |           98 |    0.0012613 |
|    4 |       2 | Accept |      13.836 |      1.7225 |      10.412 |      27.832 |           25 |      0.12479 |
|    5 |       2 | Accept |      56.766 |      2.0175 |      10.412 |      27.832 |           98 |    0.0034186 |
|    6 |       2 | Accept |       33.18 |      1.8824 |      10.412 |      27.832 |           65 |      0.66685 |
|    7 |       2 | Accept |      14.453 |      1.5772 |      10.412 |      27.832 |            6 |      0.45325 |
|    8 |       2 | Accept |      25.558 |      1.6586 |      10.412 |      27.832 |           22 |      0.19308 |
|    9 |       2 | Accept |      18.359 |      1.8631 |      10.412 |      27.832 |           77 |     0.046842 |
|   10 |       2 | Accept |      32.152 |       1.533 |      10.412 |      27.832 |            8 |     0.012857 |
|   11 |       2 | Best   |      10.412 |      1.5849 |      10.412 |      27.832 |            9 |    0.0018641 |
|   12 |       2 | Accept |      54.117 |      1.9039 |      10.412 |      27.832 |           35 |     0.010869 |
|   13 |       2 | Accept |      89.993 |      1.9969 |      10.412 |      27.832 |           80 |    0.0051923 |
|   14 |       2 | Accept |      22.629 |      1.7198 |      10.412 |      27.832 |           35 |      0.30995 |
|   15 |       2 | Accept |      53.532 |      1.8448 |      10.412 |      27.832 |           69 |    0.0032897 |
|   16 |       2 | Accept |      52.668 |      1.9527 |      10.412 |      27.832 |           31 |      0.16471 |
|   17 |      16 | Accept |      73.836 |      1.1718 |      10.412 |      30.486 |           60 |      0.62029 |
|   18 |       2 | Accept |      15.621 |     0.34844 |      10.412 |      27.395 |            5 |      0.98927 |
|   19 |       2 | Accept |       42.39 |     0.60636 |      10.412 |      27.395 |           17 |     0.002069 |
|   20 |       2 | Accept |      50.322 |     0.68917 |      10.412 |      27.395 |           41 |    0.0019471 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       2 | Accept |      31.515 |     0.62715 |      10.412 |      27.395 |           28 |    0.0012337 |
|   22 |       2 | Accept |      54.134 |     0.65578 |      10.412 |      27.395 |           27 |      0.13249 |
|   23 |       2 | Accept |      78.228 |     0.60894 |      10.412 |      27.395 |           19 |      0.14471 |
|   24 |       2 | Accept |      16.551 |     0.54052 |      10.412 |      27.395 |            7 |    0.0013601 |
|   25 |       2 | Accept |      70.204 |     0.78213 |      10.412 |      27.395 |           77 |      0.32952 |
|   26 |       2 | Accept |      94.972 |     0.69766 |      10.412 |      27.395 |           72 |    0.0011419 |
|   27 |       2 | Accept |      73.181 |     0.77477 |      10.412 |      27.395 |           68 |      0.13608 |
|   28 |       2 | Accept |      50.909 |     0.71114 |      10.412 |      27.395 |           43 |      0.51841 |
|   29 |       2 | Accept |      23.632 |     0.62636 |      10.412 |      27.395 |           22 |    0.0012544 |
|   30 |       2 | Accept |      84.656 |     0.65239 |      10.412 |      27.395 |           43 |     0.085456 |
|   31 |       2 | Accept |      53.588 |     0.89889 |      10.412 |      27.395 |           95 |      0.53547 |
|   32 |       2 | Accept |      46.045 |     0.82097 |      10.412 |      27.395 |           85 |      0.58797 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 32
Total elapsed time: 13.6244 seconds.
Total objective function evaluation time: 39.2563

Best observed feasible point:
    hiddenLayerSize       lr    
    _______________    _________

           9           0.0018641

Observed objective function value = 10.412
Estimated objective function value = 27.3955
Function evaluation time = 1.5849

Best estimated feasible point (according to models):
    hiddenLayerSize       lr    
    _______________    _________

           9           0.0018641

Estimated objective function value = 27.3955
Estimated function evaluation time = 0.93751


T =

  1x2 table

    hiddenLayerSize       lr    
    _______________    _________

           9           0.0018641

Elapsed time is 18.909965 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      3.8865 |      270.12 |      3.8865 |      3.8865 |       8.2602 |     constant |     matern52 |   1.4296e+11 |        false |
|    2 |      16 | Best   |      2.8714 |      526.81 |      2.8714 |      2.9118 |       18.507 |       linear |     matern32 |   3.2362e+12 |         true |
|    3 |      16 | Best   |       2.866 |      511.91 |       2.866 |      2.8688 |      0.33473 |       linear |     matern32 |   9.6726e+12 |         true |
|    4 |      16 | Accept |      6.9807 |      1204.5 |       2.866 |      2.8688 |    0.0002096 |       linear |     matern32 |    1.144e+12 |        false |
|    5 |      16 | Accept |      4.7205 |      475.39 |       2.866 |      2.8688 |      0.70001 | pureQuadrati |     matern32 |   5.6956e+10 |         true |
|    6 |      16 | Accept |      3.9163 |      331.68 |       2.866 |      2.8688 |       17.831 |         none |     matern32 |   1.4254e+13 |         true |
|    7 |      16 | Accept |      7.3605 |      439.81 |       2.866 |      2.8689 |      0.89251 |       linear |  exponential |    2.038e+13 |         true |
|    8 |      16 | Accept |      3.8863 |      2027.4 |       2.866 |      2.8688 |       3.9935 |         none | rationalquad |   3.0656e+10 |        false |
|    9 |      16 | Accept |      7.8988 |      534.97 |       2.866 |      2.8689 |   0.00040982 |       linear |     matern52 |   2.2559e+11 |         true |
|   10 |      16 | Accept |      3.8747 |      469.58 |       2.866 |      2.8688 |        8.555 |         none |     matern52 |   5.8562e+10 |        false |
|   11 |      16 | Accept |       3.887 |      1088.4 |       2.866 |      2.8688 |       11.691 |     constant | rationalquad |   5.9859e+10 |        false |
|   12 |      16 | Accept |      3.9163 |      1215.6 |       2.866 |      2.8688 |    0.0011145 |         none |     matern52 |   2.0199e+13 |         true |
|   13 |      16 | Error  |         NaN |      1034.7 |       2.866 |      2.8688 |   0.00047083 |     constant |     matern32 |    1.648e+11 |        false |
|   14 |      16 | Accept |      3.9166 |      530.63 |       2.866 |      2.8688 |       2.5724 |     constant |     matern52 |    1.374e+11 |         true |
|   15 |      16 | Accept |      3.9164 |      525.24 |       2.866 |      2.8688 |     0.017707 |     constant |     matern32 |   1.9848e+12 |         true |
|   16 |      16 | Accept |      3.9174 |      697.25 |       2.866 |      2.8688 |       4.7428 |     constant | rationalquad |   7.7171e+10 |         true |
|   17 |      16 | Accept |       3.875 |      336.33 |       2.866 |      2.8688 |       2.8326 |         none | squaredexpon |   4.2982e+10 |        false |
|   18 |      16 | Accept |      3.9163 |      329.01 |       2.866 |      2.8688 |       1.7197 |         none | squaredexpon |    3.716e+10 |         true |
|   19 |      16 | Accept |      3.9163 |      1687.2 |       2.866 |      2.8688 |     0.095745 |         none | rationalquad |   6.2151e+11 |         true |
|   20 |      16 | Error  |         NaN |      1080.3 |       2.866 |      2.8688 |      0.05996 |     constant | squaredexpon |   5.1495e+10 |        false |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      16 | Accept |       3.916 |      516.26 |       2.866 |      2.8688 |     0.010368 |     constant | squaredexpon |   5.7069e+10 |         true |
|   22 |      16 | Accept |      14.159 |      666.44 |       2.866 |      2.8688 |      0.58439 |       linear | squaredexpon |   5.1357e+10 |        false |
|   23 |      16 | Accept |       8.638 |      526.82 |       2.866 |      2.8688 |    0.0020377 |       linear | squaredexpon |    3.458e+10 |         true |
|   24 |      16 | Accept |      3.9167 |      530.88 |       2.866 |      2.8688 |      0.01219 |     constant |  exponential |   2.0473e+12 |         true |
|   25 |      16 | Accept |      3.9257 |      309.52 |       2.866 |      2.8688 |       69.637 |         none |     matern32 |   5.9335e+11 |        false |
|   26 |      16 | Error  |         NaN |      475.08 |       2.866 |      2.8688 |     0.014902 |         none |  exponential |   9.8035e+11 |        false |
|   27 |      16 | Error  |         NaN |      6965.4 |       2.866 |      2.8688 |       0.0259 |       linear |     matern32 |   3.1844e+10 |        false |
|   28 |      16 | Accept |      3.8545 |      605.45 |       2.866 |      2.8688 |       6.9531 |     constant |  exponential |   2.0288e+13 |        false |
|   29 |      16 | Best   |      1.5401 |       41107 |      1.5401 |      1.5405 |       3.9666 |         none |  ardmatern52 |            - |         true |
|   30 |      16 | Accept |      2.3321 |       42483 |      1.5401 |      1.5404 |       19.239 |         none | ardrationalq |            - |        false |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 42490.1844 seconds.
Total objective function evaluation time: 109502.0676

Best observed feasible point:
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    3.9666        none          ardmatern52          NaN           true    

Observed objective function value = 1.5401
Estimated objective function value = 1.5404
Function evaluation time = 41106.781

Best estimated feasible point (according to models):
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    3.9666        none          ardmatern52          NaN           true    

Estimated objective function value = 1.5404
Estimated function evaluation time = 813.6454

Elapsed time is 43377.537632 seconds.
Take a copy of the best attributes
Now use these optimum settings to do an exact GPR fit
Elapsed time is 800.830249 seconds.
Train a hyper-parameter optimized Ensemble of Trees model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|    1 |      15 | Best   |      2.5694 |       5.639 |      2.5694 |      2.6124 |          Bag |           12 |            - |            4 |           10 |           18 |
|    2 |      15 | Accept |      3.3645 |      5.7001 |      2.5694 |      2.6124 |          Bag |           37 |            - |         1430 |            3 |           13 |
|    3 |      13 | Best   |      1.8053 |      11.359 |      1.8053 |      1.8055 |          Bag |           37 |            - |           34 |           68 |            8 |
|    4 |      13 | Accept |      2.9685 |      6.5463 |      1.8053 |      1.8055 |          Bag |           16 |            - |           64 |            2 |           32 |
|    5 |      13 | Accept |      4.3547 |      10.002 |      1.8053 |      1.8055 |      LSBoost |           27 |    0.0093811 |          227 |          298 |           17 |
|    6 |      10 | Accept |      3.5546 |      15.814 |      1.8053 |      1.8231 |          Bag |          153 |            - |           16 |            1 |            4 |
|    7 |      10 | Accept |      3.4835 |      15.749 |      1.8053 |      1.8231 |      LSBoost |          165 |      0.14288 |         2461 |            3 |           11 |
|    8 |      10 | Accept |       2.897 |      15.001 |      1.8053 |      1.8231 |          Bag |           85 |            - |          487 |         4190 |            7 |
|    9 |      10 | Accept |      2.9736 |      5.3611 |      1.8053 |      1.8231 |          Bag |           17 |            - |            3 |            7 |           16 |
|   10 |      15 | Accept |      4.7118 |      23.424 |      1.8053 |      1.8185 |      LSBoost |           27 |    0.0011701 |           25 |          758 |           22 |
|   11 |      15 | Accept |      2.1114 |      24.161 |      1.8053 |      1.8185 |      LSBoost |           53 |     0.068638 |          171 |            4 |           34 |
|   12 |      14 | Accept |      3.3788 |      3.6399 |      1.8053 |      1.8055 |          Bag |           18 |            - |            6 |            2 |           10 |
|   13 |      14 | Accept |      3.6725 |      9.4409 |      1.8053 |      1.8055 |          Bag |           70 |            - |          311 |           47 |            2 |
|   14 |      14 | Accept |      2.8947 |      12.631 |      1.8053 |      1.8055 |          Bag |           65 |            - |          130 |         2540 |            4 |
|   15 |      14 | Accept |       2.092 |      24.813 |      1.8053 |       1.814 |          Bag |           56 |            - |           59 |          880 |           11 |
|   16 |      13 | Accept |      3.3674 |      36.779 |      1.8053 |      1.8182 |          Bag |          197 |            - |         1567 |          181 |           25 |
|   17 |      13 | Accept |      4.0818 |      18.296 |      1.8053 |      1.8182 |      LSBoost |           92 |    0.0058187 |           57 |            1 |           33 |
|   18 |      14 | Accept |      3.8955 |      2.7008 |      1.8053 |      1.8055 |      LSBoost |           13 |     0.054198 |           26 |            1 |           32 |
|   19 |      14 | Accept |      3.1984 |      82.079 |      1.8053 |      1.8112 |          Bag |          402 |            - |          637 |            4 |           14 |
|   20 |      13 | Accept |      1.9408 |       93.68 |      1.8053 |      1.8874 |          Bag |          227 |            - |           14 |           54 |           13 |
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|   21 |      13 | Accept |      3.3823 |      60.441 |      1.8053 |      1.8874 |          Bag |          393 |            - |         2241 |           55 |           34 |
|   22 |      13 | Best   |      1.7351 |      36.749 |      1.7351 |       1.723 |          Bag |           58 |            - |           30 |          165 |           17 |
|   23 |      15 | Accept |      2.9192 |      6.8929 |      1.7351 |      1.7225 |      LSBoost |           23 |      0.06881 |           73 |            5 |           16 |
|   24 |      15 | Accept |      3.2522 |      4.5258 |      1.7351 |      1.7225 |      LSBoost |           18 |     0.068657 |          236 |          221 |            9 |
|   25 |      11 | Best   |      1.3201 |      134.67 |      1.3201 |      1.3519 |          Bag |          170 |            - |            9 |         7341 |           15 |
|   26 |      11 | Accept |       1.802 |      108.76 |      1.3201 |      1.3519 |      LSBoost |          498 |      0.48923 |         1081 |         3341 |           26 |
|   27 |      11 | Accept |      1.3794 |      48.399 |      1.3201 |      1.3519 |          Bag |           43 |            - |           42 |         1831 |           35 |
|   28 |      11 | Accept |      2.2068 |      36.154 |      1.3201 |      1.3519 |      LSBoost |          124 |     0.068124 |          810 |           13 |           26 |
|   29 |      11 | Accept |      1.6176 |      30.341 |      1.3201 |      1.3519 |          Bag |           59 |            - |           19 |          317 |           11 |
|   30 |      16 | Accept |      1.6496 |      108.57 |      1.3201 |      1.3477 |          Bag |          239 |            - |            9 |          123 |           12 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 162.9839 seconds.
Total objective function evaluation time: 998.3234

Best observed feasible point:
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             170              NaN            9             7341                 15         

Observed objective function value = 1.3201
Estimated objective function value = 1.3477
Function evaluation time = 134.6709

Best estimated feasible point (according to models):
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             170              NaN            9             7341                 15         

Estimated objective function value = 1.3477
Estimated function evaluation time = 134.6592

Elapsed time is 173.113259 seconds.
Train the super learner model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |       3.916 |      480.33 |       3.916 |       3.916 |      0.52271 |     constant |  exponential |   4.3675e+11 |         true |
|    2 |      16 | Best   |     0.48354 |      499.19 |     0.48354 |     0.62002 |      0.36807 |       linear |     matern32 |   8.6872e+12 |         true |
|    3 |      16 | Accept |      2.7629 |      502.45 |     0.48354 |     0.65241 |       2.0899 |       linear |     matern32 |   1.9223e+11 |         true |
|    4 |      16 | Accept |     0.50572 |      532.37 |     0.48354 |     0.61842 |       55.459 |       linear |     matern32 |   8.7499e+10 |        false |
|    5 |      16 | Accept |       3.916 |      890.57 |     0.48354 |     0.63786 |    0.0063528 |         none |     matern52 |   3.2266e+12 |         true |
|    6 |      16 | Accept |      2.3665 |      482.25 |     0.48354 |      2.3251 |      0.48031 |       linear |     matern32 |   7.3635e+12 |         true |
|    7 |      16 | Accept |      5.6511 |      539.76 |     0.48354 |      1.9328 |    0.0038038 |       linear |     matern32 |   8.9269e+12 |         true |
|    8 |      16 | Accept |      1.0441 |      536.99 |     0.48354 |     0.48383 |        3.638 |       linear |     matern32 |   8.9368e+12 |         true |
|    9 |      16 | Error  |         NaN |      1131.4 |     0.48354 |     0.48383 |     0.050204 |         none |     matern52 |   1.1697e+11 |        false |
|   10 |      16 | Accept |     0.50532 |      519.74 |     0.48354 |      0.8708 |       66.764 |       linear |     matern32 |   7.8218e+10 |        false |
|   11 |      16 | Best   |     0.48148 |      443.65 |     0.48148 |     0.48122 |      0.80731 |       linear |     matern32 |    9.197e+12 |         true |
|   12 |      16 | Accept |      0.4874 |      434.57 |     0.48148 |     0.48119 |       1.4592 |       linear |     matern32 |   8.5412e+12 |         true |
|   13 |      16 | Accept |     0.50603 |      567.35 |     0.48148 |       0.481 |       42.867 |       linear |     matern32 |   1.0329e+11 |        false |
|   14 |      16 | Accept |     0.50618 |      541.56 |     0.48148 |     0.48106 |       27.722 |       linear |     matern32 |   8.0534e+10 |        false |
|   15 |      16 | Accept |     0.49478 |      1299.1 |     0.48148 |      0.4811 |       2.8148 |       linear |     matern32 |    8.626e+10 |        false |
|   16 |      16 | Accept |     0.49945 |       798.6 |     0.48148 |     0.47564 |       6.2607 |       linear |     matern32 |   1.1327e+11 |        false |
|   17 |      16 | Accept |     0.50739 |      537.67 |     0.48148 |     0.51044 |       53.303 |       linear |     matern32 |   1.2963e+11 |        false |
|   18 |      16 | Accept |     0.50608 |      1119.1 |     0.48148 |     0.45245 |       40.473 |       linear |     matern32 |   2.5114e+10 |        false |
|   19 |      16 | Accept |     0.50661 |      577.25 |     0.48148 |     0.45931 |       8.5765 |       linear |     matern32 |    9.623e+10 |        false |
|   20 |      16 | Accept |     0.50065 |      577.11 |     0.48148 |      0.4579 |       8.7968 |       linear |     matern32 |   9.2109e+11 |        false |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 3036.213 seconds.
Total objective function evaluation time: 13011.0215

Best observed feasible point:
     Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    _______    _____________    ______________    ___________    ___________

    0.80731       linear           matern32        9.197e+12        true    

Observed objective function value = 0.48148
Estimated objective function value = 0.94093
Function evaluation time = 443.6512

Best estimated feasible point (according to models):
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    27.722       linear           matern32       8.0534e+10        false   

Estimated objective function value = 0.4579
Estimated function evaluation time = 636.7101

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 90)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 3051.293892 seconds.
Train the super learner error model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |     0.51326 |      294.39 |     0.51326 |     0.51326 |      0.44155 |     constant |  exponential |   4.5718e+10 |        false |
|    2 |      16 | Accept |      3.2449 |       534.3 |     0.51326 |     0.62188 |       2.1683 | pureQuadrati |     matern52 |   1.9813e+11 |         true |
|    3 |      16 | Best   |     0.50386 |      552.05 |     0.50386 |      1.3845 |       5.2769 | pureQuadrati |     matern32 |   4.4051e+10 |        false |
|    4 |      16 | Error  |         NaN |      653.03 |     0.50386 |      1.3845 |      0.27761 |       linear |  exponential |   2.5068e+10 |        false |
|    5 |      16 | Best   |     0.50357 |      439.72 |     0.50357 |     0.54114 |      0.63687 |         none |     matern32 |   1.3491e+11 |         true |
|    6 |      16 | Error  |         NaN |      534.39 |     0.50357 |     0.54114 |     0.011508 |     constant |  exponential |   2.2016e+10 |        false |
|    7 |      16 | Accept |      1.5762 |      1120.8 |     0.50357 |     0.54289 |     0.035754 |       linear |     matern52 |   8.9691e+12 |        false |
|    8 |      16 | Accept |     0.50628 |      1125.4 |     0.50357 |     0.53513 |      0.44465 |         none | rationalquad |    9.875e+10 |        false |
|    9 |      16 | Accept |      2.5971 |      1165.1 |     0.50357 |     0.88581 |   0.00026934 | pureQuadrati |  exponential |   4.7401e+12 |         true |
|   10 |      16 | Accept |     0.50383 |      550.67 |     0.50357 |     0.50374 |    0.0019177 |         none |     matern32 |   1.1528e+11 |         true |
|   11 |      16 | Best   |     0.50336 |      447.03 |     0.50336 |     0.50362 |       1.5171 |         none |     matern32 |   2.9107e+12 |         true |
|   12 |      16 | Accept |      5.4923 |      1086.9 |     0.50336 |     0.50349 |     0.012515 | pureQuadrati |  exponential |   4.7213e+12 |         true |
|   13 |      16 | Accept |     0.50368 |      595.37 |     0.50336 |     0.50377 |       4.9185 | pureQuadrati |     matern32 |   4.2216e+10 |        false |
|   14 |      16 | Accept |     0.50379 |      416.76 |     0.50336 |     0.50376 |      0.11156 |         none |     matern52 |   4.5108e+12 |         true |
|   15 |      16 | Accept |     0.50408 |      535.24 |     0.50336 |     0.50376 |      0.14794 |     constant |     matern32 |   1.5417e+11 |         true |
|   16 |      16 | Error  |         NaN |      1138.8 |     0.50336 |     0.50376 |     0.018333 | pureQuadrati |     matern32 |   1.1026e+11 |        false |
|   17 |      16 | Accept |     0.50391 |      547.48 |     0.50336 |     0.50376 |       8.0622 |     constant |  exponential |   1.1462e+12 |        false |
|   18 |      16 | Accept |     0.50336 |      792.67 |     0.50336 |     0.50376 |       8.0781 |         none | rationalquad |   3.7452e+11 |        false |
|   19 |      16 | Accept |     0.50383 |      571.46 |     0.50336 |     0.50376 |     0.001242 |         none |     matern52 |   3.0084e+12 |         true |
|   20 |      16 | Best   |     0.50336 |      544.69 |     0.50336 |     0.50376 |       7.9327 |         none |     matern52 |     5.84e+12 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 2783.0734 seconds.
Total objective function evaluation time: 13646.3043

Best observed feasible point:
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    7.9327        none            matern52        5.84e+12         true    

Observed objective function value = 0.50336
Estimated objective function value = 0.50343
Function evaluation time = 544.6866

Best estimated feasible point (according to models):
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    4.9185    pureQuadratic       matern32       4.2216e+10        false   

Estimated objective function value = 0.50376
Estimated function evaluation time = 576.5629

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 119)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 2804.307980 seconds.
Elapsed time is 2804.311221 seconds.
Use the hyper-parameter optimized NN model for regression
Elapsed time is 0.135237 seconds.
Use the hyper-parameter optimized GPR model for regression
Elapsed time is 3.867856 seconds.
Use the hyper-parameter optimized Ensemble of Trees model for regression
Elapsed time is 0.594115 seconds.
Use the super learner model for regression
Elapsed time is 0.411498 seconds.
Use the error estimate to update the Super Learner Estimate
Elapsed time is 0.412788 seconds.
Use the hyper-parameter optimized NN model for regression
Elapsed time is 0.034054 seconds.
Use the hyper-parameter optimized GPR model for regression
Elapsed time is 0.725327 seconds.
Use the hyper-parameter optimized Ensemble of Trees model for regression
Elapsed time is 0.332751 seconds.
Use the super learner model for regression
Elapsed time is 0.080733 seconds.
Use the error estimate to update the Super Learner Estimate
Elapsed time is 0.081140 seconds.



combinedFigDaily = 

    "/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e063239e3/UTD_Rsl_All_Daily_001e063239e3_pm2_5_palas.png"


combinedFig = 

    "/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e063239e3/UTD_Rsl_All_2020_12_30_11_25_01/UTD_Rsl_All_2020_12_30_11_25_01_001e063239e3_pm2_5_palas.png"


plot3 = 

  Line with properties:

              Color: [0.9290 0.6940 0.1250]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x7385 double]
              YData: [1x7385 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot4 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot6 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot3 = 

  Line with properties:

              Color: [0.9290 0.6940 0.1250]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x7385 double]
              YData: [1x7385 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot4 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot6 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties

    "Saving Model Files for Node: 001e063239e3 & target :PM_{2.5}"


modelsSaveNameDaily = 

    "/home/lhw150030/mintsData/modelsMats/UTDNodes/001e063239e3/daily_Mdl_001e063239e3_pm2_5_palas.mat"


modelsSaveName = 

    "/home/lhw150030/mintsData/modelsMats/UTDNodes/001e063239e3/UTD_Rsl_All_2020_12_30_11_25_01/UTD_Rsl_All_2020_12_30_11_25_01_001e063239e3_pm2_5_palas.mat"


resultsSaveName = 

    "/home/lhw150030/mintsData/modelsMats/UTDNodes/001e063239e3/daily_Mdl_001e063239e3_pm2_5_palas.csv"






trainingSaveNameDaily = 

    "/home/lhw150030/mintsData/trainingMats/UTDNodes/001e063239e3/UTD_Rsl_All_Daily_001e063239e3_pm2_5_palas.mat"


trainingSaveName = 

    "/home/lhw150030/mintsData/trainingMats/UTDNodes/001e063239e3/UTD_Rsl_All_2020_12_30_11_25_01/UTD_Rsl_All_2020_12_30_11_25_01_001e063239e3_pm2_5_palas.mat"



    "Gainin Data set for Node 001e063239e3 with target output pm4_palas @ 31-Dec-2020 03:24:30"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 299 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 76 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 133 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 111 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 60 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 22 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 13 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 11 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 7 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 6 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 155 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 244 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 246 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 148 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        7467


ans =

        1318

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |      16 | Best   |      71.138 |     0.52783 |      71.138 |      71.138 |           59 |      0.25351 |
|    2 |       2 | Accept |      51.347 |      1.4613 |      23.385 |      74.443 |           95 |      0.56982 |
|    3 |       2 | Accept |      88.196 |      1.3964 |      23.385 |      74.443 |           96 |    0.0054932 |
|    4 |       2 | Accept |      48.785 |       1.106 |      23.385 |      74.443 |           16 |     0.015545 |
|    5 |       2 | Accept |       97.58 |      1.3228 |      23.385 |      74.443 |           77 |    0.0016946 |
|    6 |       2 | Accept |       81.96 |      1.2884 |      23.385 |      74.443 |           68 |      0.03057 |
|    7 |       2 | Accept |      56.172 |      1.0942 |      23.385 |      74.443 |           34 |       0.5235 |
|    8 |       2 | Accept |      72.077 |      1.5561 |      23.385 |      74.443 |           89 |    0.0047225 |
|    9 |       2 | Accept |      45.545 |      1.2099 |      23.385 |      74.443 |           61 |    0.0032816 |
|   10 |       2 | Accept |      43.511 |      1.2364 |      23.385 |      74.443 |           54 |      0.10253 |
|   11 |       2 | Accept |      87.514 |      1.0444 |      23.385 |      74.443 |           10 |      0.14023 |
|   12 |       2 | Best   |      23.385 |       1.303 |      23.385 |      74.443 |           69 |    0.0019562 |
|   13 |       2 | Accept |      93.231 |      1.2961 |      23.385 |      74.443 |           98 |      0.32802 |
|   14 |       2 | Accept |      62.476 |       1.189 |      23.385 |      74.443 |           50 |     0.011119 |
|   15 |       2 | Accept |       91.22 |      1.0905 |      23.385 |      74.443 |           32 |      0.23588 |
|   16 |       2 | Accept |      176.95 |      1.6247 |      23.385 |      74.443 |           77 |     0.010004 |
|   17 |       1 | Accept |      131.43 |     0.50235 |      15.249 |      45.836 |           68 |    0.0010959 |
|   18 |       1 | Accept |      16.708 |     0.34055 |      15.249 |      45.836 |           10 |    0.0044304 |
|   19 |       1 | Accept |      82.412 |     0.43868 |      15.249 |      45.836 |           25 |    0.0010018 |
|   20 |       1 | Best   |      15.249 |     0.48752 |      15.249 |      45.836 |           32 |      0.65022 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       1 | Accept |      121.25 |     0.52063 |      15.249 |      45.836 |           62 |    0.0029387 |
|   22 |       1 | Accept |      30.271 |     0.52374 |      15.249 |      45.836 |           52 |     0.019185 |
|   23 |       1 | Accept |      38.574 |     0.59681 |      15.249 |      45.836 |           53 |     0.088167 |
|   24 |       1 | Accept |      208.23 |     0.65928 |      15.249 |      45.836 |           69 |     0.015472 |
|   25 |       1 | Accept |      39.291 |     0.70952 |      15.249 |      45.836 |           99 |     0.062358 |
|   26 |       1 | Accept |      35.771 |     0.43231 |      15.249 |      45.836 |           38 |      0.22517 |
|   27 |       1 | Accept |      109.77 |     0.59774 |      15.249 |      45.836 |           69 |     0.059081 |
|   28 |       1 | Accept |      74.232 |     0.46974 |      15.249 |      45.836 |           44 |    0.0077606 |
|   29 |       1 | Accept |      37.605 |     0.61712 |      15.249 |      45.836 |           92 |     0.060524 |
|   30 |       1 | Accept |       74.63 |     0.43228 |      15.249 |      45.836 |           34 |    0.0020732 |
|   31 |       1 | Accept |      129.32 |     0.69846 |      15.249 |      45.836 |           76 |    0.0035615 |
|   32 |       1 | Accept |      229.27 |     0.61116 |      15.249 |      45.836 |           84 |     0.013024 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 32
Total elapsed time: 9.9891 seconds.
Total objective function evaluation time: 28.3849

Best observed feasible point:
    hiddenLayerSize      lr   
    _______________    _______

          32           0.65022

Observed objective function value = 15.249
Estimated objective function value = 45.8361
Function evaluation time = 0.48752

Best estimated feasible point (according to models):
    hiddenLayerSize      lr   
    _______________    _______

          32           0.65022

Estimated objective function value = 45.8361
Estimated function evaluation time = 0.72145


T =

  1x2 table

    hiddenLayerSize      lr   
    _______________    _______

          32           0.65022

Elapsed time is 29.935226 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      4.5625 |      347.97 |      4.5625 |      4.5625 |      0.99551 |         none |  exponential |   1.8222e+12 |         true |
|    2 |      16 | Accept |      4.5625 |      358.63 |      4.5625 |      4.5625 |       15.188 |         none |     matern52 |   1.3695e+12 |         true |
|    3 |      16 | Accept |      6.1157 |      564.04 |      4.5625 |      4.7709 |     0.038531 |       linear |     matern52 |   4.9571e+12 |         true |
|    4 |      16 | Accept |      4.5625 |      717.96 |      4.5625 |      4.5625 |    0.0084996 |         none |     matern52 |   1.1443e+11 |         true |
|    5 |      16 | Accept |      4.5625 |      361.21 |      4.5625 |      4.5625 |       1.3948 |         none |  exponential |   9.6246e+11 |         true |
|    6 |      16 | Accept |      9.3568 |      1095.5 |      4.5625 |      4.5626 |      0.00388 | pureQuadrati |     matern32 |   3.0588e+12 |        false |
|    7 |      16 | Error  |         NaN |      1108.8 |      4.5625 |      4.5626 |   0.00051127 |       linear |     matern52 |   3.7304e+11 |        false |
|    8 |      16 | Best   |      3.5176 |      1215.5 |      3.5176 |      3.5177 |     0.054123 |       linear | squaredexpon |   1.2394e+13 |        false |
|    9 |      16 | Accept |      4.5625 |       563.5 |      3.5176 |      3.5177 |      0.31695 |         none |     matern32 |   1.6824e+11 |         true |
|   10 |      16 | Accept |      4.4695 |      1374.5 |      3.5176 |      3.5177 |       2.9369 |         none |     matern52 |   4.4987e+10 |        false |
|   11 |      16 | Best   |      2.0843 |      1097.5 |      2.0843 |      2.0848 |   0.00028457 |         none |  exponential |   3.1744e+10 |         true |
|   12 |      16 | Accept |      4.5625 |      524.71 |      2.0843 |      2.0847 |      0.31801 |     constant |     matern52 |   1.9523e+11 |         true |
|   13 |      16 | Accept |       4.563 |      437.36 |      2.0843 |      2.0847 |       1.2036 |     constant |  exponential |   1.5216e+13 |         true |
|   14 |      16 | Accept |      5.9812 |      526.91 |      2.0843 |      2.0847 |     0.077807 |       linear | squaredexpon |   5.5042e+12 |         true |
|   15 |      16 | Error  |         NaN |      1876.5 |      2.0843 |      2.0847 |     0.018342 |         none | rationalquad |   3.8863e+10 |        false |
|   16 |      16 | Accept |      3.7775 |      498.88 |      2.0843 |      2.0848 |       96.914 |       linear | squaredexpon |   1.0132e+12 |        false |
|   17 |      16 | Accept |      4.5625 |      1026.8 |      2.0843 |      2.0848 |      0.25605 |         none | rationalquad |     1.35e+11 |         true |
|   18 |      16 | Accept |      6.5171 |      1174.1 |      2.0843 |      2.0848 |     0.033901 | pureQuadrati | squaredexpon |   9.8803e+12 |        false |
|   19 |      16 | Accept |      6.8345 |      1027.2 |      2.0843 |      2.0848 |     0.045311 |         none | squaredexpon |   3.1204e+11 |        false |
|   20 |      16 | Error  |         NaN |        1148 |      2.0843 |      2.0848 |   0.00010162 |         none |  exponential |   1.0643e+13 |         true |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      16 | Accept |      4.5626 |      500.48 |      2.0843 |      2.0848 |      0.37515 |     constant |     matern32 |   8.4385e+11 |         true |
|   22 |      16 | Accept |      10.214 |      1197.3 |      2.0843 |      2.0847 |   0.00010102 |         none |     matern52 |   6.5219e+11 |        false |
|   23 |      16 | Accept |      16.272 |      1261.4 |      2.0843 |      2.0846 |   0.00010232 |       linear | squaredexpon |   3.3932e+10 |        false |
|   24 |      16 | Accept |      2.9761 |      1303.4 |      2.0843 |      2.0846 |   0.00010138 |       linear |  exponential |   2.1498e+10 |         true |
|   25 |      16 | Accept |      2.0843 |      1239.4 |      2.0843 |      2.0844 |    0.0001055 |         none |  exponential |   2.3356e+10 |         true |
|   26 |      16 | Accept |      4.5628 |      529.33 |      2.0843 |      2.0844 |   0.00011824 |     constant |  exponential |   8.2164e+12 |         true |
|   27 |      16 | Accept |      3.4894 |         620 |      2.0843 |      2.0842 |      0.93267 |       linear | squaredexpon |   4.4713e+12 |        false |
|   28 |      16 | Error  |         NaN |      1358.3 |      2.0843 |      2.0842 |   0.00016031 |         none |  exponential |   2.1442e+10 |        false |
|   29 |      16 | Accept |      3.7886 |      519.16 |      2.0843 |      2.0844 |       46.051 |       linear | squaredexpon |   2.0605e+13 |        false |
|   30 |      16 | Accept |      2.1318 |      1297.9 |      2.0843 |      2.0842 |     0.000116 |         none |  exponential |   3.3624e+11 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 3934.9961 seconds.
Total objective function evaluation time: 26872.2662

Best observed feasible point:
      Sigma       BasisFunction    KernelFunction    KernelScale    Standardize
    __________    _____________    ______________    ___________    ___________

    0.00028457        none          exponential      3.1744e+10        true    

Observed objective function value = 2.0843
Estimated objective function value = 2.0842
Function evaluation time = 1097.5245

Best estimated feasible point (according to models):
      Sigma       BasisFunction    KernelFunction    KernelScale    Standardize
    __________    _____________    ______________    ___________    ___________

    0.00028457        none          exponential      3.1744e+10        true    

Estimated objective function value = 2.0842
Estimated function evaluation time = 1097.6497

Elapsed time is 3971.523770 seconds.
Take a copy of the best attributes
Now use these optimum settings to do an exact GPR fit
Elapsed time is 14.849829 seconds.
Train a hyper-parameter optimized Ensemble of Trees model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|    1 |      16 | Best   |      4.5648 |      1.8255 |      4.5648 |      4.5648 |      LSBoost |           16 |      0.17962 |            6 |            5 |            1 |
|    2 |      16 | Best   |      3.7295 |      3.8206 |      3.7295 |      3.7975 |          Bag |           16 |            - |            1 |            2 |           13 |
|    3 |      14 | Accept |      3.9951 |      8.6043 |      2.8013 |      2.8014 |          Bag |           63 |            - |          795 |            7 |            4 |
|    4 |      14 | Best   |      2.8013 |      8.6777 |      2.8013 |      2.8014 |      LSBoost |           28 |     0.057426 |           52 |         2164 |            7 |
|    5 |      14 | Accept |      3.7811 |      6.2804 |      2.8013 |      2.8014 |      LSBoost |           45 |        0.248 |          220 |           77 |            3 |
|    6 |      12 | Accept |      3.3121 |      13.433 |      2.8013 |      2.9702 |          Bag |           57 |            - |         1303 |         7253 |           32 |
|    7 |      12 | Accept |       4.953 |      12.325 |      2.8013 |      2.9702 |      LSBoost |           72 |    0.0041727 |         1130 |           42 |           17 |
|    8 |      12 | Accept |      3.0924 |      4.4863 |      2.8013 |      2.9702 |          Bag |           11 |            - |            1 |           16 |           14 |
|    9 |      12 | Accept |      3.5277 |       22.18 |      2.8013 |      2.8015 |          Bag |          156 |            - |           74 |            6 |            4 |
|   10 |      10 | Accept |      4.6273 |      31.662 |      2.6218 |      2.9842 |      LSBoost |           18 |      0.02185 |            4 |         1024 |           31 |
|   11 |      10 | Best   |      2.6218 |      36.277 |      2.6218 |      2.9842 |      LSBoost |          157 |     0.070093 |          728 |            7 |           15 |
|   12 |      10 | Accept |       3.586 |      4.6141 |      2.6218 |      2.9842 |      LSBoost |           19 |     0.057325 |          105 |         2333 |            7 |
|   13 |      16 | Accept |      4.6711 |      8.4475 |      2.6218 |       2.963 |      LSBoost |           20 |     0.019655 |           24 |         4101 |           10 |
|   14 |      16 | Accept |       3.084 |      9.3773 |      2.6218 |      3.0058 |      LSBoost |           41 |     0.072335 |          681 |            4 |           17 |
|   15 |      15 | Accept |      2.6334 |      14.026 |      2.2143 |      2.5748 |      LSBoost |           53 |     0.054866 |           19 |            8 |           11 |
|   16 |      15 | Best   |      2.2143 |       12.55 |      2.2143 |      2.5748 |          Bag |           46 |            - |            4 |          154 |            5 |
|   17 |      15 | Accept |      5.3227 |      21.712 |      2.2143 |      2.5824 |      LSBoost |           24 |    0.0016768 |           16 |         2763 |           20 |
|   18 |      15 | Accept |      2.9381 |      11.881 |      2.2143 |      2.5395 |      LSBoost |           25 |     0.069678 |          142 |         1792 |           19 |
|   19 |      12 | Accept |       3.676 |       81.28 |      2.2143 |      2.2145 |          Bag |          301 |            - |            2 |            3 |           22 |
|   20 |      12 | Accept |      2.3986 |      77.491 |      2.2143 |      2.2145 |          Bag |          107 |            - |           75 |          832 |           25 |
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|   21 |      12 | Accept |      3.0773 |      61.606 |      2.2143 |      2.2145 |      LSBoost |          418 |      0.35231 |          437 |         3343 |            5 |
|   22 |      12 | Accept |      3.2353 |      33.657 |      2.2143 |      2.2145 |      LSBoost |           88 |     0.017051 |          476 |         2089 |           29 |
|   23 |      10 | Accept |      3.2986 |      88.469 |      1.6842 |      1.6844 |          Bag |          272 |            - |           20 |            2 |           30 |
|   24 |      10 | Best   |      1.6842 |      86.316 |      1.6842 |      1.6844 |      LSBoost |           59 |      0.14011 |           30 |         5164 |           24 |
|   25 |      10 | Accept |      2.0071 |      24.056 |      1.6842 |      1.6844 |          Bag |           71 |            - |            1 |          333 |            5 |
|   26 |      16 | Accept |      3.6227 |      8.3431 |      1.6842 |      1.6844 |      LSBoost |           44 |     0.039407 |          654 |            4 |           14 |
|   27 |      15 | Accept |       2.616 |      77.238 |      1.6842 |      1.6844 |      LSBoost |          195 |     0.017623 |            1 |            4 |           25 |
|   28 |      15 | Accept |      2.6002 |       16.78 |      1.6842 |      1.6844 |      LSBoost |           94 |     0.071235 |           13 |           21 |            4 |
|   29 |      14 | Best   |      1.5984 |      24.765 |      1.5984 |      1.6156 |          Bag |           16 |            - |            2 |         2941 |           25 |
|   30 |      14 | Accept |      3.7902 |      9.3918 |      1.5984 |      1.6156 |      LSBoost |          109 |      0.08369 |         1928 |         7008 |            5 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 146.6941 seconds.
Total objective function evaluation time: 821.5736

Best observed feasible point:
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             16               NaN            2             2941                 25         

Observed objective function value = 1.5984
Estimated objective function value = 1.6156
Function evaluation time = 24.7653

Best estimated feasible point (according to models):
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             16               NaN            2             2941                 25         

Estimated objective function value = 1.6156
Estimated function evaluation time = 24.764

Elapsed time is 150.063355 seconds.
Train the super learner model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      4.5626 |      289.87 |      4.5626 |      4.5626 |       59.805 |         none | squaredexpon |   2.1668e+12 |         true |
|    2 |      16 | Accept |      4.5704 |      293.07 |      4.5626 |      4.5629 |       88.812 |         none |  exponential |   1.5903e+12 |        false |
|    3 |      16 | Best   |      4.5625 |      331.56 |      4.5625 |      4.5628 |       47.313 |         none |     matern52 |   1.0566e+12 |         true |
|    4 |      16 | Best   |  6.3136e-05 |      526.67 |  6.3136e-05 |     0.60845 |       8.9447 |       linear |     matern52 |   3.1466e+10 |         true |
|    5 |      16 | Accept |  0.00066326 |      542.37 |  6.3136e-05 |   0.0090839 |    0.0051942 |       linear |     matern32 |   4.6358e+11 |         true |
|    6 |      16 | Accept |      4.5629 |      549.05 |  6.3136e-05 |  0.00042945 |       4.2122 |     constant |     matern52 |   4.4024e+11 |         true |
|    7 |      16 | Accept |      4.5626 |      365.56 |  6.3136e-05 |  0.00038919 |       75.092 |         none |     matern52 |   6.0146e+10 |         true |
|    8 |      16 | Accept |      4.5625 |      808.89 |  6.3136e-05 |  0.00035655 |    0.0010371 |         none |     matern52 |   3.2285e+11 |         true |
|    9 |      16 | Accept |      4.5625 |       512.7 |  6.3136e-05 |  0.00032936 |      0.70372 |         none | squaredexpon |   1.3139e+12 |         true |
|   10 |      16 | Accept |      4.5625 |      940.14 |  6.3136e-05 |  0.00030652 |      0.33367 |         none |     matern52 |   8.8548e+12 |         true |
|   11 |      16 | Best   |  2.6122e-05 |      527.23 |  2.6122e-05 |  0.00019399 |       7.3711 |       linear |     matern52 |   3.1285e+10 |         true |
|   12 |      16 | Best   |  7.1375e-06 |      523.61 |  7.1375e-06 |  0.00021057 |       21.922 |       linear |     matern32 |   7.6146e+10 |         true |
|   13 |      16 | Accept |  7.1624e-06 |      536.78 |  7.1375e-06 |  0.00014915 |       22.097 |       linear |     matern52 |   2.0488e+13 |         true |
|   14 |      16 | Accept |      9.1001 |      1102.8 |  7.1375e-06 |  0.00015158 |     0.037104 | pureQuadrati |     matern32 |   6.3191e+12 |        false |
|   15 |      16 | Accept |      8.7608 |      1106.1 |  7.1375e-06 |   0.0001712 |    0.0014242 |         none | squaredexpon |   1.5287e+12 |        false |
|   16 |      16 | Accept |      9.5142 |      1211.6 |  7.1375e-06 |  0.00019274 |       1.6556 |     constant | squaredexpon |   1.2802e+12 |        false |
|   17 |      16 | Accept |  5.5576e-05 |      538.47 |  7.1375e-06 |   0.0001662 |       8.1397 | pureQuadrati |     matern52 |    4.141e+10 |         true |
|   18 |      16 | Accept |   0.0013144 |      562.16 |  7.1375e-06 |  0.00015006 |    0.0037332 | pureQuadrati |     matern32 |   6.3166e+11 |         true |
|   19 |      16 | Accept |  8.1125e-06 |      578.76 |  7.1375e-06 |  0.00013875 |   0.00086014 |       linear |     matern52 |   3.6156e+10 |        false |
|   20 |      16 | Accept |      9.1143 |      1168.8 |  7.1375e-06 |  0.00015255 |      0.59873 |         none |     matern32 |   6.0293e+12 |        false |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 1466.618 seconds.
Total objective function evaluation time: 13016.3052

Best observed feasible point:
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    21.922       linear           matern32       7.6146e+10        true    

Observed objective function value = 7.1375e-06
Estimated objective function value = 0.00051592
Function evaluation time = 523.6071

Best estimated feasible point (according to models):
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    8.9447       linear           matern52       3.1466e+10        true    

Estimated objective function value = 0.00015255
Estimated function evaluation time = 526.737

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 90)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 1492.427237 seconds.
Train the super learner error model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Error  |         NaN |      269.67 |         NaN |         NaN |   0.00066361 |         none |  exponential |    2.698e+11 |        false |
|    2 |      16 | Accept |  6.9852e-06 |      1290.2 |         NaN |  6.9852e-06 |    0.0086084 |         none | squaredexpon |   9.9258e+12 |        false |
|    3 |      16 | Accept |  6.9896e-06 |      1481.4 |         NaN |  6.9874e-06 |   0.00016348 |     constant | rationalquad |    4.376e+10 |         true |
|    4 |      16 | Accept |  2.1948e-05 |      1680.4 |         NaN |  1.1974e-05 |    0.0043431 |       linear | rationalquad |   8.5049e+10 |         true |
|    5 |      16 | Best   |  6.9852e-06 |      1683.8 |  6.9852e-06 |  1.0638e-05 |    0.0040877 |         none | rationalquad |   8.5597e+12 |         true |
|    6 |      16 | Accept |  7.0507e-06 |      2217.7 |  6.9852e-06 |  9.9076e-06 |    0.0026946 |       linear | rationalquad |   1.7646e+13 |        false |
|    7 |      16 | Accept |  6.9854e-06 |      344.53 |  6.9852e-06 |  7.0278e-06 |   0.00042198 |         none | squaredexpon |    2.485e+12 |        false |
|    8 |      16 | Accept |  6.9852e-06 |      1268.6 |  6.9852e-06 |  7.0137e-06 |    0.0093338 |         none | squaredexpon |   1.5218e+13 |        false |
|    9 |      16 | Accept |  6.9866e-06 |      767.15 |  6.9852e-06 |  7.0127e-06 |     0.001669 |         none | squaredexpon |   8.0411e+12 |         true |
|   10 |      16 | Accept |  6.9859e-06 |      1500.8 |  6.9852e-06 |   7.012e-06 |    0.0026127 |         none | rationalquad |   1.3889e+13 |        false |
|   11 |      16 | Best   |  6.9837e-06 |      1010.3 |  6.9837e-06 |  7.0115e-06 |    0.0052085 |     constant | squaredexpon |   6.1153e+11 |         true |
|   12 |      16 | Accept |  6.9879e-06 |      1826.7 |  6.9837e-06 |  7.0112e-06 |    0.0030752 |     constant | rationalquad |   7.8124e+11 |        false |
|   13 |      16 | Accept |  6.9923e-06 |      1264.2 |  6.9837e-06 |   7.011e-06 |    0.0041939 |     constant | squaredexpon |   2.0813e+10 |        false |
|   14 |      16 | Accept |  6.9877e-06 |      377.65 |  6.9837e-06 |  7.0108e-06 |   0.00040373 |         none |     matern52 |   1.3667e+13 |        false |
|   15 |      16 | Accept |  7.1085e-06 |        1335 |  6.9837e-06 |  7.0109e-06 |    0.0077643 |       linear | squaredexpon |   1.4545e+13 |        false |
|   16 |      16 | Accept |  6.9875e-06 |      1303.3 |  6.9837e-06 |  7.0108e-06 |    0.0042095 |     constant |     matern52 |   3.1999e+12 |        false |
|   17 |      16 | Accept |  6.9855e-06 |      824.94 |  6.9837e-06 |  7.0107e-06 |   0.00045967 |         none |     matern52 |   1.5324e+13 |         true |
|   18 |      16 | Accept |  6.9907e-06 |      1045.7 |  6.9837e-06 |  7.0107e-06 |    0.0046082 |     constant |     matern52 |   3.9541e+11 |         true |
|   19 |      16 | Accept |  7.0197e-06 |      1656.9 |  6.9837e-06 |  7.0107e-06 |   0.00041015 |       linear |     matern52 |   2.0628e+13 |        false |
|   20 |      16 | Accept |  6.9935e-06 |      1031.7 |  6.9837e-06 |  7.0107e-06 |     0.003952 |     constant |     matern32 |   4.5695e+11 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 9826.0888 seconds.
Total objective function evaluation time: 24180.7652

Best observed feasible point:
      Sigma      BasisFunction      KernelFunction      KernelScale    Standardize
    _________    _____________    __________________    ___________    ___________

    0.0052085      constant       squaredexponential    6.1153e+11        true    

Observed objective function value = 6.9837e-06
Estimated objective function value = 7.056e-06
Function evaluation time = 1010.3352

Best estimated feasible point (according to models):
      Sigma      BasisFunction      KernelFunction      KernelScale    Standardize
    _________    _____________    __________________    ___________    ___________

    0.0086084        none         squaredexponential    9.9258e+12        false   

Estimated objective function value = 7.0107e-06
Estimated function evaluation time = 1147.4531

Elapsed time is 9864.958211 seconds.
Elapsed time is 9864.961979 seconds.
Use the hyper-parameter optimized NN model for regression
Elapsed time is 0.053810 seconds.
Use the hyper-parameter optimized GPR model for regression
Elapsed time is 0.351053 seconds.
Use the hyper-parameter optimized Ensemble of Trees model for regression
Elapsed time is 0.066074 seconds.
Use the super learner model for regression
Elapsed time is 0.315273 seconds.
Use the error estimate to update the Super Learner Estimate
Elapsed time is 0.221276 seconds.
Use the hyper-parameter optimized NN model for regression
Elapsed time is 0.033353 seconds.
Use the hyper-parameter optimized GPR model for regression
Elapsed time is 0.065586 seconds.
Use the hyper-parameter optimized Ensemble of Trees model for regression
Elapsed time is 0.043235 seconds.
Use the super learner model for regression
Elapsed time is 0.066608 seconds.
Use the error estimate to update the Super Learner Estimate
Elapsed time is 0.051432 seconds.



combinedFigDaily = 

    "/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e063239e3/UTD_Rsl_All_Daily_001e063239e3_pm4_palas.png"


combinedFig = 

    "/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e063239e3/UTD_Rsl_All_2020_12_30_11_25_01/UTD_Rsl_All_2020_12_30_11_25_01_001e063239e3_pm4_palas.png"


plot3 = 

  Line with properties:

              Color: [0.9290 0.6940 0.1250]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x7467 double]
              YData: [1x7467 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot4 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot6 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot3 = 

  Line with properties:

              Color: [0.9290 0.6940 0.1250]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x7467 double]
              YData: [1x7467 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot4 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot6 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties

    "Saving Model Files for Node: 001e063239e3 & target :PM_{4}"


modelsSaveNameDaily = 

    "/home/lhw150030/mintsData/modelsMats/UTDNodes/001e063239e3/daily_Mdl_001e063239e3_pm4_palas.mat"


modelsSaveName = 

    "/home/lhw150030/mintsData/modelsMats/UTDNodes/001e063239e3/UTD_Rsl_All_2020_12_30_11_25_01/UTD_Rsl_All_2020_12_30_11_25_01_001e063239e3_pm4_palas.mat"


resultsSaveName = 

    "/home/lhw150030/mintsData/modelsMats/UTDNodes/001e063239e3/daily_Mdl_001e063239e3_pm4_palas.csv"






trainingSaveNameDaily = 

    "/home/lhw150030/mintsData/trainingMats/UTDNodes/001e063239e3/UTD_Rsl_All_Daily_001e063239e3_pm4_palas.mat"


trainingSaveName = 

    "/home/lhw150030/mintsData/trainingMats/UTDNodes/001e063239e3/UTD_Rsl_All_2020_12_30_11_25_01/UTD_Rsl_All_2020_12_30_11_25_01_001e063239e3_pm4_palas.mat"



    "Gainin Data set for Node 001e063239e3 with target output pm10_palas @ 31-Dec-2020 07:44:31"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 299 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 76 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 133 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 111 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 60 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 22 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 13 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 11 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 7 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 6 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 155 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 244 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 246 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 148 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        7201


ans =

        1271

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |       1 | Accept |      73.961 |     0.61951 |      34.575 |      176.99 |           84 |      0.55931 |
|    2 |       1 | Best   |      34.575 |     0.60434 |      34.575 |      176.99 |           81 |     0.020558 |
|    3 |       1 | Accept |      122.92 |     0.54009 |      34.575 |      176.99 |           51 |    0.0018754 |
|    4 |       1 | Accept |      172.61 |     0.68734 |      34.575 |      176.99 |           37 |      0.16796 |
|    5 |       1 | Accept |      236.48 |     0.56639 |      34.575 |      176.99 |           58 |      0.10145 |
|    6 |       1 | Accept |      206.06 |     0.67768 |      34.575 |      176.99 |           72 |    0.0047919 |
|    7 |       1 | Accept |      188.97 |     0.58135 |      34.575 |      176.99 |           68 |     0.063092 |
|    8 |       1 | Accept |      83.766 |     0.54269 |      34.575 |      176.99 |           21 |    0.0056489 |
|    9 |       1 | Accept |      497.81 |     0.71633 |      34.575 |      176.99 |           77 |      0.99644 |
|   10 |       1 | Accept |      293.79 |     0.77986 |      34.575 |      176.99 |           63 |     0.006448 |
|   11 |       1 | Accept |      215.79 |     0.50926 |      34.575 |      176.99 |           37 |      0.35482 |
|   12 |       1 | Accept |       391.8 |      0.7297 |      34.575 |      176.99 |           95 |     0.017075 |
|   13 |       1 | Accept |       94.42 |     0.60829 |      34.575 |      176.99 |           29 |     0.018116 |
|   14 |       1 | Accept |      50.218 |     0.63354 |      34.575 |      176.99 |           68 |      0.20401 |
|   15 |       1 | Accept |      74.186 |     0.57843 |      34.575 |      176.99 |           41 |      0.14525 |
|   16 |       1 | Accept |      94.508 |     0.63694 |      34.575 |      176.99 |           13 |      0.90953 |
|   17 |      16 | Accept |      113.48 |     0.29712 |      34.575 |      173.26 |            5 |    0.0010011 |
|   18 |       1 | Accept |      59.157 |     0.50378 |      34.575 |      123.84 |           41 |       0.1045 |
|   19 |       1 | Accept |      247.17 |     0.64014 |      34.575 |      123.84 |           89 |      0.53232 |
|   20 |       1 | Accept |      407.24 |     0.53503 |      34.575 |      123.84 |           81 |      0.16286 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       1 | Accept |      86.205 |     0.59963 |      34.575 |      123.84 |           79 |    0.0031622 |
|   22 |       1 | Accept |      339.76 |     0.58835 |      34.575 |      123.84 |           79 |      0.19127 |
|   23 |       1 | Accept |      195.22 |     0.50676 |      34.575 |      123.84 |           58 |    0.0017632 |
|   24 |       1 | Accept |       72.35 |     0.42168 |      34.575 |      123.84 |           36 |      0.16829 |
|   25 |       1 | Accept |      189.29 |     0.55572 |      34.575 |      123.84 |           88 |    0.0023663 |
|   26 |       1 | Accept |      75.128 |      0.4518 |      34.575 |      123.84 |           54 |      0.53693 |
|   27 |       1 | Accept |      54.979 |     0.60661 |      34.575 |      123.84 |           88 |     0.077476 |
|   28 |       1 | Accept |      77.583 |     0.53245 |      34.575 |      123.84 |           68 |      0.58628 |
|   29 |       1 | Accept |      278.39 |     0.59721 |      34.575 |      123.84 |          100 |     0.010523 |
|   30 |       1 | Accept |      63.564 |      0.4182 |      34.575 |      123.84 |           13 |    0.0010445 |
|   31 |       1 | Accept |      125.92 |     0.43761 |      34.575 |      123.84 |           32 |     0.051616 |
|   32 |       1 | Accept |      71.974 |     0.98332 |      34.575 |      123.84 |           12 |     0.024437 |
|   33 |       1 | Accept |      148.14 |     0.28502 |      34.575 |      123.84 |            5 |      0.41168 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 33
Total elapsed time: 11.525 seconds.
Total objective function evaluation time: 18.9722

Best observed feasible point:
    hiddenLayerSize       lr   
    _______________    ________

          81           0.020558

Observed objective function value = 34.5751
Estimated objective function value = 197.8911
Function evaluation time = 0.60434

Best estimated feasible point (according to models):
    hiddenLayerSize       lr    
    _______________    _________

          21           0.0056489

Estimated objective function value = 123.8432
Estimated function evaluation time = 0.58885


T =

  1x2 table

    hiddenLayerSize       lr    
    _______________    _________

          21           0.0056489

Elapsed time is 21.177368 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      5.7764 |      361.28 |      5.7764 |      5.7764 |       22.833 |         none |     matern52 |   2.8897e+10 |         true |
|    2 |      16 | Best   |      5.7764 |      571.06 |      5.7764 |      5.7764 |   0.00030289 |         none |     matern52 |    3.561e+11 |         true |
|    3 |      16 | Accept |      5.7765 |      654.14 |      5.7764 |      5.7764 |       154.55 |     constant | rationalquad |   7.2714e+10 |         true |
|    4 |      16 | Error  |         NaN |      687.09 |      5.7764 |      5.7764 |    0.0049723 |       linear |  exponential |   7.3813e+10 |        false |
|    5 |      16 | Accept |      5.7863 |      293.98 |      5.7764 |      5.7764 |       162.97 |         none |     matern52 |   2.3485e+12 |        false |
|    6 |      16 | Accept |      9.2503 |      506.17 |      5.7764 |      5.7764 |       80.842 |       linear |     matern52 |   1.8093e+13 |         true |
|    7 |      16 | Accept |      11.028 |      1274.2 |      5.7764 |      5.7765 |       1.5234 |       linear |     matern32 |    8.726e+12 |        false |
|    8 |      16 | Best   |      3.8031 |      1330.3 |      3.8031 |      3.8035 |   0.00023915 |         none |  exponential |   6.3654e+11 |         true |
|    9 |      16 | Accept |       5.776 |      505.28 |      3.8031 |      3.8034 |      0.37574 |     constant |     matern52 |   2.4749e+12 |         true |
|   10 |      16 | Accept |      8.6815 |      1649.9 |      3.8031 |      3.8035 |      0.52744 | pureQuadrati | rationalquad |   6.3259e+11 |        false |
|   11 |      16 | Accept |      5.7764 |      534.02 |      3.8031 |      3.8034 |        2.421 |         none | rationalquad |    3.447e+10 |         true |
|   12 |      16 | Accept |      5.7761 |      543.46 |      3.8031 |      3.8034 |       45.658 |     constant |     matern52 |   1.4328e+12 |        false |
|   13 |      16 | Accept |      5.7763 |      496.39 |      3.8031 |      3.8034 |    0.0015666 |     constant |  exponential |   5.5703e+11 |         true |
|   14 |      16 | Accept |      5.7764 |      725.73 |      3.8031 |      3.8034 |   0.00082058 |         none |     matern32 |    1.556e+11 |         true |
|   15 |      16 | Accept |      8.1421 |      510.64 |      3.8031 |      3.8034 |   0.00013919 |       linear |  exponential |   2.0224e+13 |         true |
|   16 |      16 | Error  |         NaN |      668.43 |      3.8031 |      3.8034 |   0.00025289 |         none |  exponential |   6.9834e+11 |        false |
|   17 |      16 | Accept |      5.7765 |      522.04 |      3.8031 |      3.8034 |     0.025767 |     constant |     matern32 |   5.8445e+10 |         true |
|   18 |      16 | Accept |      5.7768 |      728.28 |      3.8031 |      3.8034 |       115.93 |     constant | rationalquad |   2.7732e+11 |        false |
|   19 |      16 | Accept |      5.7764 |      325.58 |      3.8031 |      3.8034 |       75.818 |         none | squaredexpon |   2.5548e+10 |         true |
|   20 |      16 | Accept |      5.7764 |      514.04 |      3.8031 |      3.8034 |       19.096 |     constant | squaredexpon |   7.2174e+10 |         true |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      16 | Accept |      5.7636 |       268.2 |      3.8031 |      3.8034 |        55.83 |         none | squaredexpon |   2.8519e+10 |        false |
|   22 |      16 | Accept |      9.8805 |      1138.7 |      3.8031 |      3.8034 |     0.015448 |     constant |     matern32 |   1.6693e+13 |        false |
|   23 |      16 | Accept |      5.7599 |      301.37 |      3.8031 |      3.8034 |       17.791 |     constant | squaredexpon |    1.161e+11 |        false |
|   24 |      16 | Accept |      8.9791 |      509.59 |      3.8031 |      3.8034 |       17.235 |       linear | squaredexpon |   6.0711e+10 |         true |
|   25 |      16 | Accept |      4.9923 |      514.09 |      3.8031 |      3.8034 |       47.098 |       linear | squaredexpon |   4.6976e+10 |        false |
|   26 |      16 | Accept |      5.7776 |      1874.9 |      3.8031 |      3.8034 |       7.3076 |         none | rationalquad |    1.132e+11 |        false |
|   27 |      16 | Accept |      5.0041 |       684.2 |      3.8031 |      3.8034 |        179.3 |       linear | rationalquad |   1.1571e+12 |        false |
|   28 |      16 | Accept |      7.3906 |       39143 |      3.8031 |      3.8034 |       14.899 |       linear |  ardmatern52 |            - |         true |
|   29 |      16 | Accept |      4.4221 |       39969 |      3.8031 |      3.8034 |       68.842 |         none | ardsquaredex |            - |         true |
|   30 |      16 | Best   |       3.656 |       42058 |       3.656 |      3.6563 |       13.758 |     constant | ardexponenti |            - |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 45958.4738 seconds.
Total objective function evaluation time: 139862.6824

Best observed feasible point:
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    13.758      constant       ardexponential        NaN           true    

Observed objective function value = 3.656
Estimated objective function value = 3.6563
Function evaluation time = 42057.5475

Best estimated feasible point (according to models):
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    13.758      constant       ardexponential        NaN           true    

Estimated objective function value = 3.6563
Estimated function evaluation time = 943.5462

Elapsed time is 46676.359653 seconds.
Take a copy of the best attributes
Now use these optimum settings to do an exact GPR fit
Elapsed time is 513.916231 seconds.
Train a hyper-parameter optimized Ensemble of Trees model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|    1 |      16 | Best   |      6.0225 |      1.7464 |      6.0225 |      6.0225 |      LSBoost |           19 |     0.020615 |         2749 |          120 |            8 |
|    2 |      12 | Best   |      4.4274 |      2.7657 |      4.4274 |      4.4275 |      LSBoost |           17 |      0.80105 |         1441 |          103 |           20 |
|    3 |      12 | Accept |      4.8556 |       2.684 |      4.4274 |      4.4275 |          Bag |           16 |            - |           13 |          799 |            3 |
|    4 |      12 | Accept |      4.6766 |       3.434 |      4.4274 |      4.4275 |          Bag |           10 |            - |           88 |            2 |           30 |
|    5 |      12 | Accept |       5.714 |      2.3081 |      4.4274 |      4.4275 |          Bag |           22 |            - |         1442 |           42 |            2 |
|    6 |      12 | Accept |      6.4084 |      2.5946 |      4.4274 |      4.4275 |      LSBoost |           11 |    0.0060537 |         1019 |            8 |           25 |
|    7 |      12 | Accept |      4.7498 |       3.942 |      4.4274 |      4.5039 |          Bag |           27 |            - |          380 |           77 |            5 |
|    8 |      10 | Accept |      4.6395 |      12.736 |      3.1902 |      3.1904 |          Bag |           49 |            - |          976 |            4 |           33 |
|    9 |      10 | Accept |      4.2979 |      18.107 |      3.1902 |      3.1904 |      LSBoost |          128 |      0.43344 |         1366 |           53 |           17 |
|   10 |      10 | Best   |      3.1902 |       18.82 |      3.1902 |      3.1904 |      LSBoost |           15 |      0.24054 |            4 |          309 |           31 |
|   11 |      15 | Accept |      3.2138 |      21.928 |      3.1902 |      3.2568 |      LSBoost |           25 |      0.21228 |           11 |           43 |           35 |
|   12 |      15 | Accept |      4.6158 |      23.422 |      3.1902 |      3.2568 |          Bag |           88 |            - |           11 |            7 |           15 |
|   13 |      13 | Accept |      6.2631 |      33.299 |      3.1902 |      3.3275 |      LSBoost |          100 |    0.0013542 |           18 |         6965 |            7 |
|   14 |      13 | Accept |      4.5108 |      2.4652 |      3.1902 |      3.3275 |      LSBoost |           15 |      0.33119 |            5 |            3 |           10 |
|   15 |      13 | Accept |      4.1267 |       16.21 |      3.1902 |      3.3275 |      LSBoost |           88 |      0.97156 |          790 |          649 |           13 |
|   16 |      13 | Accept |      3.7663 |       37.66 |      3.1902 |      3.4127 |      LSBoost |          117 |      0.16151 |           28 |            3 |           33 |
|   17 |      13 | Accept |      5.7765 |      32.186 |      3.1902 |      3.1904 |      LSBoost |          474 |      0.94759 |         3527 |           23 |           26 |
|   18 |      12 | Accept |      4.0923 |      57.044 |      3.1902 |      3.1904 |          Bag |           99 |            - |            8 |           12 |           33 |
|   19 |      12 | Accept |      4.3622 |      32.139 |      3.1902 |      3.1904 |          Bag |          202 |            - |          449 |           15 |            8 |
|   20 |      12 | Accept |      3.6405 |      41.406 |      3.1902 |      3.1904 |      LSBoost |           89 |      0.44278 |          230 |           24 |           16 |
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|   21 |      10 | Accept |      3.5139 |      53.463 |      3.1902 |      3.1903 |          Bag |           58 |            - |           22 |         3943 |           26 |
|   22 |      10 | Accept |      3.7662 |      14.731 |      3.1902 |      3.1903 |      LSBoost |           32 |      0.32529 |            7 |            4 |           35 |
|   23 |      10 | Accept |      4.8784 |      2.9858 |      3.1902 |      3.1903 |      LSBoost |           14 |      0.15578 |            5 |            1 |           35 |
|   24 |      15 | Accept |      3.7837 |      55.794 |      3.1554 |      3.1738 |          Bag |           67 |            - |           62 |          127 |           32 |
|   25 |      15 | Best   |      3.1554 |      48.582 |      3.1554 |      3.1738 |      LSBoost |           42 |      0.25237 |            1 |           65 |           35 |
|   26 |      13 | Accept |      3.2756 |      15.918 |      3.1554 |      3.1982 |      LSBoost |           10 |      0.37365 |           15 |          723 |           34 |
|   27 |      13 | Accept |      5.1426 |       2.313 |      3.1554 |      3.1982 |      LSBoost |           10 |      0.11832 |           19 |            2 |           15 |
|   28 |      13 | Accept |       4.169 |      7.1964 |      3.1554 |      3.1982 |          Bag |           22 |            - |            6 |           28 |           12 |
|   29 |      16 | Accept |      5.2483 |      37.338 |      3.1554 |      3.2017 |          Bag |          331 |            - |         2416 |            5 |           15 |
|   30 |      16 | Accept |      4.2455 |       43.97 |      3.1554 |      3.1945 |      LSBoost |          134 |     0.011197 |           25 |          964 |            7 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 147.0323 seconds.
Total objective function evaluation time: 649.1879

Best observed feasible point:
    Method     NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    _______    _________________    _________    ___________    ____________    ____________________

    LSBoost           42             0.25237          1              65                  35         

Observed objective function value = 3.1554
Estimated objective function value = 3.1608
Function evaluation time = 48.5824

Best estimated feasible point (according to models):
    Method     NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    _______    _________________    _________    ___________    ____________    ____________________

    LSBoost           15             0.24054          4             309                  31         

Estimated objective function value = 3.1945
Estimated function evaluation time = 18.8205

Elapsed time is 150.132271 seconds.
Train the super learner model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      5.7768 |      370.04 |      5.7768 |      5.7768 |       4.0874 |         none |     matern52 |   3.0552e+11 |         true |
|    2 |      16 | Best   |  0.00079021 |      489.02 |  0.00079021 |     0.23045 |         14.8 | pureQuadrati | squaredexpon |   4.8872e+11 |         true |
|    3 |      16 | Accept |   0.0070664 |      513.47 |  0.00079021 |      1.8183 |       15.868 |       linear |     matern32 |   2.4479e+10 |         true |
|    4 |      15 | Accept |   0.0026807 |      513.53 |  4.8508e-05 |   0.0056881 |     0.012423 | pureQuadrati |     matern32 |   2.6309e+10 |         true |
|    5 |      15 | Best   |  4.8508e-05 |      524.68 |  4.8508e-05 |   0.0056881 |      0.01281 |       linear |  exponential |   3.7352e+11 |        false |
|    6 |      16 | Accept |       5.777 |      593.46 |  4.8508e-05 |   0.0020281 |        157.3 |         none | rationalquad |   1.1299e+13 |         true |
|    7 |      16 | Best   |   4.848e-05 |      766.27 |   4.848e-05 |   0.0018693 |    0.0059221 |       linear | rationalquad |   3.5277e+11 |        false |
|    8 |      16 | Accept |      5.7768 |      795.76 |   4.848e-05 |  0.00026538 |      0.59184 |         none | rationalquad |   4.1443e+11 |         true |
|    9 |      16 | Accept |  4.8846e-05 |      556.89 |   4.848e-05 |  0.00024117 |     0.017592 |       linear |     matern52 |    5.845e+11 |        false |
|   10 |      16 | Accept |   0.0020603 |      524.01 |   4.848e-05 |   0.0015152 |       3.6928 | pureQuadrati | squaredexpon |    4.649e+12 |         true |
|   11 |      16 | Accept |   0.0031628 |      514.79 |   4.848e-05 |   0.0015093 |   0.00079674 |       linear |     matern32 |   9.9049e+11 |         true |
|   12 |      16 | Accept |      5.7768 |      1058.8 |   4.848e-05 |   0.0015186 |   0.00022637 |         none | rationalquad |   9.5698e+10 |         true |
|   13 |      16 | Accept |   0.0032712 |      522.39 |   4.848e-05 |   0.0015142 |   0.00069771 | pureQuadrati |     matern32 |   8.8922e+11 |         true |
|   14 |      16 | Best   |  4.7986e-05 |       538.7 |  4.7986e-05 |  0.00013299 |       21.312 |       linear |  exponential |   1.2267e+13 |        false |
|   15 |      16 | Error  |         NaN |      1086.2 |  4.7986e-05 |  0.00013299 |       3.2864 |         none |     matern32 |   3.8499e+11 |        false |
|   16 |      16 | Accept |   5.034e-05 |      510.06 |  4.7986e-05 |  0.00012612 |      0.37823 |       linear |  exponential |   2.3472e+11 |         true |
|   17 |      16 | Accept |      9.1475 |        1148 |  4.7986e-05 |  0.00014584 |   0.00092168 | pureQuadrati | squaredexpon |   4.3269e+12 |        false |
|   18 |      16 | Accept |  4.8301e-05 |      537.22 |  4.7986e-05 |  0.00013874 |      0.45539 |       linear |     matern32 |   2.2648e+10 |        false |
|   19 |      16 | Error  |         NaN |      403.28 |  4.7986e-05 |  0.00013874 |     0.079638 | pureQuadrati |  exponential |   6.9037e+10 |        false |
|   20 |      16 | Accept |     0.00221 |      525.25 |  4.7986e-05 |  0.00013282 |     0.019201 | pureQuadrati |     matern52 |    3.607e+10 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 1556.9681 seconds.
Total objective function evaluation time: 12491.8501

Best observed feasible point:
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    21.312       linear         exponential      1.2267e+13        false   

Observed objective function value = 4.7986e-05
Estimated objective function value = 0.00013282
Function evaluation time = 538.7026

Best estimated feasible point (according to models):
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    21.312       linear         exponential      1.2267e+13        false   

Estimated objective function value = 0.00013282
Estimated function evaluation time = 538.5118

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 90)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 1572.078155 seconds.
Train the super learner error model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |   4.781e-05 |      394.96 |   4.781e-05 |   4.781e-05 |      0.01186 |         none |     matern32 |   1.9075e+12 |        false |
|    2 |      16 | Accept |  4.7825e-05 |      414.71 |   4.781e-05 |  4.7814e-05 |    0.0084025 |         none |  exponential |   5.6915e+12 |        false |
|    3 |      16 | Accept |  4.9043e-05 |      461.52 |   4.781e-05 |   4.799e-05 |    0.0044325 |         none |  exponential |   6.2786e+12 |        false |
|    4 |      16 | Accept |  4.7832e-05 |      565.44 |   4.781e-05 |  4.7939e-05 |   0.00013649 |         none | squaredexpon |   4.0405e+12 |         true |
|    5 |      16 | Accept |  4.7865e-05 |      840.38 |   4.781e-05 |  4.7916e-05 |    0.0099161 |         none |  exponential |   8.8539e+12 |         true |
|    6 |      16 | Accept |  4.7868e-05 |      901.52 |   4.781e-05 |  4.7899e-05 |     0.031417 |         none |  exponential |   3.8487e+10 |        false |
|    7 |      16 | Accept |  4.8495e-05 |      524.33 |   4.781e-05 |  4.7941e-05 |     0.013903 |       linear |     matern32 |   1.6541e+12 |        false |
|    8 |      16 | Best   |  4.7803e-05 |      987.63 |  4.7803e-05 |  4.7918e-05 |    0.0036781 |     constant | rationalquad |   4.0603e+12 |        false |
|    9 |      16 | Accept |  4.7823e-05 |      1007.8 |  4.7803e-05 |  4.7905e-05 |     0.010356 |     constant | squaredexpon |   6.1599e+11 |         true |
|   10 |      16 | Accept |  4.7854e-05 |      1034.5 |  4.7803e-05 |  4.7897e-05 |   0.00029036 |     constant |     matern32 |   2.5381e+10 |         true |
|   11 |      16 | Best   |  4.7729e-05 |      709.94 |  4.7729e-05 |  4.7847e-05 |    0.0065354 |         none |     matern52 |   8.2421e+10 |        false |
|   12 |      16 | Accept |  4.7833e-05 |      383.41 |  4.7729e-05 |  4.7842e-05 |    0.0020852 |         none | squaredexpon |   2.5655e+10 |         true |
|   13 |      16 | Accept |  4.7868e-05 |      503.66 |  4.7729e-05 |  4.7839e-05 |     0.060197 |         none |  exponential |   4.5101e+10 |         true |
|   14 |      16 | Accept |  4.7758e-05 |       341.8 |  4.7729e-05 |  4.7823e-05 |    0.0046818 |         none |     matern52 |   1.6257e+13 |        false |
|   15 |      16 | Accept |  4.7868e-05 |      1086.5 |  4.7729e-05 |  4.7818e-05 |      0.01776 |         none |     matern32 |   2.5528e+10 |        false |
|   16 |      16 | Accept |  0.00012574 |      1036.7 |  4.7729e-05 |  4.7619e-05 |   0.00014353 |         none |     matern32 |   1.7831e+13 |        false |
|   17 |      16 | Accept |   5.362e-05 |      1719.9 |  4.7729e-05 |  4.7625e-05 |     0.019585 |       linear | rationalquad |   5.3963e+11 |         true |
|   18 |      16 | Accept |  4.7783e-05 |      326.55 |  4.7729e-05 |  4.7627e-05 |    0.0038522 |     constant |     matern52 |   1.2784e+12 |        false |
|   19 |      16 | Accept |  4.7819e-05 |      1010.2 |  4.7729e-05 |   4.762e-05 |   0.00013563 |     constant | squaredexpon |   1.4233e+13 |         true |
|   20 |      16 | Accept |  4.7868e-05 |        1165 |  4.7729e-05 |  4.7593e-05 |     0.035836 |         none | squaredexpon |   1.5023e+13 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 2075.9679 seconds.
Total objective function evaluation time: 15416.3605

Best observed feasible point:
      Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    _________    _____________    ______________    ___________    ___________

    0.0065354        none            matern52       8.2421e+10        false   

Observed objective function value = 4.7729e-05
Estimated objective function value = 4.7741e-05
Function evaluation time = 709.9421

Best estimated feasible point (according to models):
     Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    _______    _____________    ______________    ___________    ___________

    0.01776        none            matern32       2.5528e+10        false   

Estimated objective function value = 4.7593e-05
Estimated function evaluation time = 690.6577

Elapsed time is 2127.139141 seconds.
Elapsed time is 2127.144105 seconds.
Use the hyper-parameter optimized NN model for regression
Elapsed time is 0.077843 seconds.
Use the hyper-parameter optimized GPR model for regression
Elapsed time is 3.874559 seconds.
Use the hyper-parameter optimized Ensemble of Trees model for regression
Elapsed time is 0.043907 seconds.
Use the super learner model for regression
Elapsed time is 0.349441 seconds.
Use the error estimate to update the Super Learner Estimate
Elapsed time is 0.383995 seconds.
Use the hyper-parameter optimized NN model for regression
Elapsed time is 0.033179 seconds.
Use the hyper-parameter optimized GPR model for regression
Elapsed time is 0.712621 seconds.
Use the hyper-parameter optimized Ensemble of Trees model for regression
Elapsed time is 0.022162 seconds.
Use the super learner model for regression
Elapsed time is 0.062625 seconds.
Use the error estimate to update the Super Learner Estimate
Elapsed time is 0.071855 seconds.



combinedFigDaily = 

    "/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e063239e3/UTD_Rsl_All_Daily_001e063239e3_pm10_palas.png"


combinedFig = 

    "/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e063239e3/UTD_Rsl_All_2020_12_30_11_25_01/UTD_Rsl_All_2020_12_30_11_25_01_001e063239e3_pm10_palas.png"


plot3 = 

  Line with properties:

              Color: [0.9290 0.6940 0.1250]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x7201 double]
              YData: [1x7201 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot4 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot6 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot3 = 

  Line with properties:

              Color: [0.9290 0.6940 0.1250]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x7201 double]
              YData: [1x7201 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot4 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot6 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties

    "Saving Model Files for Node: 001e063239e3 & target :PM_{10}"


modelsSaveNameDaily = 

    "/home/lhw150030/mintsData/modelsMats/UTDNodes/001e063239e3/daily_Mdl_001e063239e3_pm10_palas.mat"


modelsSaveName = 

    "/home/lhw150030/mintsData/modelsMats/UTDNodes/001e063239e3/UTD_Rsl_All_2020_12_30_11_25_01/UTD_Rsl_All_2020_12_30_11_25_01_001e063239e3_pm10_palas.mat"


resultsSaveName = 

    "/home/lhw150030/mintsData/modelsMats/UTDNodes/001e063239e3/daily_Mdl_001e063239e3_pm10_palas.csv"






trainingSaveNameDaily = 

    "/home/lhw150030/mintsData/trainingMats/UTDNodes/001e063239e3/UTD_Rsl_All_Daily_001e063239e3_pm10_palas.mat"


trainingSaveName = 

    "/home/lhw150030/mintsData/trainingMats/UTDNodes/001e063239e3/UTD_Rsl_All_2020_12_30_11_25_01/UTD_Rsl_All_2020_12_30_11_25_01_001e063239e3_pm10_palas.mat"



    "Gainin Data set for Node 001e063239e3 with target output pmTotal_palas @ 31-Dec-2020 21:56:51"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 299 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 76 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 133 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 111 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 60 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 22 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 13 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 11 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 7 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 6 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 155 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 244 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 246 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 148 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        7059


ans =

        1246

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |       1 | Accept |      383.71 |     0.38618 |      66.749 |      313.65 |           18 |      0.54683 |
|    2 |       1 | Accept |      199.27 |     0.43297 |      66.749 |      313.65 |           46 |    0.0075578 |
|    3 |       1 | Accept |      472.65 |     0.53862 |      66.749 |      313.65 |           77 |       0.3893 |
|    4 |       1 | Accept |      292.02 |     0.42594 |      66.749 |      313.65 |           40 |      0.64083 |
|    5 |       1 | Accept |      406.16 |     0.37395 |      66.749 |      313.65 |           21 |    0.0039713 |
|    6 |       1 | Accept |      311.26 |     0.63352 |      66.749 |      313.65 |           94 |    0.0019831 |
|    7 |       1 | Accept |      345.78 |     0.59239 |      66.749 |      313.65 |           92 |     0.054289 |
|    8 |       1 | Accept |      168.38 |     0.53022 |      66.749 |      313.65 |           78 |     0.083047 |
|    9 |       1 | Accept |      353.97 |     0.34711 |      66.749 |      313.65 |           15 |    0.0096086 |
|   10 |       1 | Accept |      98.653 |     0.51239 |      66.749 |      313.65 |           65 |      0.61294 |
|   11 |       1 | Accept |      210.08 |     0.42689 |      66.749 |      313.65 |           44 |      0.29505 |
|   12 |       1 | Accept |      670.94 |     0.44689 |      66.749 |      313.65 |           40 |     0.022385 |
|   13 |       1 | Accept |      138.32 |     0.31383 |      66.749 |      313.65 |            5 |     0.010087 |
|   14 |       1 | Best   |      66.749 |     0.31626 |      66.749 |      313.65 |            8 |       0.0184 |
|   15 |       1 | Accept |      207.72 |     0.59274 |      66.749 |      313.65 |           99 |      0.30972 |
|   16 |       1 | Accept |       692.8 |     0.57061 |      66.749 |      313.65 |           75 |     0.076701 |
|   17 |       1 | Best   |       64.73 |     0.44034 |       64.73 |      281.13 |           35 |     0.026458 |
|   18 |       1 | Accept |      176.13 |     0.56602 |       64.73 |      281.13 |          100 |      0.99822 |
|   19 |       1 | Accept |      161.98 |      0.4807 |       64.73 |      281.13 |           63 |      0.87676 |
|   20 |       1 | Accept |      154.81 |     0.60967 |       64.73 |      281.13 |           95 |     0.028386 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       1 | Accept |      358.97 |     0.44149 |       64.73 |      281.13 |           54 |      0.25205 |
|   22 |       1 | Accept |      64.919 |     0.38604 |       64.73 |      281.13 |            6 |      0.00507 |
|   23 |       1 | Accept |      218.91 |     0.34836 |       64.73 |      281.13 |           24 |      0.07704 |
|   24 |       1 | Accept |      272.17 |     0.59321 |       64.73 |      281.13 |           99 |     0.021006 |
|   25 |       1 | Accept |      334.25 |     0.39375 |       64.73 |      281.13 |           34 |      0.21082 |
|   26 |       1 | Accept |      330.29 |     0.46176 |       64.73 |      281.13 |           62 |     0.012511 |
|   27 |       1 | Accept |      480.17 |     0.55241 |       64.73 |      281.13 |           67 |    0.0040863 |
|   28 |       1 | Accept |      365.58 |     0.47205 |       64.73 |      281.13 |           53 |     0.036353 |
|   29 |       1 | Accept |      125.32 |     0.59944 |       64.73 |      281.13 |           71 |      0.92532 |
|   30 |       1 | Accept |      147.74 |     0.38443 |       64.73 |      281.13 |           32 |      0.64212 |
|   31 |       1 | Accept |      237.94 |     0.50893 |       64.73 |      281.13 |           67 |      0.27335 |
|   32 |       1 | Accept |      483.87 |     0.48766 |       64.73 |      281.13 |           43 |      0.79943 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 32
Total elapsed time: 8.82 seconds.
Total objective function evaluation time: 15.1668

Best observed feasible point:
    hiddenLayerSize       lr   
    _______________    ________

          35           0.026458

Observed objective function value = 64.7304
Estimated objective function value = 281.1325
Function evaluation time = 0.44034

Best estimated feasible point (according to models):
    hiddenLayerSize       lr   
    _______________    ________

           5           0.010087

Estimated objective function value = 281.1313
Estimated function evaluation time = 0.33711


T =

  1x2 table

    hiddenLayerSize       lr   
    _______________    ________

           5           0.010087

Elapsed time is 13.416890 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      6.9644 |      395.07 |      6.9644 |      6.9644 |     0.097618 |         none |     matern52 |   8.8608e+10 |         true |
|    2 |      16 | Accept |      7.3844 |      482.91 |      6.9644 |      6.9811 |    0.0082518 |       linear |  exponential |    6.963e+12 |         true |
|    3 |      16 | Accept |       6.965 |       489.1 |      6.9644 |      6.9729 |        2.135 |     constant |     matern32 |   2.6159e+11 |         true |
|    4 |      16 | Error  |         NaN |       498.1 |         NaN |      6.9729 |    0.0048585 | pureQuadrati |  exponential |   3.6718e+10 |        false |
|    5 |      16 | Accept |      6.9645 |      529.82 |      6.9644 |      6.9673 |       140.03 |     constant |     matern52 |   5.2519e+10 |        false |
|    6 |      16 | Accept |      6.9644 |      382.06 |      6.9644 |      6.9644 |       3.4576 |         none |     matern52 |   4.7274e+11 |         true |
|    7 |      16 | Error  |         NaN |        1151 |      6.9644 |      6.9644 |     0.017751 | pureQuadrati |     matern52 |   6.5208e+10 |        false |
|    8 |      16 | Accept |      7.5672 |      1182.4 |      6.9644 |      6.9644 |    0.0094292 |       linear |     matern52 |    1.222e+12 |        false |
|    9 |      16 | Accept |      9.0974 |      1187.6 |      6.9644 |      6.9644 |   0.00023446 |       linear |     matern52 |   6.9624e+12 |        false |
|   10 |      16 | Error  |         NaN |      1288.9 |      6.9644 |      6.9644 |      0.74987 |       linear |     matern32 |   2.6441e+10 |        false |
|   11 |      16 | Error  |         NaN |      1311.2 |      6.9644 |      6.9644 |    0.0092114 |         none |  exponential |   6.8643e+12 |         true |
|   12 |      16 | Best   |      6.9644 |      1337.4 |      6.9644 |      6.9645 |    0.0020664 |         none | rationalquad |   7.9112e+11 |         true |
|   13 |      16 | Accept |      6.9655 |      490.94 |      6.9644 |      6.9645 |       13.852 |     constant |     matern52 |    2.125e+11 |         true |
|   14 |      16 | Accept |      6.9644 |      907.98 |      6.9644 |      6.9641 |   0.00025753 |         none |     matern52 |    4.554e+11 |         true |
|   15 |      16 | Error  |         NaN |        1002 |      6.9644 |      6.9641 |    0.0013292 |     constant |     matern52 |   8.9571e+10 |        false |
|   16 |      16 | Best   |        6.95 |      388.47 |        6.95 |      6.9501 |       14.985 |         none |     matern52 |   1.2391e+11 |        false |
|   17 |      16 | Accept |      6.9644 |      348.93 |        6.95 |      6.9501 |        86.22 |         none |     matern52 |   2.0488e+11 |         true |
|   18 |      16 | Accept |      6.9663 |      495.97 |        6.95 |      6.9501 |       114.73 |     constant |     matern32 |   9.6298e+11 |        false |
|   19 |      16 | Accept |      6.9654 |      490.39 |        6.95 |      6.9501 |   0.00058631 |     constant |     matern32 |   8.7254e+10 |         true |
|   20 |      16 | Accept |      6.9652 |      493.32 |        6.95 |      6.9501 |   0.00011453 |     constant |     matern32 |   8.1202e+11 |         true |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      16 | Accept |      6.9642 |      511.41 |        6.95 |      6.9501 |       19.184 |     constant |     matern52 |   6.1298e+10 |         true |
|   22 |      16 | Accept |      6.9644 |      568.84 |        6.95 |      6.9501 |     0.064734 |         none | rationalquad |   2.4979e+11 |         true |
|   23 |      16 | Accept |      6.9659 |      513.59 |        6.95 |      6.9501 |       24.692 |     constant |     matern52 |    1.467e+12 |         true |
|   24 |      16 | Accept |      6.9644 |      453.29 |        6.95 |      6.9501 |       60.868 |         none | rationalquad |   5.6395e+12 |         true |
|   25 |      16 | Accept |      6.9639 |      510.92 |        6.95 |      6.9501 |       71.505 |     constant |     matern52 |   5.4158e+11 |        false |
|   26 |      16 | Accept |      6.9621 |       476.9 |        6.95 |      6.9501 |       51.166 |     constant |     matern32 |   8.4213e+10 |        false |
|   27 |      16 | Accept |      6.9653 |       434.3 |        6.95 |      6.9501 |       280.11 |     constant |     matern32 |   1.1632e+13 |         true |
|   28 |      16 | Accept |      6.9643 |      492.66 |        6.95 |      6.9501 |    0.0032445 |     constant |     matern52 |   4.5119e+12 |         true |
|   29 |      16 | Best   |       6.195 |      415.94 |       6.195 |      6.1951 |       322.38 |       linear |  exponential |    1.294e+13 |         true |
|   30 |      16 | Accept |      12.537 |        1144 |       6.195 |      6.1955 |       0.5419 |         none |     matern52 |   1.2679e+12 |        false |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 2847.6102 seconds.
Total objective function evaluation time: 20375.3209

Best observed feasible point:
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    322.38       linear         exponential       1.294e+13        true    

Observed objective function value = 6.195
Estimated objective function value = 6.1955
Function evaluation time = 415.9382

Best estimated feasible point (according to models):
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    322.38       linear         exponential       1.294e+13        true    

Estimated objective function value = 6.1955
Estimated function evaluation time = 416.0369

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 29)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 2863.569259 seconds.
Take a copy of the best attributes
Now use these optimum settings to do an exact GPR fit
[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In fitrsuperOptimized (line 51)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 9.402816 seconds.
Train a hyper-parameter optimized Ensemble of Trees model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|    1 |      15 | Best   |      6.9642 |      1.7679 |      6.9642 |      6.9642 |          Bag |           18 |            - |         3337 |          671 |            1 |
|    2 |      15 | Accept |      6.9642 |      1.5994 |      6.9642 |      6.9642 |      LSBoost |           20 |      0.35529 |         3149 |           11 |           26 |
|    3 |      12 | Best   |      6.0264 |      4.7427 |      6.0264 |      6.0282 |          Bag |           20 |            - |          564 |            4 |           16 |
|    4 |      12 | Accept |      6.1315 |      3.8822 |      6.0264 |      6.0282 |      LSBoost |           12 |      0.12233 |            3 |            2 |           32 |
|    5 |      12 | Accept |      7.3939 |      4.9167 |      6.0264 |      6.0282 |      LSBoost |           21 |     0.005618 |            1 |           15 |           10 |
|    6 |      12 | Accept |      6.4581 |      3.5782 |      6.0264 |      6.0282 |          Bag |           22 |            - |         1797 |            3 |           29 |
|    7 |       9 | Accept |      5.9315 |      7.4162 |      5.6676 |      5.6678 |          Bag |           24 |            - |          317 |            8 |           18 |
|    8 |       9 | Accept |      6.0762 |      6.8275 |      5.6676 |      5.6678 |          Bag |           31 |            - |          496 |           51 |           14 |
|    9 |       9 | Best   |      5.6676 |      14.701 |      5.6676 |      5.6678 |          Bag |           69 |            - |          158 |          989 |            8 |
|   10 |       9 | Accept |      6.9642 |      3.4776 |      5.6676 |      5.6678 |          Bag |           38 |            - |          505 |          405 |            1 |
|   11 |      16 | Accept |      6.1437 |      2.5094 |      5.6676 |      5.6677 |          Bag |           19 |            - |          212 |            5 |            4 |
|   12 |      16 | Accept |       6.723 |      5.6073 |      5.6676 |      5.6677 |      LSBoost |           11 |     0.049356 |           60 |         1876 |           15 |
|   13 |      13 | Accept |      6.1653 |      35.201 |      5.6676 |       5.668 |          Bag |          205 |            - |         1062 |          275 |           16 |
|   14 |      13 | Accept |      7.3925 |      8.8359 |      5.6676 |       5.668 |      LSBoost |           25 |    0.0049438 |           14 |            2 |           35 |
|   15 |      13 | Accept |      5.6951 |      5.9134 |      5.6676 |       5.668 |          Bag |           11 |            - |          236 |          304 |           31 |
|   16 |      13 | Accept |      6.4566 |      5.8915 |      5.6676 |       5.668 |          Bag |           49 |            - |           32 |            1 |            7 |
|   17 |      11 | Best   |      5.2513 |      45.018 |      5.2513 |      5.2514 |      LSBoost |           64 |      0.60465 |           20 |           34 |           22 |
|   18 |      11 | Accept |       5.734 |      44.584 |      5.2513 |      5.2514 |      LSBoost |          125 |     0.018765 |          299 |          186 |           23 |
|   19 |      11 | Accept |      6.0879 |      4.7532 |      5.2513 |      5.2514 |      LSBoost |           47 |      0.12157 |         2581 |          751 |           27 |
|   20 |      16 | Accept |      7.1398 |      1.6677 |      5.2513 |      5.2514 |      LSBoost |           13 |     0.028241 |         2230 |          236 |           26 |
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|   21 |      14 | Accept |      6.1863 |      39.864 |      5.2513 |      5.2514 |      LSBoost |          299 |     0.008628 |         1781 |           93 |           28 |
|   22 |      14 | Accept |      5.3455 |      10.269 |      5.2513 |      5.2514 |      LSBoost |           16 |       0.2584 |           82 |           91 |           19 |
|   23 |      14 | Accept |      5.6418 |      2.7777 |      5.2513 |      5.2514 |          Bag |           10 |            - |          128 |           85 |            7 |
|   24 |      13 | Accept |      5.8104 |      71.049 |      5.2513 |      5.2514 |          Bag |          185 |            - |            5 |           11 |           20 |
|   25 |      13 | Accept |      5.7632 |      15.627 |      5.2513 |      5.2514 |      LSBoost |           79 |      0.12138 |          893 |         2248 |           18 |
|   26 |      13 | Accept |      6.0763 |      77.662 |      5.2513 |      5.2514 |          Bag |          321 |            - |          899 |         1472 |           30 |
|   27 |      13 | Accept |       6.316 |      49.818 |      5.2513 |      5.2514 |          Bag |          257 |            - |          112 |            2 |           14 |
|   28 |      14 | Accept |      6.2664 |      106.06 |      5.2513 |      5.2514 |      LSBoost |          153 |    0.0055165 |            2 |          467 |           13 |
|   29 |      11 | Accept |      6.0128 |      112.16 |      5.1857 |      5.1858 |      LSBoost |          191 |    0.0050661 |            1 |          943 |            8 |
|   30 |      11 | Accept |      7.0499 |      92.866 |      5.1857 |      5.1858 |      LSBoost |          118 |    0.0025969 |            9 |          154 |           23 |
|   31 |      11 | Best   |      5.1857 |      52.912 |      5.1857 |      5.1858 |      LSBoost |           80 |      0.42504 |            5 |           35 |           23 |
|   32 |      11 | Accept |      5.4801 |      6.9224 |      5.1857 |      5.1858 |      LSBoost |           23 |      0.51804 |           25 |            7 |           16 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 32
Total elapsed time: 130.8277 seconds.
Total objective function evaluation time: 850.879

Best observed feasible point:
    Method     NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    _______    _________________    _________    ___________    ____________    ____________________

    LSBoost           80             0.42504          5              35                  23         

Observed objective function value = 5.1857
Estimated objective function value = 5.1858
Function evaluation time = 52.9122

Best estimated feasible point (according to models):
    Method     NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    _______    _________________    _________    ___________    ____________    ____________________

    LSBoost           80             0.42504          5              35                  23         

Estimated objective function value = 5.1858
Estimated function evaluation time = 52.8975

Elapsed time is 135.824321 seconds.
Train the super learner model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      6.9642 |      288.97 |      6.9642 |      6.9642 |       99.114 |         none |     matern32 |   1.3782e+11 |         true |
|    2 |      16 | Best   |      6.9642 |      380.72 |      6.9642 |      6.9642 |    0.0031377 |         none |     matern32 |   1.9515e+12 |         true |
|    3 |      16 | Best   |  6.3151e-05 |      499.14 |  6.3151e-05 |  0.00052743 |   0.00014911 |       linear |     matern32 |   7.5372e+11 |         true |
|    4 |      16 | Best   |  3.3212e-05 |      516.09 |  3.3212e-05 |  0.00038116 |       40.643 |       linear |     matern52 |   2.5064e+11 |         true |
|    5 |      16 | Accept |    3.36e-05 |      516.46 |  3.3212e-05 |   0.0003115 |      0.01512 |       linear |  exponential |   6.8967e+11 |        false |
|    6 |      16 | Accept |   0.0011895 |      685.75 |  3.3212e-05 |  0.00026513 |       129.53 | pureQuadrati | rationalquad |   6.1605e+12 |         true |
|    7 |      16 | Best   |   3.267e-05 |      747.73 |   3.267e-05 |  0.00023157 |   0.00025111 |       linear | rationalquad |     7.93e+12 |        false |
|    8 |      16 | Accept |  3.2861e-05 |       779.7 |   3.267e-05 |  0.00012228 |     0.007313 |       linear | rationalquad |   2.0595e+11 |        false |
|    9 |      16 | Accept |      6.9642 |      417.64 |   3.267e-05 |   0.0001372 |    0.0028717 |         none |     matern32 |   2.5698e+12 |         true |
|   10 |      16 | Accept |  0.00015167 |      505.14 |   3.267e-05 |  0.00012755 |    0.0017609 | pureQuadrati |     matern32 |   2.9732e+11 |         true |
|   11 |      16 | Accept |  6.3984e-05 |      499.82 |   3.267e-05 |  0.00011963 |       2.3417 | pureQuadrati |     matern52 |   2.0146e+12 |         true |
|   12 |      16 | Accept |   3.318e-05 |      521.55 |   3.267e-05 |  0.00011295 |    0.0015937 |       linear |     matern32 |   3.7704e+11 |        false |
|   13 |      16 | Accept |       9.583 |        1110 |   3.267e-05 |  0.00013409 |     0.002875 |         none |     matern32 |   1.6492e+13 |        false |
|   14 |      16 | Accept |      7.6428 |      1219.3 |   3.267e-05 |  0.00015558 |     0.033066 |         none |     matern52 |    2.022e+13 |        false |
|   15 |      16 | Accept |   3.451e-05 |      505.72 |   3.267e-05 |  0.00014745 |    0.0008112 |       linear |  exponential |   5.1686e+11 |         true |
|   16 |      16 | Accept |   3.299e-05 |      553.59 |   3.267e-05 |   0.0001403 |     0.025663 |       linear |     matern52 |   1.2988e+12 |        false |
|   17 |      16 | Accept |  3.2944e-05 |      524.68 |   3.267e-05 |  0.00013401 |    0.0059055 |       linear | squaredexpon |   2.4285e+12 |        false |
|   18 |      16 | Accept |  0.00016679 |      686.42 |   3.267e-05 |  0.00012845 |        97.43 |       linear | rationalquad |   4.7594e+11 |         true |
|   19 |      16 | Accept |  0.00024606 |      487.59 |   3.267e-05 |  0.00012355 |       72.136 | pureQuadrati |  exponential |   1.7347e+13 |         true |
|   20 |      16 | Accept |  0.00031997 |       484.6 |   3.267e-05 |  0.00011912 |       91.726 | pureQuadrati | squaredexpon |   6.1809e+12 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 1714.2806 seconds.
Total objective function evaluation time: 11930.5469

Best observed feasible point:
      Sigma       BasisFunction     KernelFunction      KernelScale    Standardize
    __________    _____________    _________________    ___________    ___________

    0.00025111       linear        rationalquadratic     7.93e+12         false   

Observed objective function value = 3.267e-05
Estimated objective function value = 0.00011912
Function evaluation time = 747.7334

Best estimated feasible point (according to models):
      Sigma       BasisFunction     KernelFunction      KernelScale    Standardize
    __________    _____________    _________________    ___________    ___________

    0.00025111       linear        rationalquadratic     7.93e+12         false   

Estimated objective function value = 0.00011912
Estimated function evaluation time = 752.0989

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 90)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 1737.129226 seconds.
Train the super learner error model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |  3.3846e-05 |      475.34 |  3.3846e-05 |  3.3846e-05 |      0.04904 |       linear |  exponential |   5.2205e+12 |         true |
|    2 |      16 | Best   |  3.2876e-05 |      517.25 |  3.2876e-05 |  3.3119e-05 |    0.0015688 |     constant |     matern32 |    8.436e+12 |        false |
|    3 |      16 | Accept |  3.3152e-05 |      534.42 |  3.2876e-05 |  3.3084e-05 |     0.010818 |       linear |     matern52 |   7.0935e+11 |        false |
|    4 |      16 | Best   |  3.2835e-05 |      535.88 |  3.2835e-05 |  3.3054e-05 |     0.047544 |       linear |     matern52 |   9.3721e+11 |        false |
|    5 |      16 | Accept |   3.287e-05 |      972.84 |  3.2835e-05 |  3.3026e-05 |   0.00016824 |         none | rationalquad |   4.9684e+11 |         true |
|    6 |      16 | Accept |  3.2927e-05 |      465.13 |  3.2835e-05 |  3.3019e-05 |    0.0017837 |     constant |     matern32 |   2.4883e+11 |        false |
|    7 |      16 | Accept |  3.2868e-05 |      1044.7 |  3.2835e-05 |  3.3004e-05 |    0.0038031 |     constant |  exponential |   1.3385e+13 |         true |
|    8 |      15 | Accept |  3.2859e-05 |       522.9 |  3.2835e-05 |  3.2923e-05 |     0.034108 |     constant |     matern32 |   1.5413e+13 |        false |
|    9 |      15 | Accept |  3.2858e-05 |      1061.5 |  3.2835e-05 |  3.2923e-05 |      0.03024 |         none |     matern52 |   2.1333e+10 |         true |
|   10 |      16 | Accept |   3.287e-05 |       711.1 |  3.2835e-05 |  3.2919e-05 |    0.0008131 |         none | squaredexpon |   3.4356e+12 |        false |
|   11 |      16 | Accept |  3.2858e-05 |      1589.8 |  3.2835e-05 |  3.2915e-05 |     0.014571 |         none | rationalquad |    1.607e+13 |        false |
|   12 |      16 | Accept |   3.287e-05 |      1616.2 |  3.2835e-05 |  3.2911e-05 |     0.007694 | pureQuadrati | rationalquad |   1.3303e+12 |        false |
|   13 |      16 | Error  |         NaN |      636.88 |  3.2835e-05 |  3.2911e-05 |    0.0019684 | pureQuadrati |  exponential |   2.1742e+11 |        false |
|   14 |      16 | Best   |  1.1096e-05 |      1001.3 |  1.1096e-05 |  1.1553e-05 |    0.0011068 |         none |  exponential |   1.0485e+11 |         true |
|   15 |      16 | Accept |  3.2875e-05 |      1042.4 |  1.1096e-05 |  1.1599e-05 |   0.00010491 |     constant |     matern52 |   6.2711e+12 |         true |
|   16 |      16 | Accept |  3.4971e-05 |      1048.6 |  1.1096e-05 |  1.1636e-05 |     0.012814 |       linear |     matern52 |   8.4884e+10 |         true |
|   17 |      16 | Accept |   0.0012219 |        1077 |  1.1096e-05 |  1.1106e-05 |   0.00015908 | pureQuadrati |     matern52 |   3.6596e+11 |         true |
|   18 |      16 | Accept |   3.287e-05 |      547.62 |  1.1096e-05 |   1.187e-05 |   0.00055619 |         none |  exponential |   1.9914e+13 |         true |
|   19 |      16 | Accept |  3.2858e-05 |      536.04 |  1.1096e-05 |  1.1829e-05 |     0.021538 |         none |     matern52 |    4.954e+12 |        false |
|   20 |      16 | Accept |  3.2857e-05 |      942.33 |  1.1096e-05 |  2.5628e-05 |    0.0072651 |         none |  exponential |    2.102e+10 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 2971.8043 seconds.
Total objective function evaluation time: 16879.1716

Best observed feasible point:
      Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    _________    _____________    ______________    ___________    ___________

    0.0011068        none          exponential      1.0485e+11        true    

Observed objective function value = 1.1096e-05
Estimated objective function value = 2.5628e-05
Function evaluation time = 1001.3245

Best estimated feasible point (according to models):
      Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    _________    _____________    ______________    ___________    ___________

    0.0011068        none          exponential      1.0485e+11        true    

Estimated objective function value = 2.5628e-05
Estimated function evaluation time = 1001.0747

Elapsed time is 2998.713229 seconds.
Elapsed time is 2998.717430 seconds.
Use the hyper-parameter optimized NN model for regression
Elapsed time is 0.042245 seconds.
Use the hyper-parameter optimized GPR model for regression
Elapsed time is 0.373729 seconds.
Use the hyper-parameter optimized Ensemble of Trees model for regression
Elapsed time is 0.184327 seconds.
Use the super learner model for regression
Elapsed time is 0.472496 seconds.
Use the error estimate to update the Super Learner Estimate
Elapsed time is 0.263641 seconds.
Use the hyper-parameter optimized NN model for regression
Elapsed time is 0.032728 seconds.
Use the hyper-parameter optimized GPR model for regression
Elapsed time is 0.074171 seconds.
Use the hyper-parameter optimized Ensemble of Trees model for regression
Elapsed time is 0.077738 seconds.
Use the super learner model for regression
Elapsed time is 0.088178 seconds.
Use the error estimate to update the Super Learner Estimate
Elapsed time is 0.056597 seconds.



combinedFigDaily = 

    "/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e063239e3/UTD_Rsl_All_Daily_001e063239e3_pmTotal_palas.png"


combinedFig = 

    "/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e063239e3/UTD_Rsl_All_2020_12_30_11_25_01/UTD_Rsl_All_2020_12_30_11_25_01_001e063239e3_pmTotal_palas.png"


plot3 = 

  Line with properties:

              Color: [0.9290 0.6940 0.1250]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x7059 double]
              YData: [1x7059 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot4 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot6 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot3 = 

  Line with properties:

              Color: [0.9290 0.6940 0.1250]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x7059 double]
              YData: [1x7059 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot4 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot6 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties

    "Saving Model Files for Node: 001e063239e3 & target :PM_{Total}"


modelsSaveNameDaily = 

    "/home/lhw150030/mintsData/modelsMats/UTDNodes/001e063239e3/daily_Mdl_001e063239e3_pmTotal_palas.mat"


modelsSaveName = 

    "/home/lhw150030/mintsData/modelsMats/UTDNodes/001e063239e3/UTD_Rsl_All_2020_12_30_11_25_01/UTD_Rsl_All_2020_12_30_11_25_01_001e063239e3_pmTotal_palas.mat"


resultsSaveName = 

    "/home/lhw150030/mintsData/modelsMats/UTDNodes/001e063239e3/daily_Mdl_001e063239e3_pmTotal_palas.csv"






trainingSaveNameDaily = 

    "/home/lhw150030/mintsData/trainingMats/UTDNodes/001e063239e3/UTD_Rsl_All_Daily_001e063239e3_pmTotal_palas.mat"


trainingSaveName = 

    "/home/lhw150030/mintsData/trainingMats/UTDNodes/001e063239e3/UTD_Rsl_All_2020_12_30_11_25_01/UTD_Rsl_All_2020_12_30_11_25_01_001e063239e3_pmTotal_palas.mat"



    "Gainin Data set for Node 001e063239e3 with target output dCn_palas @ 01-Jan-2021 00:07:25"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 299 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 76 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 133 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 111 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 60 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 22 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 13 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 11 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 7 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 6 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 155 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 244 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 246 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 148 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        5936


ans =

        1048

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |      16 | Best   |       16631 |     0.34135 |       16631 |       16631 |           24 |      0.46803 |
|    2 |       2 | Accept |      4454.2 |     0.52256 |      3441.9 |       15047 |           95 |      0.16712 |
|    3 |       2 | Accept |       37596 |     0.52891 |      3441.9 |       15047 |          100 |    0.0065094 |
|    4 |       2 | Accept |       34310 |     0.45515 |      3441.9 |       15047 |           45 |    0.0040525 |
|    5 |       2 | Accept |      6998.2 |     0.50796 |      3441.9 |       15047 |           89 |    0.0039957 |
|    6 |       2 | Accept |       14715 |     0.40717 |      3441.9 |       15047 |           47 |     0.082527 |
|    7 |       2 | Accept |      4697.9 |     0.41517 |      3441.9 |       15047 |           35 |     0.016672 |
|    8 |       2 | Accept |       18827 |     0.53153 |      3441.9 |       15047 |           99 |    0.0076362 |
|    9 |       2 | Accept |      3583.4 |     0.38181 |      3441.9 |       15047 |           37 |     0.018842 |
|   10 |       2 | Accept |       23432 |      0.4932 |      3441.9 |       15047 |           83 |      0.61377 |
|   11 |       2 | Accept |       24736 |     0.47696 |      3441.9 |       15047 |           77 |     0.030467 |
|   12 |       2 | Best   |      3441.9 |     0.35948 |      3441.9 |       15047 |           29 |      0.10148 |
|   13 |       2 | Accept |      8587.9 |     0.42568 |      3441.9 |       15047 |           55 |     0.010863 |
|   14 |       2 | Accept |       14437 |     0.41982 |      3441.9 |       15047 |           48 |    0.0011687 |
|   15 |       2 | Accept |       16372 |     0.49642 |      3441.9 |       15047 |           84 |    0.0052425 |
|   16 |       2 | Accept |      7945.3 |      0.5094 |      3441.9 |       15047 |           76 |     0.060995 |
|   17 |       1 | Accept |      9130.2 |     0.42077 |      1988.8 |       10750 |           65 |      0.22472 |
|   18 |       1 | Accept |      5803.6 |      0.3112 |      1988.8 |       10750 |            5 |       0.0198 |
|   19 |       1 | Accept |      9992.7 |     0.40262 |      1988.8 |       10750 |           47 |     0.063701 |
|   20 |       1 | Accept |      7576.6 |     0.34652 |      1988.8 |       10750 |           20 |     0.030803 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       1 | Accept |       13030 |     0.38959 |      1988.8 |       10750 |           24 |      0.37932 |
|   22 |       1 | Accept |       19469 |       0.505 |      1988.8 |       10750 |           58 |     0.001716 |
|   23 |       1 | Accept |      6414.3 |     0.42936 |      1988.8 |       10750 |           30 |    0.0022952 |
|   24 |       1 | Accept |       12929 |     0.35116 |      1988.8 |       10750 |           29 |    0.0014201 |
|   25 |       1 | Accept |       24664 |      0.5854 |      1988.8 |       10750 |           91 |      0.84362 |
|   26 |       1 | Accept |      6651.9 |     0.54716 |      1988.8 |       10750 |           88 |    0.0018535 |
|   27 |       1 | Best   |      1988.8 |     0.36467 |      1988.8 |       10750 |            8 |        0.123 |
|   28 |       1 | Accept |       14829 |     0.55557 |      1988.8 |       10750 |           67 |       0.7276 |
|   29 |       1 | Accept |      3408.3 |      0.4291 |      1988.8 |       10750 |           38 |      0.09088 |
|   30 |       1 | Accept |      5297.9 |     0.42882 |      1988.8 |       10750 |           55 |     0.017844 |
|   31 |       1 | Accept |       22931 |     0.45017 |      1988.8 |       10750 |           53 |      0.01927 |
|   32 |       1 | Accept |        3647 |     0.41836 |      1988.8 |       10750 |           39 |    0.0045263 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 32
Total elapsed time: 10.11 seconds.
Total objective function evaluation time: 14.2081

Best observed feasible point:
    hiddenLayerSize     lr  
    _______________    _____

           8           0.123

Observed objective function value = 1988.8009
Estimated objective function value = 10577.326
Function evaluation time = 0.36467

Best estimated feasible point (according to models):
    hiddenLayerSize      lr   
    _______________    _______

          24           0.37932

Estimated objective function value = 10749.5168
Estimated function evaluation time = 0.36972


T =

  1x2 table

    hiddenLayerSize      lr   
    _______________    _______

          24           0.37932

Elapsed time is 19.187745 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      17.697 |      257.64 |      17.697 |      17.697 |       5095.4 | pureQuadrati |     matern32 |   1.1325e+11 |         true |
|    2 |      16 | Best   |       16.79 |      311.32 |       16.79 |      17.244 |       1864.8 | pureQuadrati |     matern32 |     2.31e+11 |         true |
|    3 |      16 | Best   |      12.701 |      330.58 |      12.701 |      12.798 |       1497.1 |       linear | squaredexpon |   4.7743e+12 |        false |
|    4 |      16 | Accept |      12.785 |       427.6 |      12.701 |      12.702 |       114.16 | pureQuadrati | squaredexpon |   9.3835e+12 |        false |
|    5 |      16 | Accept |      12.785 |      450.19 |      12.701 |      12.702 |       0.3178 |         none |     matern32 |   1.3432e+13 |         true |
|    6 |      16 | Accept |      17.786 |      484.87 |      12.701 |      12.702 |      0.16138 |       linear | squaredexpon |   1.1368e+12 |         true |
|    7 |      16 | Accept |      12.734 |      485.27 |      12.701 |      12.702 |    0.0073757 |       linear |  exponential |   5.8609e+12 |         true |
|    8 |      16 | Accept |      12.785 |       649.7 |      12.701 |      12.702 |     0.039556 |         none | rationalquad |   4.2375e+11 |         true |
|    9 |      16 | Accept |      12.785 |      695.15 |      12.701 |      12.702 |       16.031 |     constant | rationalquad |    4.927e+12 |         true |
|   10 |      16 | Accept |      12.785 |      482.76 |      12.701 |      12.702 |    0.0098108 |     constant |  exponential |   1.1886e+12 |         true |
|   11 |      16 | Accept |      12.785 |      448.99 |      12.701 |      12.702 |       0.2648 |         none |     matern32 |   1.4993e+12 |         true |
|   12 |      16 | Accept |      16.332 |      487.97 |      12.701 |      12.702 |      0.14227 |       linear |  exponential |    2.555e+11 |         true |
|   13 |      16 | Accept |      12.786 |       563.2 |      12.701 |      12.702 |       2112.7 | pureQuadrati | squaredexpon |   5.2813e+12 |        false |
|   14 |      16 | Accept |       14.08 |      1060.5 |      12.701 |      12.702 |       78.123 |         none |     matern32 |   9.3547e+11 |        false |
|   15 |      16 | Accept |      29.731 |      1148.3 |      12.701 |      12.702 |      0.14726 |       linear | squaredexpon |   2.0955e+11 |        false |
|   16 |      16 | Best   |      12.692 |      491.03 |      12.692 |      12.692 |   0.00028289 |       linear |  exponential |   6.6909e+10 |         true |
|   17 |      16 | Accept |      12.785 |      648.02 |      12.692 |      12.692 |    0.0016723 |         none | rationalquad |   6.2582e+11 |         true |
|   18 |      16 | Accept |      12.785 |      641.69 |      12.692 |      12.692 |      0.62336 |     constant | rationalquad |   4.4321e+12 |         true |
|   19 |      16 | Accept |      12.785 |         483 |      12.692 |      12.692 |   0.00010759 |     constant |  exponential |   7.8563e+10 |         true |
|   20 |      16 | Accept |      12.785 |      490.72 |      12.692 |      12.692 |        0.167 |     constant |  exponential |   4.0693e+11 |         true |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      16 | Accept |      16.645 |        1151 |      12.692 |      12.693 |       9.3929 |       linear | squaredexpon |   1.8745e+13 |        false |
|   22 |      16 | Accept |      12.785 |      484.91 |      12.692 |      12.693 |    0.0019562 |     constant |  exponential |   2.0409e+13 |         true |
|   23 |      16 | Best   |      12.683 |      501.79 |      12.683 |      12.679 |    0.0093337 |       linear |  exponential |   2.0615e+13 |         true |
|   24 |      16 | Accept |      12.785 |      342.82 |      12.683 |      12.682 |         3209 |         none |     matern32 |   2.0229e+13 |         true |
|   25 |      16 | Accept |      13.092 |        1240 |      12.683 |      12.682 |      0.29563 | pureQuadrati | squaredexpon |   1.1958e+12 |        false |
|   26 |      16 | Accept |      12.785 |      528.87 |      12.683 |      12.682 |       36.803 |         none | rationalquad |   1.7523e+11 |         true |
|   27 |      16 | Accept |      12.786 |      386.56 |      12.683 |      12.682 |       5972.5 |     constant | rationalquad |   1.2261e+11 |         true |
|   28 |      16 | Best   |      12.458 |      1749.9 |      12.458 |      12.458 |    0.0018245 |     constant | rationalquad |   5.4966e+10 |        false |
|   29 |      16 | Accept |      12.785 |      296.68 |      12.458 |      12.458 |       3179.5 |     constant |  exponential |   5.0085e+11 |         true |
|   30 |      16 | Accept |      18.004 |      501.82 |      12.458 |      12.458 |     0.053632 | pureQuadrati |     matern32 |    1.537e+11 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 1860.4038 seconds.
Total objective function evaluation time: 18222.8995

Best observed feasible point:
      Sigma      BasisFunction     KernelFunction      KernelScale    Standardize
    _________    _____________    _________________    ___________    ___________

    0.0018245      constant       rationalquadratic    5.4966e+10        false   

Observed objective function value = 12.458
Estimated objective function value = 12.4581
Function evaluation time = 1749.9042

Best estimated feasible point (according to models):
      Sigma      BasisFunction     KernelFunction      KernelScale    Standardize
    _________    _____________    _________________    ___________    ___________

    0.0018245      constant       rationalquadratic    5.4966e+10        false   

Estimated objective function value = 12.4581
Estimated function evaluation time = 1748.1198

The identifier was:
stats:classreg:learning:impl:GPImpl:GPImpl:UnableToComputeLFactorExactThere was an error! The message was:
The Cholesky factor needed for making predictions cannot be computed. When calling fitrgp, try changing the initial values of 'KernelParameters' and 'Sigma'. Also consider setting 'Standardize' to true and increasing the value of 'SigmaLowerBound'.

    "Gainin Data set for Node 001e063239e3 with target output temperatureAirmar @ 01-Jan-2021 00:40:23"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 299 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 76 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 133 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 111 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 60 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 22 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 13 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 11 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 7 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 6 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 155 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 244 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 246 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 148 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        8342


ans =

        1472

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |       1 | Accept |      18.872 |      0.3851 |      10.923 |      21.696 |           24 |      0.35393 |
|    2 |       1 | Accept |      16.069 |     0.38183 |      10.923 |      21.696 |           24 |     0.015009 |
|    3 |       1 | Accept |      27.684 |     0.56131 |      10.923 |      21.696 |           70 |     0.039941 |
|    4 |       1 | Accept |      41.076 |     0.37967 |      10.923 |      21.696 |           24 |      0.74826 |
|    5 |       1 | Accept |      55.811 |     0.61979 |      10.923 |      21.696 |           86 |    0.0034188 |
|    6 |       1 | Accept |      46.895 |     0.58553 |      10.923 |      21.696 |           70 |      0.40607 |
|    7 |       1 | Accept |      20.359 |     0.36989 |      10.923 |      21.696 |           20 |     0.010721 |
|    8 |       1 | Accept |      78.684 |     0.56857 |      10.923 |      21.696 |           80 |       0.2308 |
|    9 |       1 | Accept |      44.826 |     0.59412 |      10.923 |      21.696 |           81 |     0.083873 |
|   10 |       1 | Accept |      28.464 |     0.62277 |      10.923 |      21.696 |           87 |    0.0095916 |
|   11 |       1 | Accept |      77.302 |     0.63036 |      10.923 |      21.696 |           87 |     0.002969 |
|   12 |       1 | Accept |      14.062 |     0.39764 |      10.923 |      21.696 |           25 |      0.86893 |
|   13 |       1 | Accept |      61.344 |     0.55549 |      10.923 |      21.696 |           69 |     0.033629 |
|   14 |       1 | Best   |      10.923 |     0.43408 |      10.923 |      21.696 |           36 |      0.14051 |
|   15 |       1 | Accept |      12.872 |     0.34675 |      10.923 |      21.696 |           12 |     0.012348 |
|   16 |       1 | Accept |       27.04 |     0.49289 |      10.923 |      21.696 |           43 |       0.1355 |
|   17 |       1 | Best   |      9.4103 |     0.30549 |      9.4103 |      31.945 |            5 |    0.0011805 |
|   18 |       1 | Accept |      56.443 |     0.45844 |      9.4103 |      31.945 |           40 |    0.0047688 |
|   19 |       1 | Accept |      33.732 |     0.40167 |      9.4103 |      31.945 |           11 |      0.12787 |
|   20 |       1 | Accept |      57.602 |     0.36052 |      9.4103 |      31.945 |           16 |      0.15693 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       1 | Accept |       29.65 |     0.54184 |      9.4103 |      31.945 |           44 |      0.10031 |
|   22 |       1 | Accept |      51.144 |     0.64934 |      9.4103 |      31.945 |           92 |      0.94233 |
|   23 |       1 | Accept |      70.848 |     0.48956 |      9.4103 |      31.945 |           55 |      0.48778 |
|   24 |       1 | Accept |      68.816 |     0.41684 |      9.4103 |      31.945 |           27 |     0.021493 |
|   25 |       1 | Accept |      23.803 |       0.521 |      9.4103 |      31.945 |           56 |      0.25184 |
|   26 |       1 | Accept |      19.831 |      0.6227 |      9.4103 |      31.945 |           76 |     0.001229 |
|   27 |       1 | Accept |      56.651 |     0.64031 |      9.4103 |      31.945 |           79 |    0.0014414 |
|   28 |       1 | Accept |      71.862 |      0.5463 |      9.4103 |      31.945 |           45 |     0.056775 |
|   29 |       1 | Accept |      16.668 |     0.40564 |      9.4103 |      31.945 |           22 |    0.0069946 |
|   30 |       1 | Accept |      80.501 |     0.58357 |      9.4103 |      31.945 |           72 |      0.27841 |
|   31 |       1 | Accept |      19.027 |     0.65922 |      9.4103 |      31.945 |           96 |     0.016384 |
|   32 |       1 | Accept |      51.231 |     0.66355 |      9.4103 |      31.945 |           76 |    0.0013925 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 32
Total elapsed time: 6.4731 seconds.
Total objective function evaluation time: 16.1918

Best observed feasible point:
    hiddenLayerSize       lr    
    _______________    _________

           5           0.0011805

Observed objective function value = 9.4103
Estimated objective function value = 31.8504
Function evaluation time = 0.30549

Best estimated feasible point (according to models):
    hiddenLayerSize      lr   
    _______________    _______

          16           0.15693

Estimated objective function value = 31.945
Estimated function evaluation time = 0.36611


T =

  1x2 table

    hiddenLayerSize      lr   
    _______________    _______

          16           0.15693

Elapsed time is 13.802452 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      4.4087 |      415.32 |      4.4087 |      4.4087 |       2.3995 |         none |     matern52 |   1.7322e+13 |         true |
|    2 |      16 | Best   |      3.4563 |      552.61 |      3.4563 |      3.5188 |       4.4072 |       linear |     matern32 |   4.2844e+10 |         true |
|    3 |      16 | Accept |      4.4087 |      589.34 |      3.4563 |      3.4574 |       6.6901 |         none | rationalquad |   2.3533e+11 |         true |
|    4 |      16 | Accept |      3.4873 |       610.5 |      3.4563 |      3.4566 |   0.00085392 |       linear | rationalquad |   1.3019e+13 |         true |
|    5 |      16 | Accept |      3.7393 |      464.04 |      3.4563 |      3.4564 |       1.1163 |       linear |     matern32 |   7.3548e+10 |         true |
|    6 |      16 | Accept |      6.5983 |        1097 |      3.4563 |       3.596 |      0.18608 |     constant |     matern52 |   4.5168e+11 |        false |
|    7 |      16 | Best   |       1.564 |      561.49 |       1.564 |      1.5644 |   0.00010041 |       linear |     matern32 |   2.5447e+10 |         true |
|    8 |      16 | Accept |      3.9896 |      548.64 |       1.564 |      1.7137 |       18.647 |       linear |     matern32 |    1.483e+12 |         true |
|    9 |      16 | Best   |     0.33318 |      609.82 |     0.33318 |      0.3335 |   0.00013119 |       linear | rationalquad |   6.6387e+10 |         true |
|   10 |      16 | Accept |      2.2343 |      561.36 |     0.33318 |     0.33352 |   0.00091491 |       linear |     matern32 |   2.1128e+10 |         true |
|   11 |      16 | Accept |      3.2315 |      563.39 |     0.33318 |     0.56811 |    0.0001005 |       linear |     matern32 |   4.5955e+10 |         true |
|   12 |      16 | Best   |     0.32308 |      733.04 |     0.32308 |     0.45173 |       89.696 |       linear | rationalquad |   1.5685e+12 |         true |
|   13 |      16 | Error  |         NaN |      2134.6 |     0.32308 |     0.45173 |      0.26375 |     constant | rationalquad |   5.3677e+10 |        false |
|   14 |      16 | Error  |         NaN |        2192 |     0.32308 |     0.45173 |    0.0001806 | pureQuadrati | rationalquad |   2.7933e+10 |        false |
|   15 |      16 | Accept |      2.4535 |      613.53 |     0.32308 |     0.51547 |    0.0026054 |       linear | rationalquad |   2.1021e+10 |         true |
|   16 |      16 | Accept |      2.4772 |       560.2 |     0.32308 |     0.67141 |      0.17557 |       linear | rationalquad |   8.9273e+10 |         true |
|   17 |      16 | Accept |      2.3426 |      615.13 |     0.32308 |      1.1764 |   0.00011258 |       linear | rationalquad |   2.8736e+10 |         true |
|   18 |      16 | Accept |      3.5167 |      566.88 |     0.32308 |     0.48566 |      0.19155 |       linear | rationalquad |   3.9357e+11 |         true |
|   19 |      16 | Accept |      3.1969 |      614.15 |     0.32308 |     0.55271 |   0.00010684 |       linear | rationalquad |   6.1581e+11 |         true |
|   20 |      16 | Accept |      2.7936 |      745.39 |     0.32308 |      0.7052 |       68.165 |       linear | rationalquad |   2.2134e+11 |         true |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      16 | Accept |      2.8643 |      614.31 |     0.32308 |     0.43957 |   0.00011917 |       linear | rationalquad |   1.7887e+11 |         true |
|   22 |      16 | Accept |      2.8943 |      737.74 |     0.32308 |      2.5049 |       47.386 |       linear | rationalquad |   1.5471e+12 |         true |
|   23 |      16 | Accept |     0.32609 |      742.91 |     0.32308 |      2.3351 |       80.732 |       linear | rationalquad |   7.9873e+11 |         true |
|   24 |      16 | Accept |      2.0321 |      734.62 |     0.32308 |      2.2958 |       50.038 |       linear | rationalquad |   2.1085e+12 |         true |
|   25 |      16 | Accept |      2.6983 |      519.48 |     0.32308 |      2.3486 |       0.4194 |       linear | rationalquad |   5.4781e+10 |         true |
|   26 |      16 | Accept |      3.6341 |      763.37 |     0.32308 |      1.9603 |       1.5766 |       linear | rationalquad |   1.5826e+12 |         true |
|   27 |      16 | Accept |      5.4862 |      738.05 |     0.32308 |      2.6299 |       85.032 |       linear | rationalquad |   1.8267e+12 |         true |
|   28 |      16 | Accept |      1.7489 |      573.68 |     0.32308 |      2.9323 |    0.0034906 |       linear |     matern52 |   2.0937e+10 |         true |
|   29 |      16 | Accept |      3.5925 |      519.34 |     0.32308 |      2.6696 |       87.533 |       linear | squaredexpon |   3.6868e+10 |         true |
|   30 |      16 | Accept |     0.89697 |      526.16 |     0.32308 |      2.8832 |       84.331 |       linear |     matern52 |   4.3641e+11 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 4217.9313 seconds.
Total objective function evaluation time: 21818.0466

Best observed feasible point:
    Sigma     BasisFunction     KernelFunction      KernelScale    Standardize
    ______    _____________    _________________    ___________    ___________

    89.696       linear        rationalquadratic    1.5685e+12        true    

Observed objective function value = 0.32308
Estimated objective function value = 2.8832
Function evaluation time = 733.0445

Best estimated feasible point (according to models):
     Sigma     BasisFunction     KernelFunction      KernelScale    Standardize
    _______    _____________    _________________    ___________    ___________

    0.17557       linear        rationalquadratic    8.9273e+10        true    

Estimated objective function value = 2.8832
Estimated function evaluation time = 560.3826

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 29)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 4235.016102 seconds.
Take a copy of the best attributes
Now use these optimum settings to do an exact GPR fit
[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In fitrsuperOptimized (line 51)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 25.958417 seconds.
Train a hyper-parameter optimized Ensemble of Trees model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|    1 |      16 | Best   |      6.3281 |      2.1809 |      6.3281 |      6.3281 |      LSBoost |           13 |     0.006442 |            1 |            3 |            8 |
|    2 |      16 | Best   |       3.218 |      3.9079 |       3.218 |      3.5128 |          Bag |           12 |            - |          283 |            2 |           24 |
|    3 |      12 | Accept |     0.47217 |      14.837 |     0.26974 |     0.27159 |      LSBoost |           16 |      0.23676 |           15 |          622 |           18 |
|    4 |      12 | Best   |     0.26974 |       11.23 |     0.26974 |     0.27159 |          Bag |           12 |            - |           73 |         4324 |           33 |
|    5 |      12 | Accept |     0.67456 |      6.0442 |     0.26974 |     0.27159 |          Bag |           15 |            - |           13 |         3863 |            6 |
|    6 |      12 | Accept |      4.9521 |       6.734 |     0.26974 |     0.27159 |      LSBoost |           41 |     0.019645 |         2130 |           56 |           30 |
|    7 |      12 | Accept |      3.8363 |      10.302 |     0.26974 |     0.27159 |          Bag |           75 |            - |           75 |            9 |            3 |
|    8 |      10 | Accept |      4.4087 |      19.352 |     0.26974 |     0.27214 |          Bag |          206 |            - |           21 |           58 |            1 |
|    9 |      10 | Accept |      6.3892 |      17.241 |     0.26974 |     0.27214 |      LSBoost |           28 |    0.0018611 |           27 |         6262 |           13 |
|   10 |      10 | Accept |      3.2191 |      5.4047 |     0.26974 |     0.27214 |          Bag |           20 |            - |          332 |            2 |           21 |
|   11 |      15 | Accept |      1.1811 |       29.09 |     0.26974 |     0.26992 |          Bag |           68 |            - |           35 |            6 |           27 |
|   12 |      15 | Accept |      2.0854 |      1.8769 |     0.26974 |     0.26992 |      LSBoost |           10 |      0.79736 |         1946 |         7773 |           32 |
|   13 |      14 | Accept |      3.4366 |      2.2736 |     0.26974 |        0.27 |      LSBoost |           15 |      0.13217 |         2075 |         4160 |           25 |
|   14 |      14 | Accept |      5.2373 |      6.1259 |     0.26974 |        0.27 |      LSBoost |           40 |     0.018339 |            3 |          229 |            2 |
|   15 |      16 | Best   |      0.1525 |      22.101 |      0.1525 |     0.15244 |          Bag |           13 |            - |            1 |         8040 |           31 |
|   16 |      16 | Accept |      4.4088 |      38.102 |      0.1525 |     0.15241 |          Bag |          402 |            - |         3813 |         8317 |            7 |
|   17 |      14 | Accept |      0.4243 |      86.072 |      0.1525 |     0.15246 |      LSBoost |          463 |      0.61323 |          557 |          382 |            8 |
|   18 |      14 | Accept |     0.25057 |      82.244 |      0.1525 |     0.15246 |      LSBoost |          202 |     0.038891 |           41 |            5 |           26 |
|   19 |      14 | Accept |     0.32444 |      12.141 |      0.1525 |     0.15246 |      LSBoost |           24 |      0.90217 |           11 |            4 |           31 |
|   20 |      14 | Accept |     0.80963 |      39.418 |      0.1525 |     0.15241 |      LSBoost |           11 |      0.96564 |            2 |         1317 |           16 |
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|   21 |      12 | Accept |      5.5341 |      68.147 |      0.1525 |     0.15484 |      LSBoost |          268 |    0.0018927 |          172 |           32 |            9 |
|   22 |      12 | Accept |     0.16596 |      41.988 |      0.1525 |     0.15484 |          Bag |           27 |            - |           10 |         5598 |           35 |
|   23 |      12 | Accept |     0.28852 |      12.496 |      0.1525 |     0.15484 |          Bag |           11 |            - |            7 |         7395 |           22 |
|   24 |      12 | Accept |      2.7462 |      81.735 |      0.1525 |      0.1552 |          Bag |          365 |            - |          877 |          415 |           17 |
|   25 |      10 | Accept |      1.2582 |      112.79 |      0.1525 |     0.15282 |          Bag |          215 |            - |            2 |           88 |           14 |
|   26 |      10 | Accept |     0.94719 |      91.149 |      0.1525 |     0.15282 |          Bag |          162 |            - |           52 |           11 |           29 |
|   27 |      10 | Accept |      3.8974 |       4.618 |      0.1525 |     0.15282 |      LSBoost |           43 |      0.37298 |            8 |            8 |            2 |
|   28 |      16 | Accept |     0.70314 |      134.89 |      0.1525 |     0.15281 |          Bag |          389 |            - |           11 |         3586 |            5 |
|   29 |      15 | Accept |       5.242 |      4.1896 |      0.1525 |     0.15286 |      LSBoost |           14 |     0.044029 |          107 |         2353 |            8 |
|   30 |      15 | Accept |      3.5157 |      5.5194 |      0.1525 |     0.15286 |      LSBoost |           23 |     0.079838 |            1 |            2 |           14 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 158.3133 seconds.
Total objective function evaluation time: 974.1973

Best observed feasible point:
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             13               NaN            1             8040                 31         

Observed objective function value = 0.1525
Estimated objective function value = 0.15286
Function evaluation time = 22.1013

Best estimated feasible point (according to models):
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             13               NaN            1             8040                 31         

Estimated objective function value = 0.15286
Estimated function evaluation time = 22.1079

Elapsed time is 161.567918 seconds.
Train the super learner model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      3.0969 |      720.38 |      3.0969 |      3.0969 |       6.5363 | pureQuadrati | rationalquad |   5.5016e+11 |         true |
|    2 |      16 | Accept |      4.4087 |      733.22 |      3.0969 |      3.1491 |   0.00095006 |         none | squaredexpon |   6.9721e+11 |         true |
|    3 |      16 | Best   |    0.033214 |      829.38 |    0.033214 |      2.4634 |     0.023961 |       linear | squaredexpon |   4.3722e+12 |        false |
|    4 |      16 | Accept |      4.4087 |      896.58 |    0.033214 |    0.033529 |    0.0092781 |         none | squaredexpon |   3.0547e+11 |         true |
|    5 |      16 | Error  |         NaN |      1028.3 |    0.033214 |    0.033529 |   0.00089034 |         none | squaredexpon |   4.5553e+10 |        false |
|    6 |      16 | Error  |         NaN |      1039.8 |    0.033214 |    0.033529 |      0.10025 |         none |  exponential |   1.3171e+13 |        false |
|    7 |      16 | Accept |       5.433 |      1203.3 |    0.033214 |    0.033556 |      0.74426 |     constant |     matern52 |   5.4494e+12 |        false |
|    8 |      16 | Accept |      1.9475 |         495 |    0.033214 |    0.033537 |       1.7356 | pureQuadrati |     matern32 |   3.0277e+10 |         true |
|    9 |      16 | Accept |      11.401 |      1227.8 |    0.033214 |     0.03364 |    0.0013189 |     constant |     matern52 |   1.3592e+12 |        false |
|   10 |      16 | Accept |      1.4089 |      633.22 |    0.033214 |    0.033594 |     0.093152 | pureQuadrati | rationalquad |   2.1737e+11 |         true |
|   11 |      16 | Error  |         NaN |        1565 |    0.033214 |    0.033594 |   0.00016583 |         none | rationalquad |   2.5396e+11 |        false |
|   12 |      16 | Accept |      3.0961 |      531.25 |    0.033214 |    0.033594 |       16.022 |       linear | squaredexpon |   2.0631e+12 |         true |
|   13 |      16 | Accept |      1.7628 |      554.35 |    0.033214 |    0.033574 |       13.388 | pureQuadrati |     matern52 |   5.8929e+10 |         true |
|   14 |      16 | Accept |    0.077194 |      547.58 |    0.033214 |    0.033443 |       12.512 |       linear | squaredexpon |   3.4648e+12 |        false |
|   15 |      16 | Error  |         NaN |      1035.3 |    0.033214 |    0.033443 |   0.00096517 | pureQuadrati | squaredexpon |   1.3996e+11 |        false |
|   16 |      16 | Accept |      2.0517 |      629.58 |    0.033214 |    0.033438 |   0.00010028 | pureQuadrati | rationalquad |   7.9738e+11 |         true |
|   17 |      16 | Accept |    0.033446 |      1243.5 |    0.033214 |    0.031237 |     0.014796 |       linear | squaredexpon |   7.4306e+11 |        false |
|   18 |      16 | Accept |      2.3719 |      567.34 |    0.033214 |    0.031254 |   0.00017813 | pureQuadrati |     matern32 |   1.4829e+12 |         true |
|   19 |      16 | Accept |      2.8076 |      587.28 |    0.033214 |    0.031248 |    0.0031856 | pureQuadrati |     matern52 |   1.5253e+13 |         true |
|   20 |      16 | Accept |     0.22568 |      563.62 |    0.033214 |    0.031454 |   0.00010064 |       linear | squaredexpon |   1.4329e+13 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 2596.8449 seconds.
Total objective function evaluation time: 16631.6536

Best observed feasible point:
     Sigma      BasisFunction      KernelFunction      KernelScale    Standardize
    ________    _____________    __________________    ___________    ___________

    0.023961       linear        squaredexponential    4.3722e+12        false   

Observed objective function value = 0.033214
Estimated objective function value = 0.031454
Function evaluation time = 829.3757

Best estimated feasible point (according to models):
     Sigma      BasisFunction      KernelFunction      KernelScale    Standardize
    ________    _____________    __________________    ___________    ___________

    0.023961       linear        squaredexponential    4.3722e+12        false   

Estimated objective function value = 0.031454
Estimated function evaluation time = 800.0933

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 90)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 2630.952010 seconds.
Train the super learner error model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |    0.033633 |      457.93 |    0.033633 |    0.033633 |     0.066621 |         none |  exponential |   7.7083e+11 |         true |
|    2 |      16 | Error  |         NaN |      563.02 |         NaN |    0.033633 |     0.015358 |         none |  exponential |   1.0032e+11 |        false |
|    3 |      16 | Accept |      1.3458 |      768.64 |    0.033633 |    0.085807 |      0.94145 |       linear | rationalquad |   2.1097e+11 |         true |
|    4 |      16 | Accept |    0.036949 |        1225 |    0.033633 |    0.079307 |   0.00027738 |       linear | squaredexpon |   3.4554e+12 |        false |
|    5 |      16 | Accept |      1.9265 |      1232.3 |    0.033633 |    0.087884 |     0.015524 |       linear | squaredexpon |   3.2702e+10 |        false |
|    6 |      16 | Accept |    0.033925 |      1267.3 |    0.033633 |    0.033697 |   0.00028785 |         none |  exponential |   6.9149e+10 |         true |
|    7 |      16 | Accept |    0.033634 |      511.74 |    0.033633 |    0.033606 |     0.025832 |         none |  exponential |   7.3662e+12 |         true |
|    8 |      16 | Best   |    0.033628 |       510.7 |    0.033628 |    0.033584 |     0.030573 |         none |  exponential |   5.4688e+11 |         true |
|    9 |      16 | Best   |    0.033625 |      525.82 |    0.033625 |    0.033618 |      0.15828 |         none |  exponential |    7.489e+11 |         true |
|   10 |      16 | Best   |    0.033625 |       475.1 |    0.033625 |    0.033627 |      0.77413 |         none |     matern32 |   7.2104e+11 |         true |
|   11 |      16 | Accept |    0.033772 |      568.48 |    0.033625 |    0.033646 |       1.6799 |       linear | squaredexpon |   1.8964e+13 |        false |
|   12 |      16 | Accept |    0.033631 |      514.55 |    0.033625 |    0.033644 |      0.10734 |         none |     matern32 |    2.081e+10 |         true |
|   13 |      16 | Accept |    0.033635 |      587.73 |    0.033625 |    0.033641 |     0.011085 |         none |     matern32 |   2.0631e+13 |         true |
|   14 |      16 | Accept |     0.24066 |      1274.5 |    0.033625 |    0.033644 |    0.0019776 |       linear |  exponential |   7.1658e+11 |         true |
|   15 |      16 | Accept |    0.034553 |      1308.8 |    0.033625 |    0.033644 |   0.00081722 |     constant |  exponential |   7.1172e+11 |         true |
|   16 |      16 | Accept |    0.033633 |      542.78 |    0.033625 |    0.033645 |      0.37954 |     constant |     matern32 |   6.3806e+11 |         true |
|   17 |      16 | Accept |     0.90937 |      1078.3 |    0.033625 |    0.033648 |    0.0038266 |       linear |     matern32 |   6.6999e+11 |         true |
|   18 |      16 | Accept |    0.033708 |      1091.8 |    0.033625 |    0.033646 |     0.025175 |     constant |  exponential |   2.0976e+10 |         true |
|   19 |      16 | Accept |    0.033652 |        1129 |    0.033625 |    0.033644 |   0.00057896 |     constant |     matern32 |   2.0127e+13 |         true |
|   20 |      16 | Error  |         NaN |       977.6 |    0.033625 |    0.033644 |   0.00010754 |     constant |  exponential |   2.0513e+13 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 5173.885 seconds.
Total objective function evaluation time: 16611.0578

Best observed feasible point:
     Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    _______    _____________    ______________    ___________    ___________

    0.77413        none            matern32       7.2104e+11        true    

Observed objective function value = 0.033625
Estimated objective function value = 0.033621
Function evaluation time = 475.0976

Best estimated feasible point (according to models):
     Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    _______    _____________    ______________    ___________    ___________

    0.15828        none          exponential       7.489e+11        true    

Estimated objective function value = 0.033644
Estimated function evaluation time = 521.3195

Elapsed time is 5191.019441 seconds.
Elapsed time is 5191.023054 seconds.
Use the hyper-parameter optimized NN model for regression
Elapsed time is 0.052772 seconds.
Use the hyper-parameter optimized GPR model for regression
Elapsed time is 0.696073 seconds.
Use the hyper-parameter optimized Ensemble of Trees model for regression
Elapsed time is 0.054108 seconds.
Use the super learner model for regression
Elapsed time is 0.281265 seconds.
Use the error estimate to update the Super Learner Estimate
Elapsed time is 0.353465 seconds.
Use the hyper-parameter optimized NN model for regression
Elapsed time is 0.032870 seconds.
Use the hyper-parameter optimized GPR model for regression
Elapsed time is 0.126009 seconds.
Use the hyper-parameter optimized Ensemble of Trees model for regression
Elapsed time is 0.029243 seconds.
Use the super learner model for regression
Elapsed time is 0.054187 seconds.
Use the error estimate to update the Super Learner Estimate
Elapsed time is 0.069066 seconds.



combinedFigDaily = 

    "/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e063239e3/UTD_Rsl_All_Daily_001e063239e3_temperatureAirmar.png"


combinedFig = 

    "/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e063239e3/UTD_Rsl_All_2020_12_30_11_25_01/UTD_Rsl_All_2020_12_30_11_25_01_001e063239e3_temperatureAirmar.png"


plot3 = 

  Line with properties:

              Color: [0.9290 0.6940 0.1250]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x8342 double]
              YData: [1x8342 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot4 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot6 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot3 = 

  Line with properties:

              Color: [0.9290 0.6940 0.1250]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x8342 double]
              YData: [1x8342 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot4 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties


plot6 = 

  Line (fitted curve) with properties:

              Color: [1 0 0]
          LineStyle: '-'
          LineWidth: 0.5000
             Marker: 'none'
         MarkerSize: 6
    MarkerFaceColor: 'none'
              XData: [1x1001 double]
              YData: [1x1001 double]
              ZData: [1x0 double]

  Use GET to show all properties

    "Saving Model Files for Node: 001e063239e3 & target :Temperature"


modelsSaveNameDaily = 

    "/home/lhw150030/mintsData/modelsMats/UTDNodes/001e063239e3/daily_Mdl_001e063239e3_temperatureAirmar.mat"


modelsSaveName = 

    "/home/lhw150030/mintsData/modelsMats/UTDNodes/001e063239e3/UTD_Rsl_All_2020_12_30_11_25_01/UTD_Rsl_All_2020_12_30_11_25_01_001e063239e3_temperatureAirmar.mat"


resultsSaveName = 

    "/home/lhw150030/mintsData/modelsMats/UTDNodes/001e063239e3/daily_Mdl_001e063239e3_temperatureAirmar.csv"






trainingSaveNameDaily = 

    "/home/lhw150030/mintsData/trainingMats/UTDNodes/001e063239e3/UTD_Rsl_All_Daily_001e063239e3_temperatureAirmar.mat"


trainingSaveName = 

    "/home/lhw150030/mintsData/trainingMats/UTDNodes/001e063239e3/UTD_Rsl_All_2020_12_30_11_25_01/UTD_Rsl_All_2020_12_30_11_25_01_001e063239e3_temperatureAirmar.mat"



    "Gainin Data set for Node 001e063239e3 with target output humidityAirmar @ 01-Jan-2021 04:05:57"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 299 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 76 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 133 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 111 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 60 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 22 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 13 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 11 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 7 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 6 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 155 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 244 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 246 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 148 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

        8583


ans =

        1515

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |       1 | Accept |      36.482 |     0.48341 |      22.886 |      100.77 |           43 |     0.084632 |
|    2 |       1 | Accept |      42.901 |     0.40603 |      22.886 |      100.77 |           17 |       0.9138 |
|    3 |       1 | Accept |      91.044 |     0.59211 |      22.886 |      100.77 |           84 |      0.17169 |
|    4 |       1 | Accept |      83.373 |     0.37381 |      22.886 |      100.77 |           21 |      0.61641 |
|    5 |       1 | Accept |      73.917 |     0.68522 |      22.886 |      100.77 |           99 |    0.0011543 |
|    6 |       1 | Accept |      300.58 |     0.63963 |      22.886 |      100.77 |           84 |    0.0010266 |
|    7 |       1 | Accept |      234.28 |     0.66474 |      22.886 |      100.77 |           98 |     0.010328 |
|    8 |       1 | Accept |      102.93 |     0.40195 |      22.886 |      100.77 |           30 |       0.6931 |
|    9 |       1 | Accept |      39.855 |     0.48389 |      22.886 |      100.77 |           47 |     0.002117 |
|   10 |       1 | Accept |      99.376 |     0.60448 |      22.886 |      100.77 |           84 |     0.012345 |
|   11 |       1 | Accept |      74.844 |      0.5178 |      22.886 |      100.77 |           56 |     0.081055 |
|   12 |       1 | Accept |      151.01 |      0.5118 |      22.886 |      100.77 |           53 |    0.0015013 |
|   13 |       1 | Accept |      85.558 |     0.56124 |      22.886 |      100.77 |           68 |    0.0012565 |
|   14 |       1 | Accept |      35.961 |     0.58661 |      22.886 |      100.77 |           76 |    0.0010328 |
|   15 |       1 | Accept |      137.42 |     0.52904 |      22.886 |      100.77 |           64 |     0.065968 |
|   16 |       1 | Best   |      22.886 |     0.41338 |      22.886 |      100.77 |           23 |      0.16067 |
|   17 |       1 | Accept |      25.252 |     0.30193 |      22.886 |      80.313 |            5 |    0.0010051 |
|   18 |       1 | Accept |      96.145 |     0.40818 |      22.886 |      80.313 |           33 |      0.32163 |
|   19 |       1 | Accept |      25.749 |     0.34551 |      22.886 |      80.313 |           13 |     0.002576 |
|   20 |       1 | Accept |      52.606 |     0.51059 |      22.886 |      80.313 |           61 |      0.94015 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       1 | Accept |      25.917 |     0.55776 |      22.886 |      80.313 |           72 |    0.0022019 |
|   22 |       1 | Accept |      105.33 |      0.5573 |      22.886 |      80.313 |           77 |      0.72249 |
|   23 |       1 | Accept |      33.478 |      0.6186 |      22.886 |      80.313 |           90 |    0.0034742 |
|   24 |       1 | Accept |      155.71 |     0.45373 |      22.886 |      80.313 |           42 |    0.0020854 |
|   25 |       1 | Accept |      99.867 |     0.59429 |      22.886 |      80.313 |           88 |      0.13847 |
|   26 |       1 | Accept |      47.914 |     0.41353 |      22.886 |      80.313 |           29 |     0.010009 |
|   27 |       1 | Accept |      48.955 |      0.3552 |      22.886 |      80.313 |           17 |     0.038144 |
|   28 |       1 | Accept |       53.88 |     0.54072 |      22.886 |      80.313 |           54 |      0.28796 |
|   29 |       1 | Accept |      32.884 |     0.42908 |      22.886 |      80.313 |           35 |      0.05454 |
|   30 |       1 | Accept |      72.496 |     0.71629 |      22.886 |      80.313 |           94 |    0.0030621 |
|   31 |       1 | Accept |      26.408 |     0.54499 |      22.886 |      80.313 |           64 |     0.001482 |
|   32 |       1 | Accept |      55.017 |     0.55118 |      22.886 |      80.313 |           53 |    0.0021218 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 32
Total elapsed time: 8.603 seconds.
Total objective function evaluation time: 16.354

Best observed feasible point:
    hiddenLayerSize      lr   
    _______________    _______

          23           0.16067

Observed objective function value = 22.8856
Estimated objective function value = 80.3132
Function evaluation time = 0.41338

Best estimated feasible point (according to models):
    hiddenLayerSize       lr    
    _______________    _________

           5           0.0010051

Estimated objective function value = 80.3131
Estimated function evaluation time = 0.31309


T =

  1x2 table

    hiddenLayerSize       lr    
    _______________    _________

           5           0.0010051

Elapsed time is 12.375662 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      5.5625 |      459.56 |      5.5625 |      5.5625 |       2.4409 |         none |     matern32 |   1.1614e+11 |         true |
|    2 |      16 | Best   |      5.5448 |      549.76 |      5.5448 |      5.5455 |      0.03244 |       linear | squaredexpon |   1.7321e+11 |         true |
|    3 |      16 | Best   |      4.5192 |      596.73 |      4.5192 |      4.5613 |    0.0021089 | pureQuadrati |     matern32 |   1.7796e+11 |         true |
|    4 |      16 | Error  |         NaN |      605.63 |      4.5192 |      4.5613 |   0.00028311 | pureQuadrati |  exponential |   2.4916e+11 |        false |
|    5 |      16 | Error  |         NaN |      777.53 |         NaN |      5.5409 |       1.1654 |         none |  exponential |   3.5063e+10 |        false |
|    6 |      16 | Best   |      1.3811 |       816.7 |      1.3811 |      2.3571 |       18.694 |       linear | rationalquad |   5.2079e+10 |        false |
|    7 |      16 | Error  |         NaN |      1029.5 |      1.3811 |      2.3571 |   0.00013333 |         none |  exponential |   4.7502e+12 |        false |
|    8 |      16 | Accept |      5.5629 |      573.18 |      1.3811 |      1.3839 |     0.014497 |     constant |     matern32 |   4.0963e+10 |         true |
|    9 |      16 | Accept |      2.3324 |      552.23 |      1.3811 |      1.6575 |    0.0003102 |       linear | squaredexpon |   3.4462e+11 |         true |
|   10 |      16 | Accept |      3.8897 |      565.68 |      1.3811 |      1.6128 |   0.00016434 | pureQuadrati |     matern32 |   4.4555e+10 |         true |
|   11 |      16 | Accept |      7.9781 |      1196.9 |      1.3811 |      1.3814 |   0.00010561 |     constant |     matern32 |   2.0531e+12 |        false |
|   12 |      16 | Accept |      6.0957 |      597.82 |      1.3811 |      1.3814 |     0.052027 | pureQuadrati |     matern32 |   7.7956e+10 |         true |
|   13 |      16 | Best   |       1.378 |      814.68 |       1.378 |      1.3794 |       19.271 |       linear | rationalquad |   4.6314e+10 |        false |
|   14 |      16 | Best   |       1.377 |      816.71 |       1.377 |       1.379 |       16.516 |       linear | rationalquad |   8.3922e+10 |        false |
|   15 |      16 | Accept |      1.3812 |      795.88 |       1.377 |      1.3787 |       21.071 |       linear | rationalquad |   1.5466e+11 |        false |
|   16 |      16 | Accept |       1.377 |      737.02 |       1.377 |      1.3784 |       160.71 |       linear | rationalquad |   9.8567e+12 |        false |
|   17 |      16 | Accept |      1.3776 |      794.34 |       1.377 |      1.3788 |       18.372 |       linear | rationalquad |   2.0315e+11 |        false |
|   18 |      16 | Accept |        1.38 |      480.43 |       1.377 |      1.3789 |       160.51 |       linear | squaredexpon |   1.2727e+13 |        false |
|   19 |      16 | Accept |        1.39 |      872.05 |       1.377 |      1.3789 |   0.00038745 |       linear | squaredexpon |   7.2152e+12 |        false |
|   20 |      16 | Accept |      1.6066 |      1855.7 |       1.377 |      1.3789 |    0.0001619 |       linear | rationalquad |   1.8704e+13 |        false |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      16 | Best   |      1.3766 |      542.25 |      1.3766 |      1.3789 |        3.751 |       linear | squaredexpon |   6.5379e+11 |        false |
|   22 |      16 | Accept |      1.3785 |      2340.1 |      1.3766 |      1.3789 |       1.2813 |       linear | rationalquad |   1.1274e+13 |        false |
|   23 |      16 | Accept |       4.914 |      589.23 |      1.3766 |      1.3789 |   0.00010327 |       linear | rationalquad |    2.079e+11 |         true |
|   24 |      16 | Accept |      3.0125 |      1215.2 |      1.3766 |      1.3789 |      0.01979 |       linear | squaredexpon |   9.7908e+12 |        false |
|   25 |      16 | Accept |      7.9336 |      1046.2 |      1.3766 |      1.3789 |      0.16788 | pureQuadrati | squaredexpon |   7.3203e+11 |        false |
|   26 |      16 | Accept |      2.5281 |      1797.2 |      1.3766 |      1.3785 |    0.0093247 |       linear | rationalquad |   8.2693e+11 |        false |
|   27 |      16 | Accept |      5.7862 |        1252 |      1.3766 |      1.3785 |      0.21028 |         none | squaredexpon |   7.3573e+12 |        false |
|   28 |      16 | Accept |      3.6718 |      874.45 |      1.3766 |      1.3792 |   0.00010041 |       linear | squaredexpon |   3.1505e+12 |        false |
|   29 |      16 | Accept |      4.2965 |      687.55 |      1.3766 |      1.3792 |       157.51 |       linear | rationalquad |   3.4252e+12 |         true |
|   30 |      16 | Accept |      1.3836 |      589.85 |      1.3766 |      1.3792 |        23.66 |       linear | squaredexpon |   8.3131e+10 |        false |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 5414.3079 seconds.
Total objective function evaluation time: 26422.1039

Best observed feasible point:
    Sigma    BasisFunction      KernelFunction      KernelScale    Standardize
    _____    _____________    __________________    ___________    ___________

    3.751       linear        squaredexponential    6.5379e+11        false   

Observed objective function value = 1.3766
Estimated objective function value = 1.377
Function evaluation time = 542.2494

Best estimated feasible point (according to models):
    Sigma     BasisFunction     KernelFunction      KernelScale    Standardize
    ______    _____________    _________________    ___________    ___________

    18.694       linear        rationalquadratic    5.2079e+10        false   

Estimated objective function value = 1.3792
Estimated function evaluation time = 816.1258

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 29)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 5434.030090 seconds.
Take a copy of the best attributes
Now use these optimum settings to do an exact GPR fit
[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In fitrsuperOptimized (line 51)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 24.143606 seconds.
Train a hyper-parameter optimized Ensemble of Trees model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|    1 |      16 | Best   |      5.3091 |       1.485 |      5.3091 |      5.3091 |          Bag |           10 |            - |           93 |         2474 |            2 |
|    2 |      15 | Accept |      8.0376 |      2.4944 |      5.3091 |      5.3093 |      LSBoost |           15 |    0.0014932 |         1658 |         2149 |           17 |
|    3 |      15 | Accept |      8.0483 |      2.2088 |      5.3091 |      5.3093 |      LSBoost |           11 |    0.0015338 |            3 |            2 |           11 |
|    4 |      11 | Accept |      4.9608 |      5.9595 |      1.4722 |      1.4727 |          Bag |           31 |            - |         1591 |          607 |           18 |
|    5 |      11 | Best   |      1.4722 |      8.9504 |      1.4722 |      1.4727 |      LSBoost |           40 |      0.14902 |          756 |          187 |           14 |
|    6 |      11 | Accept |      4.4216 |      10.898 |      1.4722 |      1.4727 |      LSBoost |           20 |     0.088767 |           11 |            6 |           35 |
|    7 |      11 | Accept |      5.2341 |      5.8831 |      1.4722 |      1.4727 |      LSBoost |           43 |      0.06863 |          513 |         3838 |            4 |
|    8 |      11 | Accept |      6.6071 |      18.456 |      1.4722 |      1.4727 |      LSBoost |           12 |     0.059631 |            8 |          422 |           33 |
|    9 |      15 | Best   |     0.69732 |      31.181 |     0.69732 |       0.698 |          Bag |           30 |            - |            2 |         2644 |           15 |
|   10 |      15 | Accept |      5.4609 |      1.4182 |     0.69732 |       0.698 |          Bag |           12 |            - |         2901 |           33 |            5 |
|   11 |      14 | Accept |      1.1745 |      32.356 |     0.69732 |       1.089 |          Bag |           38 |            - |          128 |         4018 |           35 |
|   12 |      14 | Accept |      7.4056 |      8.1027 |     0.69732 |       1.089 |      LSBoost |           24 |     0.014222 |           23 |           38 |           10 |
|   13 |      10 | Accept |      2.7865 |      49.097 |     0.69732 |      1.2206 |          Bag |          263 |            - |          997 |           61 |           12 |
|   14 |      10 | Accept |     0.85518 |      47.174 |     0.69732 |      1.2206 |      LSBoost |           56 |      0.72118 |           34 |           18 |           30 |
|   15 |      10 | Accept |      3.8866 |      10.343 |     0.69732 |      1.2206 |          Bag |           44 |            - |            6 |           47 |            5 |
|   16 |      10 | Accept |      7.5308 |      15.389 |     0.69732 |      1.2206 |      LSBoost |           85 |     0.003451 |            8 |          828 |            3 |
|   17 |      10 | Accept |      3.9909 |      5.0227 |     0.69732 |      1.2206 |      LSBoost |           10 |       0.1964 |           33 |            8 |           24 |
|   18 |      16 | Accept |      5.8345 |      27.437 |     0.69732 |      1.1879 |      LSBoost |           71 |     0.016424 |          108 |         1687 |           11 |
|   19 |      14 | Accept |      5.5626 |      30.316 |     0.69732 |     0.69772 |      LSBoost |          412 |      0.24379 |          467 |            2 |            1 |
|   20 |      14 | Accept |      5.5626 |      17.829 |     0.69732 |     0.69772 |      LSBoost |          252 |      0.26002 |         4278 |           96 |           34 |
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|   21 |      14 | Accept |      5.2373 |      4.8924 |     0.69732 |     0.69772 |          Bag |           32 |            - |         3125 |          303 |           23 |
|   22 |      11 | Accept |      5.5626 |      20.036 |     0.69732 |     0.69787 |      LSBoost |          272 |      0.99521 |         3825 |            8 |           22 |
|   23 |      11 | Accept |      1.7899 |      19.461 |     0.69732 |     0.69787 |          Bag |           26 |            - |            1 |            8 |           35 |
|   24 |      11 | Accept |      4.8557 |      13.798 |     0.69732 |     0.69787 |          Bag |           76 |            - |            6 |            4 |            6 |
|   25 |      11 | Accept |      8.0253 |      10.384 |     0.69732 |     0.69787 |      LSBoost |           25 |    0.0011194 |          445 |            7 |           25 |
|   26 |      16 | Accept |      5.5626 |      1.9389 |     0.69732 |     0.69785 |          Bag |           19 |            - |         3677 |           35 |           12 |
|   27 |      15 | Accept |       4.098 |       101.1 |     0.69732 |     0.69803 |          Bag |          439 |            - |            1 |            1 |           27 |
|   28 |      15 | Accept |      3.3882 |      4.3148 |     0.69732 |     0.69803 |      LSBoost |           34 |      0.95221 |         2606 |           11 |           13 |
|   29 |      14 | Accept |      1.6435 |      107.78 |     0.69732 |     0.69811 |          Bag |          202 |            - |          334 |           91 |           30 |
|   30 |      14 | Accept |      2.6601 |      6.0395 |     0.69732 |     0.69811 |      LSBoost |           34 |      0.70835 |         2046 |          268 |           32 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 124.6882 seconds.
Total objective function evaluation time: 621.7395

Best observed feasible point:
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             30               NaN            2             2644                 15         

Observed objective function value = 0.69732
Estimated objective function value = 0.69811
Function evaluation time = 31.1813

Best estimated feasible point (according to models):
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             30               NaN            2             2644                 15         

Estimated objective function value = 0.69811
Estimated function evaluation time = 31.1676

Elapsed time is 128.385843 seconds.
Train the super learner model for regression
Copying objective function to workers...
Done copying objective function to workers.
