Running calibration scripts for UTD Node: 12
Running on host: compute-1-1-27

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
              R2020a Update 1 (9.8.0.1359463) 64-bit (glnxa64)
                               April 9, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 


    "---------------------MINTS---------------------"

30-Dec-2020 11:24:42

mintsDefinitions = 

  struct with fields:

                dataFolder: '/home/lhw150030/mintsData'
               poolWorkers: 16
                  timeSpan: 30
                  airmarID: '001e0610c0e4'
             binsPerColumn: 500
              numberPerBin: 2
                    pValid: 0.1500
                   nodeIDs: {1x16 cell}
               inputStack1: {1x9 cell}
         mintsInputsStack1: {1x35 cell}
    mintsInputLabelsStack1: {1x35 cell}
               inputStack2: {1x11 cell}
         mintsInputsStack2: {1x35 cell}
    mintsInputLabelsStack2: {1x35 cell}
               inputStack3: {1x10 cell}
         mintsInputsStack3: {1x38 cell}
    mintsInputLabelsStack3: {1x38 cell}
              mintsTargets: {1x10 cell}
         mintsTargetLabels: {1x10 cell}
                     units: {1x10 cell}
               instruments: {1x10 cell}

Starting parallel pool (parpool) using the 'local' profile ...
Connected to the parallel pool (number of workers: 16).

ans = 

 ProcessPool with properties: 

            Connected: true
           NumWorkers: 16
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


airmarFolder = 

    "/home/lhw150030/mintsData/referenceMats/airmar"

UTD_Rsl_All_2020_12_30_11_25_09


UTD_Rsl_All_Daily


Super Learner All Inputs




    "Data Folder Located @:/home/lhw150030/mintsData"

    "Raw Data Located @: /home/lhw150030/mintsData"

    "Raw DotMat Data Located @ :/home/lhw150030/mintsData/rawMats"

    "UTD Nodes DotMat Data Located @ :/home/lhw150030/mintsData/rawMats/UTDNodes"

    "Reference Data Located @: /home/lhw150030/mintsData/reference"

    "Reference DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats"

    "Palas Raw Data Located @ :/home/lhw150030/mintsData/reference/palasStream"

    "Palas DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats/palas"

    "Car GPS Files Located @ :/home/lhw150030/mintsData/referenceMats/carMintsGPS"

    "Loading Palas Files"

    "Loading GPS Files"

    "Loading Airmar Files"

    "Aligning GPS data with Palas Data"

    "WSTC Palas Data"

    "Palas With Airmar"

    "Analysis"

    "Save merged data for calibration: 001e063239e6"



    "Creating Training Data Sets for Node: 001e063239e6"



    "Gainin Data set for Node 001e063239e6 with target output pm1_palas @ 30-Dec-2020 11:25:18"

Going through column 1 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 330 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 75 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 318 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 81 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 59 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 38 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 19 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 8 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 4 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 487 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 321 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 191 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 500 bins for this column. With 2 members per bin.
Going through column 37 and choosing a representative sample. Choosing 149 bins for this column. With 2 members per bin.
Going through column 38 and choosing a representative sample. Choosing 291 bins for this column. With 2 members per bin.
Going through column 39 and choosing a representative sample. Choosing 1000 bins for this column. With 4 members per bin.

ans =

       11617


ans =

        2050

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |       1 | Accept |      31.353 |      3.1716 |      4.3767 |      23.202 |           15 |    0.0011685 |
|    2 |       1 | Accept |      16.011 |      3.2173 |      4.3767 |      23.202 |           43 |      0.58905 |
|    3 |       1 | Accept |      82.108 |      3.3697 |      4.3767 |      23.202 |           72 |     0.035507 |
|    4 |       1 | Accept |      69.194 |      3.3578 |      4.3767 |      23.202 |           86 |    0.0020014 |
|    5 |       1 | Accept |      41.682 |      3.2784 |      4.3767 |      23.202 |           77 |     0.019256 |
|    6 |       1 | Accept |      57.592 |      3.1578 |      4.3767 |      23.202 |           72 |     0.009567 |
|    7 |       1 | Accept |      31.623 |      3.1657 |      4.3767 |      23.202 |           38 |    0.0096602 |
|    8 |       1 | Best   |      4.3767 |      3.0143 |      4.3767 |      23.202 |            7 |     0.035287 |
|    9 |       1 | Accept |      16.546 |      3.1963 |      4.3767 |      23.202 |           64 |     0.059271 |
|   10 |       1 | Accept |      78.161 |      3.2319 |      4.3767 |      23.202 |           75 |      0.16385 |
|   11 |       1 | Accept |      55.949 |      3.1527 |      4.3767 |      23.202 |           46 |      0.19826 |
|   12 |       1 | Accept |      27.908 |      3.0763 |      4.3767 |      23.202 |           16 |     0.011813 |
|   13 |       1 | Accept |      13.645 |       3.064 |      4.3767 |      23.202 |            6 |     0.094786 |
|   14 |       1 | Accept |      24.835 |      3.1218 |      4.3767 |      23.202 |           36 |     0.014186 |
|   15 |       1 | Accept |      65.709 |      3.2338 |      4.3767 |      23.202 |           83 |    0.0064574 |
|   16 |       1 | Accept |      37.819 |      3.1103 |      4.3767 |      23.202 |           31 |      0.67998 |
|   17 |      16 | Accept |      14.305 |     0.51566 |      4.3767 |       19.55 |            5 |    0.0010369 |
|   18 |       2 | Accept |      20.094 |     0.61297 |      4.3767 |      20.389 |           59 |      0.10477 |
|   19 |       2 | Accept |      26.213 |     0.73258 |      4.3767 |      20.389 |           78 |      0.45664 |
|   20 |       2 | Accept |      16.185 |     0.64117 |      4.3767 |      20.389 |           46 |    0.0030086 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       2 | Accept |      61.751 |     0.75682 |      4.3767 |      20.389 |           84 |      0.19968 |
|   22 |       2 | Accept |      15.384 |     0.66922 |      4.3767 |      20.389 |           58 |     0.014919 |
|   23 |       2 | Accept |      16.376 |     0.64692 |      4.3767 |      20.389 |           27 |     0.027439 |
|   24 |       2 | Accept |      54.406 |     0.59099 |      4.3767 |      20.389 |           42 |    0.0057405 |
|   25 |       2 | Accept |      43.897 |     0.74239 |      4.3767 |      20.389 |           93 |      0.23837 |
|   26 |       2 | Accept |      31.804 |     0.65673 |      4.3767 |      20.389 |           79 |      0.95983 |
|   27 |       2 | Accept |      48.695 |     0.78248 |      4.3767 |      20.389 |           94 |     0.033758 |
|   28 |       2 | Accept |      93.238 |     0.71207 |      4.3767 |      20.389 |           76 |     0.046003 |
|   29 |       2 | Accept |      34.892 |     0.64591 |      4.3767 |      20.389 |           63 |     0.031917 |
|   30 |       2 | Accept |      18.468 |      0.6653 |      4.3767 |      20.389 |           35 |     0.001364 |
|   31 |       2 | Accept |      30.458 |     0.71863 |      4.3767 |      20.389 |           63 |    0.0035224 |
|   32 |       2 | Accept |      12.946 |     0.72189 |      4.3767 |      20.389 |           72 |      0.12584 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 32
Total elapsed time: 16.6939 seconds.
Total objective function evaluation time: 61.7314

Best observed feasible point:
    hiddenLayerSize       lr   
    _______________    ________

           7           0.035287

Observed objective function value = 4.3767
Estimated objective function value = 20.3889
Function evaluation time = 3.0143

Best estimated feasible point (according to models):
    hiddenLayerSize       lr   
    _______________    ________

           7           0.035287

Estimated objective function value = 20.3889
Estimated function evaluation time = 1.4624


T =

  1x2 table

    hiddenLayerSize       lr   
    _______________    ________

           7           0.035287

Elapsed time is 23.075655 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      3.0056 |      180.52 |      3.0056 |      3.0056 |       40.509 |         none |     matern32 |   2.3205e+12 |        false |
|    2 |      16 | Best   |      2.7303 |      239.39 |      2.7303 |      2.8677 |       3.4983 |         none |  exponential |   1.9071e+13 |        false |
|    3 |      16 | Accept |      3.0015 |      268.84 |      2.7303 |       2.911 |       21.992 |     constant | squaredexpon |   1.6806e+12 |         true |
|    4 |      16 | Error  |         NaN |       423.3 |      2.7303 |       2.911 |     0.046279 |       linear |     matern32 |   1.3331e+11 |        false |
|    5 |      16 | Accept |      3.0004 |      496.67 |      2.7303 |      2.7304 |   0.00019304 |         none |     matern32 |   2.5679e+12 |         true |
|    6 |      16 | Accept |      2.7914 |      230.12 |      2.7303 |      2.7306 |       5.5099 |     constant |  exponential |      1.6e+12 |        false |
|    7 |      16 | Error  |         NaN |      518.86 |      2.7303 |      2.7306 |   0.00034153 |       linear |     matern32 |   4.4582e+12 |        false |
|    8 |      16 | Best   |      2.7054 |      221.45 |      2.7054 |      2.7195 |       3.3509 |         none |  exponential |   1.3621e+13 |        false |
|    9 |      16 | Accept |      6.5414 |      774.66 |      2.7054 |      2.7174 |        0.606 |       linear | rationalquad |   1.5521e+11 |        false |
|   10 |      16 | Accept |      9.3967 |      642.27 |      2.7054 |      2.7179 |     0.027368 | pureQuadrati |     matern52 |   3.0139e+11 |         true |
|   11 |      16 | Error  |         NaN |      348.18 |      2.7054 |      2.7179 |   0.00088465 |       linear |  exponential |   1.9197e+13 |        false |
|   12 |      16 | Error  |         NaN |      223.07 |      2.7054 |      2.7179 |   0.00023179 |         none |  exponential |   1.4962e+12 |        false |
|   13 |      16 | Error  |         NaN |      429.56 |      2.7054 |      2.7179 |    0.0012247 |         none |  exponential |   2.0523e+13 |        false |
|   14 |      16 | Accept |      3.0012 |      282.95 |      2.7054 |      2.7179 |       15.966 |     constant |     matern32 |    1.574e+12 |        false |
|   15 |      16 | Error  |         NaN |      607.47 |      2.7054 |      2.7179 |      0.24693 |         none |  exponential |   2.0736e+10 |        false |
|   16 |      16 | Accept |      3.0007 |      292.85 |      2.7054 |      2.7179 |       6.5008 |     constant |  exponential |   1.2434e+12 |         true |
|   17 |      16 | Best   |      1.0082 |      578.98 |      1.0082 |      1.0085 |    0.0033214 |         none |  exponential |   2.1356e+10 |         true |
|   18 |      16 | Accept |      3.0005 |      301.61 |      1.0082 |      1.0085 |       16.319 |     constant |     matern52 |   4.0669e+12 |        false |
|   19 |      16 | Accept |      3.0004 |      588.55 |      1.0082 |      1.0085 |   0.00025007 |     constant |     matern32 |   1.1884e+13 |         true |
|   20 |      16 | Accept |      3.0011 |      385.03 |      1.0082 |      1.0085 |       33.846 |     constant | rationalquad |   2.6268e+12 |         true |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      16 | Accept |      3.0004 |      573.54 |      1.0082 |      1.0085 |   0.00022955 |         none |     matern52 |   2.3015e+12 |         true |
|   22 |      16 | Accept |      9.2414 |      283.67 |      1.0082 |      1.0085 |       26.717 |       linear |  exponential |   2.8402e+10 |         true |
|   23 |      16 | Accept |           3 |      184.02 |      1.0082 |      1.0085 |       28.737 |         none |     matern52 |   2.9084e+12 |        false |
|   24 |      16 | Accept |      3.0008 |      309.28 |      1.0082 |      1.0085 |       3.1307 |     constant |     matern52 |   4.0413e+12 |         true |
|   25 |      16 | Accept |       3.001 |      684.01 |      1.0082 |      1.0085 |       32.815 |     constant | rationalquad |   3.3358e+12 |        false |
|   26 |      16 | Accept |      3.0007 |      655.48 |      1.0082 |      1.0085 |       39.676 |     constant | squaredexpon |   2.1095e+12 |        false |
|   27 |      16 | Accept |      3.0004 |      440.14 |      1.0082 |      1.0085 |       17.862 |         none | squaredexpon |   1.8329e+12 |         true |
|   28 |      16 | Accept |      3.0004 |      1132.6 |      1.0082 |      1.0085 |      0.11395 |         none | rationalquad |   2.5331e+12 |         true |
|   29 |      16 | Accept |      3.0005 |      401.36 |      1.0082 |      1.0085 |       27.337 |         none | squaredexpon |   1.5607e+12 |        false |
|   30 |      16 | Accept |      9.3667 |       651.3 |      1.0082 |      1.0085 |       16.994 |       linear | squaredexpon |   2.6678e+12 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 3494.0407 seconds.
Total objective function evaluation time: 13349.757

Best observed feasible point:
      Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    _________    _____________    ______________    ___________    ___________

    0.0033214        none          exponential      2.1356e+10        true    

Observed objective function value = 1.0082
Estimated objective function value = 1.0085
Function evaluation time = 578.983

Best estimated feasible point (according to models):
      Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    _________    _____________    ______________    ___________    ___________

    0.0033214        none          exponential      2.1356e+10        true    

Estimated objective function value = 1.0085
Estimated function evaluation time = 578.8886

Elapsed time is 3577.447218 seconds.
Take a copy of the best attributes
Now use these optimum settings to do an exact GPR fit
Elapsed time is 46.681672 seconds.
Train a hyper-parameter optimized Ensemble of Trees model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|    1 |      16 | Best   |      2.3054 |      6.9306 |      2.3054 |      2.3054 |          Bag |           19 |            - |         1479 |           13 |           12 |
|    2 |      16 | Accept |      3.4653 |      14.607 |      2.3054 |      2.8851 |      LSBoost |           19 |    0.0017096 |          131 |           13 |           17 |
|    3 |      13 | Best   |      1.5109 |      17.712 |      1.5109 |      1.5539 |          Bag |           12 |            - |          223 |           35 |           36 |
|    4 |      13 | Accept |      3.4624 |      16.126 |      1.5109 |      1.5539 |      LSBoost |           30 |    0.0010346 |           26 |          102 |            6 |
|    5 |      13 | Accept |      2.1652 |      16.264 |      1.5109 |      1.5539 |          Bag |           60 |            - |           30 |            2 |            6 |
|    6 |      13 | Accept |      1.6244 |      22.339 |      1.5109 |      1.5539 |          Bag |           19 |            - |            8 |           11 |           35 |
|    7 |      13 | Accept |      1.8462 |      23.671 |      1.5109 |      1.5114 |          Bag |           44 |            - |            2 |           34 |           10 |
|    8 |      14 | Best   |     0.69742 |      44.323 |     0.69742 |      0.6975 |      LSBoost |           33 |       0.2348 |           22 |          126 |           16 |
|    9 |      14 | Accept |      3.0004 |      5.7393 |     0.69742 |      0.6975 |          Bag |           41 |            - |         5590 |        10118 |           38 |
|   10 |      13 | Accept |       2.478 |      49.131 |     0.69742 |     0.69755 |          Bag |          330 |            - |         4149 |            7 |            9 |
|   11 |      13 | Accept |      1.2934 |      52.358 |     0.69742 |     0.69755 |      LSBoost |           14 |      0.10001 |            1 |         3447 |           34 |
|   12 |      13 | Accept |      1.8238 |      57.159 |     0.69742 |     0.69755 |          Bag |           63 |            - |          500 |         7739 |           35 |
|   13 |      11 | Accept |      1.2759 |      23.593 |     0.69742 |     0.69757 |          Bag |           14 |            - |          116 |           60 |           38 |
|   14 |      11 | Accept |      1.9848 |      19.463 |     0.69742 |     0.69757 |          Bag |           21 |            - |            1 |            4 |           38 |
|   15 |      11 | Accept |      3.0004 |      10.345 |     0.69742 |     0.69757 |      LSBoost |          116 |      0.96767 |         5615 |            8 |            2 |
|   16 |      13 | Accept |     0.77601 |      79.892 |     0.69742 |     0.69767 |      LSBoost |           30 |      0.48929 |            1 |          629 |           19 |
|   17 |      13 | Accept |      1.2202 |      81.001 |     0.69742 |     0.69767 |      LSBoost |          100 |      0.11167 |            2 |            4 |           36 |
|   18 |      13 | Accept |      2.2781 |      72.085 |     0.69742 |     0.69767 |          Bag |          366 |            - |            1 |           10 |            2 |
|   19 |      13 | Accept |      3.0004 |      11.211 |     0.69742 |     0.69767 |      LSBoost |          126 |       0.2962 |         5668 |          160 |           36 |
|   20 |      13 | Best   |     0.63749 |      61.478 |     0.63749 |     0.63784 |      LSBoost |           30 |      0.15886 |            1 |          256 |           32 |
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|   21 |      12 | Accept |      1.6582 |       11.21 |     0.63749 |      0.6378 |          Bag |           27 |            - |          187 |         4131 |            7 |
|   22 |      12 | Accept |      1.7735 |      18.427 |     0.63749 |      0.6378 |          Bag |           35 |            - |            1 |           10 |           15 |
|   23 |      11 | Accept |      1.0354 |      24.381 |     0.63749 |     0.63773 |          Bag |           19 |            - |            3 |           86 |           27 |
|   24 |      11 | Accept |      1.2726 |      3.8229 |     0.63749 |     0.63773 |      LSBoost |           15 |      0.23836 |            2 |          121 |            2 |
|   25 |      15 | Accept |     0.72526 |      33.797 |     0.63749 |     0.74854 |      LSBoost |           14 |      0.18661 |           22 |         2087 |           38 |
|   26 |      15 | Accept |     0.77788 |       30.41 |     0.63749 |     0.74854 |          Bag |           39 |            - |            6 |          959 |            7 |
|   27 |      11 | Accept |      1.6511 |      127.24 |     0.63749 |     0.79427 |          Bag |          215 |            - |          271 |           92 |           16 |
|   28 |      11 | Accept |      3.4589 |      8.4269 |     0.63749 |     0.79427 |      LSBoost |           41 |    0.0011443 |         2409 |           37 |           21 |
|   29 |      11 | Accept |      1.3202 |      8.7552 |     0.63749 |     0.79427 |          Bag |           11 |            - |           78 |           40 |           15 |
|   30 |      11 | Accept |      2.8234 |      9.7821 |     0.63749 |     0.79427 |      LSBoost |           19 |     0.022353 |          135 |          174 |            8 |
|   31 |      11 | Accept |      2.0615 |      3.5293 |     0.63749 |     0.79427 |      LSBoost |           14 |      0.93082 |         2134 |           10 |            8 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 31
Total elapsed time: 143.3383 seconds.
Total objective function evaluation time: 965.2065

Best observed feasible point:
    Method     NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    _______    _________________    _________    ___________    ____________    ____________________

    LSBoost           30             0.15886          1             256                  32         

Observed objective function value = 0.63749
Estimated objective function value = 0.79427
Function evaluation time = 61.4776

Best estimated feasible point (according to models):
    Method     NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    _______    _________________    _________    ___________    ____________    ____________________

    LSBoost           30             0.15886          1             256                  32         

Estimated objective function value = 0.79427
Estimated function evaluation time = 61.5142

Elapsed time is 150.089150 seconds.
Train the super learner model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |    0.026707 |      643.65 |    0.026707 |    0.026707 |       39.116 |       linear |     matern52 |   1.6491e+13 |         true |
|    2 |      16 | Best   |  4.6724e-05 |      646.44 |  4.6724e-05 |   0.0011068 |    0.0076303 |       linear |  exponential |   3.5857e+11 |        false |
|    3 |      16 | Accept |      3.0003 |      653.91 |  4.6724e-05 |    0.061552 |       36.108 |     constant | squaredexpon |   4.2579e+12 |         true |
|    4 |      16 | Best   |  4.5669e-05 |      699.36 |  4.5669e-05 |  0.00015344 |        5.531 |       linear |     matern52 |   8.1061e+12 |        false |
|    5 |      16 | Best   |  4.5624e-05 |      936.43 |  4.5624e-05 |   0.0013355 |     0.070296 |       linear | rationalquad |   2.5509e+11 |        false |
|    6 |      16 | Error  |         NaN |      1029.4 |  4.5624e-05 |   0.0013355 |    0.0010366 |         none |  exponential |   1.6225e+13 |         true |
|    7 |      16 | Error  |         NaN |      1107.7 |  4.5624e-05 |   0.0013355 |    0.0055307 | pureQuadrati |     matern32 |   2.4923e+12 |        false |
|    8 |      16 | Best   |  4.5583e-05 |      685.82 |  4.5583e-05 |  7.7737e-05 |     0.004874 |       linear |  exponential |   3.6803e+12 |        false |
|    9 |      16 | Best   |  4.5564e-05 |      684.93 |  4.5564e-05 |  6.4016e-05 |        2.165 |       linear |  exponential |   2.3554e+11 |        false |
|   10 |      16 | Accept |      2.9954 |      464.36 |  4.5564e-05 |  7.8281e-05 |       6.1878 |         none |     matern52 |   9.0691e+12 |        false |
|   11 |      16 | Accept |  4.5575e-05 |      708.25 |  4.5564e-05 |  7.3311e-05 |      0.25973 |       linear |     matern32 |    1.753e+12 |        false |
|   12 |      16 | Accept |      3.0006 |      1863.2 |  4.5564e-05 |  8.3433e-05 |    0.0012861 |     constant | rationalquad |    5.881e+12 |         true |
|   13 |      16 | Accept |   0.0049293 |        1868 |  4.5564e-05 |  7.8832e-05 |    0.0073091 |       linear | rationalquad |    6.164e+12 |         true |
|   14 |      16 | Accept |  4.5691e-05 |      654.53 |  4.5564e-05 |  7.5304e-05 |   0.00013184 |       linear | squaredexpon |   1.5678e+12 |        false |
|   15 |      16 | Accept |   0.0087334 |       620.1 |  4.5564e-05 |  7.2543e-05 |      0.58446 |       linear |     matern32 |   2.9903e+12 |         true |
|   16 |      16 | Accept |    0.019632 |      1424.8 |  4.5564e-05 |  7.0984e-05 |   0.00010141 |       linear |     matern52 |   2.7799e+10 |         true |
|   17 |      16 | Accept |    0.029006 |      674.44 |  4.5564e-05 |  6.8986e-05 |       8.4771 | pureQuadrati |     matern52 |   2.3058e+11 |         true |
|   18 |      16 | Accept |    0.028187 |      682.22 |  4.5564e-05 |  6.7302e-05 |      0.15516 |       linear |  exponential |   8.7077e+11 |         true |
|   19 |      16 | Error  |         NaN |      1803.7 |  4.5564e-05 |  6.7302e-05 |     0.066567 | pureQuadrati | rationalquad |    3.095e+11 |        false |
|   20 |      16 | Error  |         NaN |      1952.1 |  4.5564e-05 |  6.7302e-05 |      0.10559 |         none | rationalquad |   9.2939e+12 |        false |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 3311.6085 seconds.
Total objective function evaluation time: 19803.2266

Best observed feasible point:
    Sigma    BasisFunction    KernelFunction    KernelScale    Standardize
    _____    _____________    ______________    ___________    ___________

    2.165       linear         exponential      2.3554e+11        false   

Observed objective function value = 4.5564e-05
Estimated objective function value = 6.7302e-05
Function evaluation time = 684.9321

Best estimated feasible point (according to models):
      Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    _________    _____________    ______________    ___________    ___________

    0.0076303       linear         exponential      3.5857e+11        false   

Estimated objective function value = 6.7302e-05
Estimated function evaluation time = 795.0609

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 90)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 3753.159012 seconds.
Train the super learner error model for regression
Copying objective function to workers...
Done copying objective function to workers.
