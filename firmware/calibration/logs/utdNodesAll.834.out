Running calibration scripts for UTD Node: 9
Running on host: compute-1-1-35

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
              R2020a Update 1 (9.8.0.1359463) 64-bit (glnxa64)
                               April 9, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 


    "---------------------MINTS---------------------"

30-Dec-2020 11:51:01

mintsDefinitions = 

  struct with fields:

                dataFolder: '/home/lhw150030/mintsData'
               poolWorkers: 16
                  timeSpan: 30
                  airmarID: '001e0610c0e4'
             binsPerColumn: 200
              numberPerBin: 3
                    pValid: 0.1500
                   nodeIDs: {1x16 cell}
               inputStack1: {1x9 cell}
         mintsInputsStack1: {1x35 cell}
    mintsInputLabelsStack1: {1x35 cell}
               inputStack2: {1x11 cell}
         mintsInputsStack2: {1x35 cell}
    mintsInputLabelsStack2: {1x35 cell}
               inputStack3: {1x10 cell}
         mintsInputsStack3: {1x38 cell}
    mintsInputLabelsStack3: {1x38 cell}
              mintsTargets: {1x10 cell}
         mintsTargetLabels: {1x10 cell}
                     units: {1x10 cell}
               instruments: {1x10 cell}

Starting parallel pool (parpool) using the 'local' profile ...
Connected to the parallel pool (number of workers: 16).

ans = 

 ProcessPool with properties: 

            Connected: true
           NumWorkers: 16
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


airmarFolder = 

    "/home/lhw150030/mintsData/referenceMats/airmar"

UTD_Rsl_All_2020_12_30_11_53_14


UTD_Rsl_All_Daily


Super Learner All Inputs




    "Data Folder Located @:/home/lhw150030/mintsData"

    "Raw Data Located @: /home/lhw150030/mintsData"

    "Raw DotMat Data Located @ :/home/lhw150030/mintsData/rawMats"

    "UTD Nodes DotMat Data Located @ :/home/lhw150030/mintsData/rawMats/UTDNodes"

    "Reference Data Located @: /home/lhw150030/mintsData/reference"

    "Reference DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats"

    "Palas Raw Data Located @ :/home/lhw150030/mintsData/reference/palasStream"

    "Palas DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats/palas"

    "Car GPS Files Located @ :/home/lhw150030/mintsData/referenceMats/carMintsGPS"

    "Loading Palas Files"

    "Loading GPS Files"

    "Loading Airmar Files"

    "Aligning GPS data with Palas Data"

    "WSTC Palas Data"

    "Palas With Airmar"

    "Analysis"

    "Save merged data for calibration: 001e06305a6b"



    "Creating Training Data Sets for Node: 001e06305a6b"



    "Gainin Data set for Node 001e06305a6b with target output pm1_palas @ 30-Dec-2020 11:53:24"

Going through column 1 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 2 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 3 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 4 and choosing a representative sample. Choosing 73 bins for this column. With 3 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 3 members per bin.
Going through column 6 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 7 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 8 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 9 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 10 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 11 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 12 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 13 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 14 and choosing a representative sample. Choosing 76 bins for this column. With 3 members per bin.
Going through column 15 and choosing a representative sample. Choosing 57 bins for this column. With 3 members per bin.
Going through column 16 and choosing a representative sample. Choosing 26 bins for this column. With 3 members per bin.
Going through column 17 and choosing a representative sample. Choosing 18 bins for this column. With 3 members per bin.
Going through column 18 and choosing a representative sample. Choosing 14 bins for this column. With 3 members per bin.
Going through column 19 and choosing a representative sample. Choosing 9 bins for this column. With 3 members per bin.
Going through column 20 and choosing a representative sample. Choosing 8 bins for this column. With 3 members per bin.
Going through column 21 and choosing a representative sample. Choosing 6 bins for this column. With 3 members per bin.
Going through column 22 and choosing a representative sample. Choosing 3 bins for this column. With 3 members per bin.
Going through column 23 and choosing a representative sample. Choosing 2 bins for this column. With 3 members per bin.
Going through column 24 and choosing a representative sample. Choosing 2 bins for this column. With 3 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 3 members per bin.
Going through column 26 and choosing a representative sample. Choosing 2 bins for this column. With 3 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 3 members per bin.
Going through column 28 and choosing a representative sample. Choosing 123 bins for this column. With 3 members per bin.
Going through column 29 and choosing a representative sample. Choosing 190 bins for this column. With 3 members per bin.
Going through column 30 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 31 and choosing a representative sample. Choosing 124 bins for this column. With 3 members per bin.
Going through column 32 and choosing a representative sample. Choosing 2 bins for this column. With 3 members per bin.
Going through column 33 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 34 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 35 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 36 and choosing a representative sample. Choosing 400 bins for this column. With 6 members per bin.

ans =

        5443


ans =

   960

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |      12 | Accept |      38.772 |      7.7219 |      16.081 |      16.083 |           20 |     0.011785 |
|    2 |      12 | Best   |      16.081 |      7.8691 |      16.081 |      16.083 |           74 |    0.0020999 |
|    3 |      12 | Accept |      20.594 |      7.8034 |      16.081 |      16.083 |           86 |      0.00123 |
|    4 |      12 | Accept |      27.423 |      8.1256 |      16.081 |      16.083 |           34 |    0.0030699 |
|    5 |      12 | Accept |      71.777 |      8.0532 |      16.081 |      16.083 |           61 |    0.0069915 |
|    6 |       5 | Best   |      7.3264 |      16.316 |      7.3264 |      33.136 |           32 |      0.66443 |
|    7 |       5 | Accept |      36.012 |      11.933 |      7.3264 |      33.136 |           93 |     0.073475 |
|    8 |       5 | Accept |      32.967 |      8.7417 |      7.3264 |      33.136 |           43 |    0.0078924 |
|    9 |       5 | Accept |      33.766 |      9.2225 |      7.3264 |      33.136 |           93 |      0.13832 |
|   10 |       5 | Accept |      38.217 |      15.036 |      7.3264 |      33.136 |           70 |    0.0043055 |
|   11 |       5 | Accept |      56.436 |      11.811 |      7.3264 |      33.136 |           42 |    0.0030541 |
|   12 |       5 | Accept |      27.803 |       12.28 |      7.3264 |      33.136 |           37 |    0.0015359 |
|   13 |       5 | Accept |      23.676 |      15.818 |      7.3264 |      33.136 |           90 |     0.007788 |
|   14 |      13 | Accept |      87.498 |      14.693 |      7.3264 |      32.978 |           77 |    0.0014413 |
|   15 |      13 | Accept |      12.514 |      14.288 |      7.3264 |      32.978 |           46 |      0.17527 |
|   16 |      13 | Accept |      20.232 |      14.386 |      7.3264 |      32.978 |            7 |     0.003662 |
|   17 |      13 | Accept |      9.5399 |     0.52448 |      7.3264 |      32.978 |           12 |     0.024936 |
|   18 |       2 | Accept |      53.949 |     0.83745 |      7.3264 |      7.3288 |           26 |      0.97349 |
|   19 |       2 | Accept |      61.809 |      1.0416 |      7.3264 |      7.3288 |           50 |      0.52622 |
|   20 |       2 | Accept |      36.367 |      1.9307 |      7.3264 |      7.3288 |           29 |    0.0019537 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       2 | Accept |      21.715 |      1.2624 |      7.3264 |      7.3288 |           35 |      0.84776 |
|   22 |       2 | Accept |      13.919 |     0.88083 |      7.3264 |      7.3288 |           41 |      0.10374 |
|   23 |       2 | Accept |      30.451 |     0.87616 |      7.3264 |      7.3288 |           24 |    0.0046264 |
|   24 |       2 | Accept |      12.124 |      2.4162 |      7.3264 |      7.3288 |           85 |    0.0019579 |
|   25 |       2 | Accept |      14.531 |      2.4609 |      7.3264 |      7.3288 |           11 |      0.20506 |
|   26 |       2 | Accept |      41.486 |      1.1043 |      7.3264 |      7.3288 |           59 |      0.27454 |
|   27 |       2 | Accept |      58.522 |      2.3933 |      7.3264 |      7.3288 |           59 |     0.077849 |
|   28 |       2 | Accept |      18.227 |      2.4689 |      7.3264 |      7.3288 |           82 |      0.14993 |
|   29 |       2 | Accept |      13.536 |      1.1157 |      7.3264 |      7.3288 |           17 |      0.12031 |
|   30 |      16 | Accept |      25.421 |     0.30807 |      7.3264 |      7.3288 |          100 |    0.0010004 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 35.1445 seconds.
Total objective function evaluation time: 203.7184

Best observed feasible point:
    hiddenLayerSize      lr   
    _______________    _______

          32           0.66443

Observed objective function value = 7.3264
Estimated objective function value = 7.3288
Function evaluation time = 16.3157

Best estimated feasible point (according to models):
    hiddenLayerSize      lr   
    _______________    _______

          32           0.66443

Estimated objective function value = 7.3288
Estimated function evaluation time = 3.9099


T =

  1x2 table

    hiddenLayerSize      lr   
    _______________    _______

          32           0.66443

Elapsed time is 53.060568 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      3.6763 |      1332.7 |      3.6763 |      3.6763 |       47.366 |         none |     matern52 |   2.6192e+11 |         true |
|    2 |      16 | Accept |      10.245 |      2675.2 |      3.6763 |      3.9374 |   0.00043945 | pureQuadrati |  exponential |   8.6294e+11 |         true |
|    3 |      16 | Accept |      9.6505 |      2553.9 |      3.6763 |      3.7032 |       24.881 | pureQuadrati |  exponential |   4.0213e+11 |         true |
|    4 |      16 | Best   |      3.6761 |      1816.3 |      3.6761 |      3.6763 |      0.69905 |         none |     matern52 |   5.5062e+11 |         true |
|    5 |      16 | Accept |      3.6763 |      1473.8 |      3.6761 |      3.6825 |       48.938 |         none |     matern52 |   2.0429e+13 |         true |
|    6 |      16 | Accept |      5.1687 |      6448.7 |      3.6761 |      3.6764 |       0.1939 |     constant |     matern52 |   8.5933e+11 |        false |
|    7 |      16 | Accept |      3.6761 |      2468.2 |      3.6761 |      3.6763 |       5.2374 |         none | rationalquad |   3.0386e+12 |         true |
|    8 |      16 | Best   |      3.3406 |      2626.5 |      3.3406 |       3.358 |       29.745 |       linear |     matern52 |    1.361e+12 |         true |
|    9 |      16 | Accept |      3.6765 |        2470 |      3.3406 |      3.3408 |       1.9975 |     constant |     matern52 |    1.584e+11 |         true |
|   10 |      16 | Accept |      8.0442 |      9582.4 |      3.3406 |      3.3609 |    0.0015917 |       linear | rationalquad |   1.7901e+12 |        false |
|   11 |      16 | Accept |      3.6216 |      2684.5 |      3.3406 |      3.3409 |       2.9507 |         none |     matern52 |    7.295e+11 |        false |
|   12 |      16 | Accept |      3.4494 |      3141.3 |      3.3406 |      3.3408 |     0.020313 |       linear | rationalquad |   1.9292e+12 |         true |
|   13 |      16 | Accept |      10.049 |        2678 |      3.3406 |      3.3409 |      0.17851 | pureQuadrati |     matern52 |    1.389e+12 |         true |
|   14 |      16 | Accept |      3.6763 |      3607.6 |      3.3406 |      3.3409 |       2.9918 |     constant | rationalquad |   1.4674e+12 |         true |
|   15 |      16 | Best   |      3.1697 |      2636.3 |      3.1697 |      3.1699 |       59.222 |       linear |     matern32 |   2.8489e+10 |         true |
|   16 |      16 | Accept |      3.6762 |       13453 |      3.1697 |      3.1699 |       31.209 |         none |     matern52 |   2.1101e+10 |         true |
|   17 |      16 | Accept |      3.6761 |       13885 |      3.1697 |      3.1831 |       8.7509 |         none |  exponential |    4.873e+11 |         true |
|   18 |      16 | Error  |         NaN |       14083 |      3.1697 |      3.1831 |      0.01471 | pureQuadrati |     matern32 |   3.8309e+10 |        false |
|   19 |      16 | Accept |      9.8139 |      2453.4 |      3.1697 |      3.1699 |     0.021586 |       linear | squaredexpon |   1.4645e+11 |         true |
|   20 |      15 | Accept |      8.9717 |      3018.5 |      3.1697 |      3.1699 |     0.024901 | pureQuadrati | rationalquad |   9.1576e+11 |         true |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      15 | Accept |      3.6761 |      1671.7 |      3.1697 |      3.1699 |       20.965 |         none |     matern32 |   4.4912e+12 |         true |
|   22 |      16 | Accept |      3.6135 |      1255.1 |      3.1697 |      3.1699 |       8.8131 |         none |  exponential |   2.9255e+11 |        false |
|   23 |      16 | Accept |      3.6761 |        2024 |      3.1697 |      3.1699 |       1.4052 |     constant | squaredexpon |   3.6336e+12 |         true |
|   24 |      16 | Accept |      3.6771 |      2532.3 |      3.1697 |      3.1699 |       8.8932 |     constant |  exponential |   2.0059e+13 |         true |
|   25 |      16 | Accept |      3.6191 |      1219.5 |      3.1697 |      3.1832 |        9.019 |     constant |  exponential |   6.0284e+11 |        false |
|   26 |      16 | Accept |      3.2021 |      2563.9 |      3.1697 |      3.1699 |       61.573 |       linear |  exponential |   1.2484e+13 |        false |
|   27 |      16 | Accept |      3.6261 |       10620 |      3.1697 |      3.1699 |       2.4436 |     constant | rationalquad |   1.1351e+12 |        false |
|   28 |      16 | Error  |         NaN |      5535.7 |      3.1697 |      3.1699 |     0.002867 |     constant |     matern32 |   5.6412e+11 |        false |
|   29 |      16 | Accept |      3.6223 |      1799.6 |      3.1697 |      3.1698 |       2.6127 |     constant | squaredexpon |   5.1204e+11 |        false |
|   30 |      16 | Accept |      3.6326 |      1567.3 |      3.1697 |      3.1698 |       4.4088 |         none | squaredexpon |    1.492e+12 |        false |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 27754.5099 seconds.
Total objective function evaluation time: 125876.1761

Best observed feasible point:
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    59.222       linear           matern32       2.8489e+10        true    

Observed objective function value = 3.1697
Estimated objective function value = 3.1698
Function evaluation time = 2636.2662

Best estimated feasible point (according to models):
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    59.222       linear           matern32       2.8489e+10        true    

Estimated objective function value = 3.1698
Estimated function evaluation time = 2878.904

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 29)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 27902.154066 seconds.
Take a copy of the best attributes
Now use these optimum settings to do an exact GPR fit
[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In fitrsuperOptimized (line 51)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 49.258330 seconds.
Train a hyper-parameter optimized Ensemble of Trees model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|    1 |      16 | Best   |      2.7734 |      11.421 |      2.7734 |      2.7734 |          Bag |           13 |            - |          494 |            2 |           32 |
|    2 |      16 | Best   |      2.7101 |      11.862 |      2.7101 |      2.7135 |          Bag |           18 |            - |           96 |          915 |            6 |
|    3 |      15 | Accept |      2.7825 |      36.648 |      2.3128 |      2.3128 |          Bag |           54 |            - |          221 |            7 |           22 |
|    4 |      15 | Best   |      2.3128 |      30.731 |      2.3128 |      2.3128 |      LSBoost |           66 |      0.21535 |           42 |            5 |            6 |
|    5 |      14 | Accept |       3.467 |       98.76 |      2.3128 |      2.3128 |          Bag |           11 |            - |         1744 |          197 |            4 |
|    6 |      14 | Accept |      2.8359 |      21.409 |      2.3128 |      2.3128 |          Bag |           41 |            - |          215 |         1069 |            7 |
|    7 |      10 | Accept |      3.4319 |      155.79 |      1.3071 |      1.3095 |      LSBoost |          327 |    0.0022817 |           97 |         2059 |            6 |
|    8 |      10 | Best   |      1.3071 |      124.23 |      1.3071 |      1.3095 |          Bag |           57 |            - |            2 |         1330 |           21 |
|    9 |      10 | Accept |      3.3691 |      150.61 |      1.3071 |      1.3095 |      LSBoost |          488 |     0.061666 |          309 |          874 |            3 |
|   10 |      10 | Accept |      2.1086 |      123.86 |      1.3071 |      1.3095 |          Bag |           13 |            - |           29 |           13 |           30 |
|   11 |      10 | Accept |      1.3091 |      39.899 |      1.3071 |      1.3095 |      LSBoost |           12 |      0.18776 |            1 |         4495 |           33 |
|   12 |      16 | Accept |      3.4021 |      10.952 |      1.3071 |      1.3072 |      LSBoost |           38 |      0.36733 |           15 |           28 |            2 |
|   13 |      12 | Best   |      1.2974 |      229.72 |      1.2974 |      1.2975 |      LSBoost |           83 |     0.063786 |           66 |         4423 |           30 |
|   14 |      12 | Accept |      2.4465 |      241.74 |      1.2974 |      1.2975 |          Bag |           44 |            - |            6 |           12 |           22 |
|   15 |      12 | Accept |      2.4937 |      216.78 |      1.2974 |      1.2975 |      LSBoost |           24 |     0.047618 |           30 |         1999 |           31 |
|   16 |      12 | Accept |      2.8118 |      15.922 |      1.2974 |      1.2975 |          Bag |           23 |            - |          159 |         3475 |           10 |
|   17 |      12 | Accept |      4.3961 |      16.976 |      1.2974 |      1.2975 |      LSBoost |           21 |    0.0014356 |           46 |            7 |           25 |
|   18 |      10 | Accept |      2.5003 |      291.73 |      1.2974 |      1.2975 |      LSBoost |          379 |    0.0044728 |           24 |           10 |           22 |
|   19 |      10 | Accept |      3.2872 |      69.831 |      1.2974 |      1.2975 |          Bag |           17 |            - |           30 |          144 |            3 |
|   20 |      10 | Accept |      3.6758 |      32.134 |      1.2974 |      1.2975 |      LSBoost |          128 |      0.24033 |         2712 |            1 |           17 |
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|   21 |      16 | Accept |      3.1896 |      124.82 |      1.2974 |      1.2975 |          Bag |          295 |            - |          728 |            5 |           22 |
|   22 |      12 | Accept |      2.2778 |      40.662 |      1.0492 |      1.1787 |      LSBoost |           59 |     0.042409 |          420 |         5382 |           33 |
|   23 |      12 | Accept |      2.9066 |       19.98 |      1.0492 |      1.1787 |          Bag |           10 |            - |          940 |           11 |           35 |
|   24 |      12 | Best   |      1.0492 |      190.87 |      1.0492 |      1.1787 |          Bag |           76 |            - |            1 |         4913 |           35 |
|   25 |      12 | Accept |      3.2851 |      34.683 |      1.0492 |      1.1787 |          Bag |           94 |            - |           56 |            3 |            4 |
|   26 |      12 | Accept |      2.1095 |      10.748 |      1.0492 |      1.1787 |          Bag |           19 |            - |           18 |           63 |            6 |
|   27 |      11 | Accept |      2.8007 |      56.902 |      1.0492 |      1.1792 |          Bag |          132 |            - |          128 |         1074 |            9 |
|   28 |      11 | Accept |      2.6004 |      10.751 |      1.0492 |      1.1792 |      LSBoost |           29 |      0.15993 |         1233 |         5427 |           30 |
|   29 |      15 | Accept |      3.7059 |      89.825 |      1.0492 |      1.2262 |      LSBoost |          106 |    0.0041831 |           66 |          190 |           17 |
|   30 |      15 | Accept |      3.6645 |      97.103 |      1.0492 |      1.2262 |          Bag |           34 |            - |          495 |            1 |            3 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 487.6078 seconds.
Total objective function evaluation time: 2607.3545

Best observed feasible point:
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             76               NaN            1             4913                 35         

Observed objective function value = 1.0492
Estimated objective function value = 1.2262
Function evaluation time = 190.875

Best estimated feasible point (according to models):
    Method    NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    ______    _________________    _________    ___________    ____________    ____________________

     Bag             76               NaN            1             4913                 35         

Estimated objective function value = 1.2262
Estimated function evaluation time = 52.5634

Elapsed time is 510.761194 seconds.
Train the super learner model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      3.6769 |      3117.9 |      3.6769 |      3.6769 |    0.0013684 |     constant |     matern52 |   4.1918e+11 |         true |
|    2 |      16 | Error  |         NaN |      3180.4 |         NaN |      3.6769 |    0.0028892 |         none |  exponential |    3.283e+10 |        false |
|    3 |      16 | Error  |         NaN |      6647.3 |         NaN |      3.6769 |      0.79415 |         none |     matern52 |   1.6055e+11 |        false |
|    4 |      16 | Error  |         NaN |      6154.6 |      3.6769 |      3.6769 |   0.00013237 |         none |     matern52 |   3.8729e+11 |        false |
|    5 |      16 | Best   |       3.676 |      6965.3 |       3.676 |      3.6764 |    0.0020243 |         none |     matern52 |   1.3294e+11 |         true |
|    6 |      16 | Accept |       3.676 |      1694.2 |       3.676 |       3.676 |       7.1537 |         none |     matern52 |   1.7644e+11 |         true |
|    7 |      16 | Error  |         NaN |      5875.7 |       3.676 |       3.676 |    0.0011232 |     constant |     matern32 |   3.2199e+11 |        false |
|    8 |      16 | Best   |  4.3562e-06 |      2296.5 |  4.3562e-06 |  0.00028007 |       1.6012 |       linear |     matern52 |   2.0635e+10 |         true |
|    9 |      16 | Accept |  4.4367e-06 |      2890.5 |  4.3562e-06 |  0.00022492 |       7.1674 |       linear |     matern32 |   2.2251e+10 |         true |
|   10 |      16 | Accept |  4.9695e-06 |      9665.1 |  4.3562e-06 |  0.00018813 |     0.039801 |       linear | squaredexpon |   1.6266e+11 |        false |
|   11 |      16 | Accept |  3.6272e-05 |      2957.6 |  4.3562e-06 |  0.00016181 |       17.003 | pureQuadrati |     matern32 |   2.4962e+10 |         true |
|   12 |      16 | Accept |      3.6196 |      1419.4 |  4.3562e-06 |  0.00018755 |        9.442 | pureQuadrati |     matern32 |   9.6678e+10 |        false |
|   13 |      16 | Accept |       3.676 |      9677.1 |  4.3562e-06 |  0.00020797 |     0.040391 |         none | rationalquad |   2.0677e+10 |         true |
|   14 |      16 | Best   |  4.3402e-06 |      4293.5 |  4.3402e-06 |  0.00018761 |        1.376 |       linear | rationalquad |   2.1588e+10 |         true |
|   15 |      16 | Accept |  0.00039541 |       24827 |  4.3402e-06 |    0.000171 |        8.762 | pureQuadrati |     matern52 |   1.9032e+13 |         true |
|   16 |      16 | Accept |  5.9149e-06 |      2905.3 |  4.3402e-06 |  0.00015703 |      0.05159 |       linear |  exponential |   2.4749e+10 |         true |
|   17 |      16 | Accept |  9.0544e-06 |      2732.1 |  4.3402e-06 |  0.00014532 |       56.906 | pureQuadrati |  exponential |   2.3366e+10 |         true |
|   18 |      16 | Accept |  0.00010615 |      2755.2 |  4.3402e-06 |  0.00013528 |     0.012672 |       linear | squaredexpon |   6.0894e+10 |         true |
|   19 |      16 | Accept |      3.6265 |      2979.2 |  4.3402e-06 |  0.00015075 |       10.133 | pureQuadrati | squaredexpon |   1.6332e+11 |        false |
|   20 |      16 | Accept |  3.9913e-05 |      2985.7 |  4.3402e-06 |  0.00014158 |      0.13788 | pureQuadrati | squaredexpon |   6.1443e+10 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 30819.8639 seconds.
Total objective function evaluation time: 106020.2645

Best observed feasible point:
    Sigma    BasisFunction     KernelFunction      KernelScale    Standardize
    _____    _____________    _________________    ___________    ___________

    1.376       linear        rationalquadratic    2.1588e+10        true    

Observed objective function value = 4.3402e-06
Estimated objective function value = 0.00014179
Function evaluation time = 4293.5011

Best estimated feasible point (according to models):
    Sigma     BasisFunction    KernelFunction    KernelScale    Standardize
    ______    _____________    ______________    ___________    ___________

    7.1674       linear           matern32       2.2251e+10        true    

Estimated objective function value = 0.00014158
Estimated function evaluation time = 3812.0542

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 90)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 30914.659933 seconds.
Train the super learner error model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |  0.00072181 |      2760.4 |  0.00072181 |  0.00072181 |     0.026227 |     constant |     matern52 |   1.5623e+11 |        false |
|    2 |      16 | Best   |  0.00072132 |      5514.5 |  0.00072132 |  0.00072144 |     0.029245 |     constant |  exponential |   4.3166e+10 |         true |
|    3 |      16 | Best   |  4.3981e-06 |      5546.5 |  4.3981e-06 |   9.371e-05 |   0.00010732 |       linear |  exponential |   5.0295e+11 |         true |
|    4 |      16 | Accept |    0.025147 |      5869.9 |  4.3981e-06 |   0.0063967 |   0.00011546 | pureQuadrati |     matern32 |   1.4427e+12 |         true |
|    5 |      16 | Best   |  4.3168e-06 |        5516 |  4.3168e-06 |  4.7154e-06 |   0.00030456 |       linear |  exponential |   3.4694e+11 |         true |
|    6 |      16 | Accept |  1.2288e-05 |      5651.9 |  4.3168e-06 |   7.201e-06 |     0.000122 |       linear |  exponential |   1.5247e+13 |         true |
|    7 |      16 | Accept |  5.9203e-06 |        6322 |  4.3168e-06 |  7.5636e-06 |   0.00026012 |     constant |  exponential |   1.0257e+12 |         true |
|    8 |      16 | Error  |         NaN |      62.031 |  4.3168e-06 |  7.5636e-06 |   0.00048845 |       linear |  exponential |   1.9018e+11 |        false |
|    9 |      16 | Error  |         NaN |      841.97 |  4.3168e-06 |  7.5636e-06 |   0.00010009 |     constant |  exponential |    3.243e+11 |        false |
|   10 |      16 | Accept |  0.00072143 |      5547.2 |  4.3168e-06 |  7.5673e-06 |   0.00010151 |     constant |     matern32 |   6.1207e+10 |         true |
|   11 |      16 | Accept |  0.00060604 |       19695 |  4.3168e-06 |  7.5743e-06 |     0.049119 | pureQuadrati | squaredexpon |   2.7746e+11 |         true |
|   12 |      16 | Accept |  0.00072263 |       22837 |  4.3168e-06 |  7.5834e-06 |      0.15657 | pureQuadrati |  exponential |   1.6933e+13 |        false |
|   13 |      16 | Best   |  4.3141e-06 |       23258 |  4.3141e-06 |  7.5901e-06 |     0.069669 |       linear |     matern52 |   3.7696e+11 |         true |
|   14 |      16 | Accept |  0.00072163 |      5477.6 |  4.3141e-06 |  7.5997e-06 |    0.0016363 |     constant |     matern52 |   1.7289e+11 |         true |
|   15 |      16 | Accept |  0.00072263 |       23494 |  4.3141e-06 |  7.6088e-06 |      0.21034 |         none |  exponential |   5.3057e+12 |         true |
|   16 |      16 | Accept |  0.00072263 |      2748.3 |  4.3141e-06 |  7.6175e-06 |     0.065004 |         none |     matern52 |   1.3973e+12 |         true |
|   17 |      16 | Accept |  0.00072147 |      1724.9 |  4.3141e-06 |  7.6256e-06 |     0.039141 |         none |     matern52 |   1.9007e+11 |        false |
|   18 |      16 | Accept |  0.00072141 |       28325 |  4.3141e-06 |  7.6332e-06 |      0.01521 |     constant | rationalquad |   3.7989e+11 |        false |
|   19 |      16 | Accept |   0.0001829 |      3347.6 |  4.3141e-06 |  7.6394e-06 |     0.049615 | pureQuadrati | rationalquad |   1.0796e+12 |         true |
|   20 |      16 | Accept |   0.0007216 |      9320.6 |  4.3141e-06 |  7.6461e-06 |    0.0050957 |     constant | rationalquad |   4.5455e+11 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 41411.5983 seconds.
Total objective function evaluation time: 183860.2305

Best observed feasible point:
     Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    ________    _____________    ______________    ___________    ___________

    0.069669       linear           matern52       3.7696e+11        true    

Observed objective function value = 4.3141e-06
Estimated objective function value = 4.5105e-06
Function evaluation time = 23257.7541

Best estimated feasible point (according to models):
     Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    ________    _____________    ______________    ___________    ___________

    0.000122       linear         exponential      1.5247e+13        true    

Estimated objective function value = 7.6461e-06
Estimated function evaluation time = 5632.8317

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 119)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 41575.230715 seconds.
Elapsed time is 41575.241731 seconds.
Use the hyper-parameter optimized NN model for regression
Elapsed time is 0.360406 seconds.
Use the hyper-parameter optimized GPR model for regression
Elapsed time is 1.702123 seconds.
Use the hyper-parameter optimized Ensemble of Trees model for regression
Elapsed time is 0.348903 seconds.
Use the super learner model for regression
Elapsed time is 1.605016 seconds.
Use the error estimate to update the Super Learner Estimate
Elapsed time is 1.595770 seconds.
Use the hyper-parameter optimized NN model for regression
Elapsed time is 0.096663 seconds.
Use the hyper-parameter optimized GPR model for regression
Elapsed time is 0.156448 seconds.
Use the hyper-parameter optimized Ensemble of Trees model for regression
Elapsed time is 0.225487 seconds.
Use the super learner model for regression
Elapsed time is 0.167913 seconds.
Use the error estimate to update the Super Learner Estimate
Elapsed time is 0.141062 seconds.



combinedFigDaily = 

    "/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e06305a6b/UTD_Rsl_All_Daily_001e06305a6b_pm1_palas.png"


combinedFig = 

    "/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e06305a6b/UTD_Rsl_All_2020_12_30_11_53_14/UTD_Rsl_All_2020_12_30_11_53_14_001e06305a6b_pm1_palas.png"

    "Creating Folder @: '/home/lhw150030/mintsData/visualAnalysis/UTDNodes/001e06305a6b/UTD_Rsl_All_2020_12_30_11_53_14'"

The identifier was:
MATLAB:license:checkouterrorThere was an error! The message was:
License checkout failed.
License Manager Error -15
Unable to connect to the license server. 
Check that the network license manager has been started, and that the client machine can communicate with the license server.

Troubleshoot this issue by visiting: 
https://www.mathworks.com/support/lme/R2020a/15

Diagnostic Information:
Feature: Curve_Fitting_Toolbox 
License path: /home/lhw150030/.matlab/R2020a_licenses:/opt/ohpc/pub/unpackaged/apps/matlab/R2020a/licenses/license.dat:/opt/ohpc/pub/unpackaged/apps/matlab/R2020a/licenses/network.lic 
Licensing error: -15,570. System Error: 115

    "Gainin Data set for Node 001e06305a6b with target output pm2_5_palas @ 31-Dec-2020 15:58:38"

Going through column 1 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 2 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 3 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 4 and choosing a representative sample. Choosing 73 bins for this column. With 3 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 3 members per bin.
Going through column 6 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 7 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 8 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 9 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 10 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 11 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 12 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 13 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 14 and choosing a representative sample. Choosing 76 bins for this column. With 3 members per bin.
Going through column 15 and choosing a representative sample. Choosing 57 bins for this column. With 3 members per bin.
Going through column 16 and choosing a representative sample. Choosing 26 bins for this column. With 3 members per bin.
Going through column 17 and choosing a representative sample. Choosing 18 bins for this column. With 3 members per bin.
Going through column 18 and choosing a representative sample. Choosing 14 bins for this column. With 3 members per bin.
Going through column 19 and choosing a representative sample. Choosing 9 bins for this column. With 3 members per bin.
Going through column 20 and choosing a representative sample. Choosing 8 bins for this column. With 3 members per bin.
Going through column 21 and choosing a representative sample. Choosing 6 bins for this column. With 3 members per bin.
Going through column 22 and choosing a representative sample. Choosing 3 bins for this column. With 3 members per bin.
Going through column 23 and choosing a representative sample. Choosing 2 bins for this column. With 3 members per bin.
Going through column 24 and choosing a representative sample. Choosing 2 bins for this column. With 3 members per bin.
Going through column 25 and choosing a representative sample. Choosing 2 bins for this column. With 3 members per bin.
Going through column 26 and choosing a representative sample. Choosing 2 bins for this column. With 3 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 3 members per bin.
Going through column 28 and choosing a representative sample. Choosing 123 bins for this column. With 3 members per bin.
Going through column 29 and choosing a representative sample. Choosing 190 bins for this column. With 3 members per bin.
Going through column 30 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 31 and choosing a representative sample. Choosing 124 bins for this column. With 3 members per bin.
Going through column 32 and choosing a representative sample. Choosing 2 bins for this column. With 3 members per bin.
Going through column 33 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 34 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 35 and choosing a representative sample. Choosing 200 bins for this column. With 3 members per bin.
Going through column 36 and choosing a representative sample. Choosing 400 bins for this column. With 6 members per bin.

ans =

        5044


ans =

   890

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |      15 | Best   |      19.417 |      1.1787 |      19.417 |      19.878 |           23 |     0.013624 |
|    2 |      15 | Accept |      23.652 |        1.28 |      19.417 |      19.878 |           53 |     0.042532 |
|    3 |       4 | Accept |      39.066 |      1.5938 |      19.038 |      43.049 |           86 |    0.0010288 |
|    4 |       4 | Accept |      55.904 |      2.4713 |      19.038 |      43.049 |           59 |     0.032524 |
|    5 |       4 | Accept |      21.305 |      1.5702 |      19.038 |      43.049 |           71 |      0.57873 |
|    6 |       4 | Accept |      96.486 |      1.4866 |      19.038 |      43.049 |           77 |     0.078724 |
|    7 |       4 | Accept |      29.115 |      5.2367 |      19.038 |      43.049 |           41 |    0.0081591 |
|    8 |       4 | Accept |      92.444 |      5.5167 |      19.038 |      43.049 |           60 |     0.023897 |
|    9 |       4 | Accept |      46.424 |      1.3477 |      19.038 |      43.049 |           23 |      0.16259 |
|   10 |       4 | Accept |      62.232 |      5.5068 |      19.038 |      43.049 |           91 |      0.11399 |
|   11 |       4 | Accept |      105.53 |      5.8697 |      19.038 |      43.049 |           81 |     0.002294 |
|   12 |       4 | Accept |      29.276 |       5.597 |      19.038 |      43.049 |           37 |    0.0049009 |
|   13 |       4 | Best   |      19.038 |      2.1734 |      19.038 |      43.049 |           58 |      0.14894 |
|   14 |       4 | Accept |      40.257 |      2.4198 |      19.038 |      43.049 |           50 |    0.0029665 |
|   15 |      13 | Accept |      25.708 |      6.9274 |      9.9092 |      43.179 |           47 |     0.010449 |
|   16 |      13 | Accept |        96.4 |      6.9769 |      9.9092 |      43.179 |           45 |    0.0039233 |
|   17 |      13 | Accept |      25.613 |     0.37012 |      9.9092 |      43.179 |           22 |    0.0069107 |
|   18 |      13 | Best   |      9.9092 |     0.44483 |      9.9092 |      43.179 |            5 |      0.99675 |
|   19 |       2 | Accept |      79.915 |      1.6119 |      9.9092 |      9.9141 |           56 |    0.0013484 |
|   20 |       2 | Accept |       34.72 |      2.8788 |      9.9092 |      9.9141 |           36 |    0.0072472 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       2 | Accept |      78.405 |      1.5464 |      9.9092 |      9.9141 |           19 |      0.27473 |
|   22 |       2 | Accept |      38.544 |       1.734 |      9.9092 |      9.9141 |            8 |      0.32133 |
|   23 |       2 | Accept |      88.197 |      1.9382 |      9.9092 |      9.9141 |           84 |     0.055631 |
|   24 |       2 | Accept |      132.63 |      5.3714 |      9.9092 |      9.9141 |           61 |     0.010128 |
|   25 |       2 | Accept |      45.492 |      5.5371 |      9.9092 |      9.9141 |           25 |    0.0017261 |
|   26 |       2 | Accept |      63.196 |       1.878 |      9.9092 |      9.9141 |           64 |      0.02828 |
|   27 |       2 | Accept |      22.608 |      5.4165 |      9.9092 |      9.9141 |           32 |     0.048756 |
|   28 |       2 | Accept |      153.73 |      5.5208 |      9.9092 |      9.9141 |           75 |      0.21866 |
|   29 |       2 | Accept |      100.47 |      5.1539 |      9.9092 |      9.9141 |           14 |      0.39701 |
|   30 |       2 | Accept |      35.152 |      4.6408 |      9.9092 |      9.9141 |           68 |      0.31266 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 20.2953 seconds.
Total objective function evaluation time: 101.1953

Best observed feasible point:
    hiddenLayerSize      lr   
    _______________    _______

           5           0.99675

Observed objective function value = 9.9092
Estimated objective function value = 9.9141
Function evaluation time = 0.44483

Best estimated feasible point (according to models):
    hiddenLayerSize      lr   
    _______________    _______

           5           0.99675

Estimated objective function value = 9.9141
Estimated function evaluation time = 2.6293


T =

  1x2 table

    hiddenLayerSize      lr   
    _______________    _______

           5           0.99675

Elapsed time is 41.571317 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      5.7826 |      2804.1 |      5.7826 |      5.7826 |       58.966 |       linear |     matern52 |   1.3729e+13 |         true |
|    2 |      16 | Best   |      3.9511 |      2901.7 |      3.9511 |      4.0239 |       41.209 |     constant |     matern32 |   1.4416e+13 |         true |
|    3 |      16 | Accept |      19.816 |      3045.2 |      3.9511 |      7.6273 |      0.22774 | pureQuadrati |     matern32 |   2.0103e+12 |         true |
|    4 |      16 | Best   |      3.9511 |      2666.7 |      3.9511 |      3.9514 |       2.7771 |     constant |     matern32 |   2.1559e+12 |         true |
|    5 |      16 | Best   |       3.951 |      6260.7 |       3.951 |      3.9513 |    0.0070061 |         none |     matern32 |   7.1968e+10 |         true |
|    6 |      16 | Accept |      3.9515 |      2798.6 |       3.951 |      3.9514 |        34.57 |     constant |     matern32 |   1.4738e+13 |         true |
|    7 |      16 | Accept |      3.9519 |      2688.4 |       3.951 |      3.9513 |       9.6147 |     constant |     matern52 |   3.1068e+11 |         true |
|    8 |      16 | Accept |       3.951 |        4030 |       3.951 |      3.9513 |      0.22724 |         none |     matern52 |   4.2773e+12 |         true |
|    9 |      16 | Best   |      3.8781 |      4714.4 |      3.8781 |      3.8783 |       4.1116 |     constant |     matern32 |   8.5345e+12 |        false |
|   10 |      16 | Best   |      3.6409 |      1780.5 |      3.6409 |      3.6411 |       4.1054 |     constant |  exponential |   8.1943e+12 |        false |
|   11 |      16 | Accept |      7.6472 |      5757.8 |      3.6409 |      3.6411 |      0.03198 |         none |     matern32 |   1.1245e+12 |        false |
|   12 |      16 | Accept |      10.484 |      6285.6 |      3.6409 |      3.6411 |     0.058684 |     constant |     matern52 |   3.2797e+11 |        false |
|   13 |      16 | Error  |         NaN |      4577.7 |      3.6409 |      3.6411 |       1.1248 |         none |  exponential |   8.1559e+12 |        false |
|   14 |      16 | Accept |      3.9519 |      3863.3 |      3.6409 |      3.6411 |        10.26 |     constant | rationalquad |   3.8616e+11 |         true |
|   15 |      16 | Accept |       3.951 |       22709 |      3.6409 |      3.6411 |     0.082134 |     constant |  exponential |   6.7747e+12 |         true |
|   16 |      16 | Accept |      24.825 |       22800 |      3.6409 |      3.6412 |   0.00026434 | pureQuadrati |     matern52 |   1.8207e+12 |         true |
|   17 |      16 | Best   |      2.0552 |      6758.6 |      2.0552 |      2.0557 |    0.0083107 |         none |  exponential |   6.4827e+10 |         true |
|   18 |      16 | Accept |      3.9512 |        2668 |      2.0552 |      2.0557 |       14.992 |     constant | squaredexpon |   3.4067e+11 |         true |
|   19 |      16 | Accept |      3.9006 |      1208.3 |      2.0552 |      2.0556 |       12.514 |     constant | squaredexpon |   4.0111e+11 |        false |
|   20 |      16 | Accept |       9.061 |      2597.7 |      2.0552 |      2.0557 |      0.29131 |       linear |  exponential |   6.2748e+12 |         true |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      16 | Accept |       3.903 |      1395.2 |      2.0552 |      2.0556 |       20.864 |         none | squaredexpon |   1.0098e+12 |        false |
|   22 |      16 | Accept |       3.951 |        1647 |      2.0552 |      2.0556 |       12.862 |         none | squaredexpon |   2.6904e+11 |         true |
|   23 |      16 | Accept |      6.3614 |      2836.2 |      2.0552 |      2.0556 |       19.173 |       linear | squaredexpon |   9.9201e+11 |        false |
|   24 |      16 | Accept |      3.8725 |      5892.7 |      2.0552 |      2.0556 |       14.292 |         none | rationalquad |   9.6621e+11 |        false |
|   25 |      16 | Accept |      6.1077 |      2551.4 |      2.0552 |      2.0556 |       11.901 |       linear | squaredexpon |   3.8221e+12 |         true |
|   26 |      16 | Accept |      3.9049 |      3820.8 |      2.0552 |      2.0556 |       13.212 |     constant | rationalquad |   8.1511e+11 |        false |
|   27 |      16 | Accept |       9.169 |      4094.1 |      2.0552 |      2.0556 |       16.459 |       linear | rationalquad |   1.2375e+12 |        false |
|   28 |      16 | Accept |      3.9294 |      1658.1 |      2.0552 |      2.0556 |         24.9 | pureQuadrati | squaredexpon |   1.4004e+13 |        false |
|   29 |      16 | Accept |      21.638 |      2727.4 |      2.0552 |      2.0557 |       15.729 | pureQuadrati | squaredexpon |   3.1128e+12 |         true |
|   30 |      16 | Accept |      5.8803 |       48185 |      2.0552 |      2.0557 |     0.032087 |         none |     matern52 |   3.9285e+12 |        false |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 30
Total elapsed time: 48407.2182 seconds.
Total objective function evaluation time: 187724.0137

Best observed feasible point:
      Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    _________    _____________    ______________    ___________    ___________

    0.0083107        none          exponential      6.4827e+10        true    

Observed objective function value = 2.0552
Estimated objective function value = 2.0557
Function evaluation time = 6758.5567

Best estimated feasible point (according to models):
      Sigma      BasisFunction    KernelFunction    KernelScale    Standardize
    _________    _____________    ______________    ___________    ___________

    0.0083107        none          exponential      6.4827e+10        true    

Estimated objective function value = 2.0557
Estimated function evaluation time = 3905.5564

Elapsed time is 48531.388966 seconds.
Take a copy of the best attributes
Now use these optimum settings to do an exact GPR fit
Elapsed time is 32.754064 seconds.
Train a hyper-parameter optimized Ensemble of Trees model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|    1 |      16 | Best   |       4.759 |      7.8608 |       4.759 |       4.759 |      LSBoost |           17 |    0.0014978 |          379 |          110 |           30 |
|    2 |      15 | Best   |      2.1681 |      24.012 |      2.1681 |      2.2879 |          Bag |           31 |            - |           22 |           31 |           19 |
|    3 |      15 | Accept |      3.5459 |      10.044 |      2.1681 |      2.2879 |          Bag |           45 |            - |         1765 |          122 |           29 |
|    4 |      13 | Accept |      3.4622 |      71.651 |      2.1681 |      2.1683 |          Bag |          215 |            - |          970 |          137 |           20 |
|    5 |      13 | Accept |      3.9508 |      49.094 |      2.1681 |      2.1683 |          Bag |          240 |            - |         2022 |            1 |           30 |
|    6 |      13 | Accept |      2.4933 |      37.641 |      2.1681 |      2.1683 |      LSBoost |           38 |       0.1763 |            2 |            5 |            7 |
|    7 |      13 | Accept |      4.6874 |      79.669 |      2.1681 |      2.1683 |      LSBoost |           14 |    0.0046894 |          124 |            8 |           26 |
|    8 |      11 | Accept |      3.6659 |      83.697 |      2.1681 |      2.1684 |      LSBoost |          470 |     0.003087 |         1477 |            1 |           16 |
|    9 |      11 | Accept |      2.3239 |      26.116 |      2.1681 |      2.1684 |          Bag |           45 |            - |           24 |           22 |           23 |
|   10 |      11 | Accept |      2.5187 |      4.3282 |      2.1681 |      2.1684 |      LSBoost |           11 |      0.17635 |           29 |            7 |           19 |
|   11 |      16 | Accept |      3.6068 |      115.07 |      2.1681 |      2.1927 |          Bag |           45 |            - |         1698 |            1 |           17 |
|   12 |      11 | Accept |      4.7263 |      141.79 |      1.4993 |      1.4995 |      LSBoost |           42 |    0.0010727 |          302 |            2 |           33 |
|   13 |      11 | Best   |      1.4993 |      56.655 |      1.4993 |      1.4995 |      LSBoost |           19 |      0.71969 |            1 |         4461 |           26 |
|   14 |      11 | Accept |      3.4876 |      4.4811 |      1.4993 |      1.4995 |          Bag |           10 |            - |            1 |          179 |            2 |
|   15 |      11 | Accept |      2.8018 |      5.9059 |      1.4993 |      1.4995 |      LSBoost |           16 |       0.1669 |         1012 |          480 |           30 |
|   16 |      11 | Accept |      4.7755 |      31.599 |      1.4993 |      1.4995 |      LSBoost |           11 |    0.0013604 |            3 |           47 |           34 |
|   17 |      11 | Accept |      1.6232 |      9.7525 |      1.4993 |      1.4995 |          Bag |           13 |            - |            3 |          673 |            7 |
|   18 |      16 | Accept |      1.5694 |      15.568 |      1.4993 |       1.503 |          Bag |           10 |            - |            7 |         4453 |           25 |
|   19 |      13 | Accept |      1.6724 |      246.17 |      1.4993 |      1.6002 |      LSBoost |          315 |     0.042464 |           80 |          382 |           18 |
|   20 |      13 | Accept |      1.6866 |      224.73 |      1.4993 |      1.6002 |          Bag |          250 |            - |            4 |          211 |           19 |
|===========================================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |       Method | NumLearningC-|    LearnRate |  MinLeafSize | MaxNumSplits | NumVariables-|
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              | ycles        |              |              |              | ToSample     |
|===========================================================================================================================================================================|
|   21 |      13 | Accept |      2.9108 |      66.235 |      1.4993 |      1.6002 |      LSBoost |          408 |      0.97951 |          133 |            2 |            4 |
|   22 |      13 | Accept |      3.9868 |      21.159 |      1.4993 |      1.6002 |      LSBoost |           27 |     0.017402 |           64 |           43 |           22 |
|   23 |      13 | Accept |      3.0528 |      90.099 |      1.4993 |      1.5032 |          Bag |          209 |            - |          254 |          293 |           14 |
|   24 |      12 | Accept |      1.7005 |      336.09 |      1.4993 |      1.5037 |      LSBoost |           80 |     0.070113 |           12 |         1454 |           10 |
|   25 |      12 | Accept |      2.1195 |       28.52 |      1.4993 |      1.5037 |      LSBoost |           30 |     0.069968 |          109 |          993 |           30 |
|   26 |       9 | Accept |      2.0513 |         170 |      1.4993 |      1.6252 |      LSBoost |          388 |      0.12451 |            2 |            2 |           27 |
|   27 |       9 | Accept |      1.8599 |      155.77 |      1.4993 |      1.6252 |      LSBoost |           52 |     0.046853 |            3 |           63 |           21 |
|   28 |       9 | Accept |      3.6062 |      153.21 |      1.4993 |      1.6252 |      LSBoost |           52 |      0.02524 |         1016 |           53 |           13 |
|   29 |       9 | Accept |      1.8768 |      8.9287 |      1.4993 |      1.6252 |      LSBoost |           15 |      0.76782 |            3 |           19 |           22 |
|   30 |      15 | Accept |      4.7686 |      8.1553 |      1.4993 |      1.5059 |      LSBoost |           13 |    0.0014883 |           44 |          341 |           12 |
|   31 |      15 | Accept |      4.6268 |      8.1887 |      1.4993 |      1.5059 |      LSBoost |           24 |    0.0046699 |          422 |         2226 |           16 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 31
Total elapsed time: 435.6724 seconds.
Total objective function evaluation time: 2292.189

Best observed feasible point:
    Method     NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    _______    _________________    _________    ___________    ____________    ____________________

    LSBoost           19             0.71969          1             4461                 26         

Observed objective function value = 1.4993
Estimated objective function value = 1.5059
Function evaluation time = 56.6548

Best estimated feasible point (according to models):
    Method     NumLearningCycles    LearnRate    MinLeafSize    MaxNumSplits    NumVariablesToSample
    _______    _________________    _________    ___________    ____________    ____________________

    LSBoost           19             0.71969          1             4461                 26         

Estimated objective function value = 1.5059
Estimated function evaluation time = 56.6456

Elapsed time is 450.271059 seconds.
Train the super learner model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Error  |         NaN |      3994.7 |         NaN |         NaN |    0.0053834 |     constant |  exponential |    1.515e+11 |        false |
|    2 |      16 | Error  |         NaN |      4002.9 |         NaN |         NaN |    0.0080902 |         none |  exponential |   6.0982e+10 |        false |
|    3 |      16 | Best   |      1.8781 |      5259.6 |      1.8781 |      1.8781 |       9.0926 | pureQuadrati |  exponential |   4.1442e+12 |         true |
|    4 |      15 | Accept |      3.9516 |        5271 |      1.8781 |      1.9623 |    0.0024506 |     constant | squaredexpon |   7.7634e+12 |         true |
|    5 |      15 | Accept |        3.95 |      5336.9 |      1.8781 |      1.9623 |     0.020366 |     constant |     matern32 |    3.656e+10 |         true |
|    6 |      14 | Best   |    0.017677 |      5686.3 |    0.017677 |     0.15051 |       8.4688 | pureQuadrati | squaredexpon |   4.2031e+10 |         true |
|    7 |      14 | Error  |         NaN |      5486.5 |    0.017677 |     0.15051 |     0.068694 |         none |  exponential |     2.66e+12 |        false |
|    8 |      16 | Accept |      3.9504 |      3065.1 |    0.017677 |     0.15816 |       1.7867 |         none |     matern52 |   2.0272e+11 |         true |
|    9 |      16 | Accept |    0.022187 |      4807.5 |    0.017677 |     0.21107 |       46.978 | pureQuadrati |  exponential |   1.9496e+13 |         true |
|   10 |      16 | Accept |      0.2658 |      4562.6 |    0.017677 |    0.026453 |      0.30802 | pureQuadrati | squaredexpon |   4.4079e+10 |         true |
|   11 |      16 | Accept |    0.019423 |      5186.4 |    0.017677 |    0.019044 |        26.07 | pureQuadrati | squaredexpon |   2.1452e+11 |         true |
|   12 |      16 | Best   |    0.012522 |      4936.3 |    0.012522 |    0.012635 |       30.728 | pureQuadrati | squaredexpon |   2.6816e+10 |         true |
|   13 |      16 | Accept |    0.016444 |      3736.2 |    0.012522 |   -0.018676 |       2.4838 | pureQuadrati | squaredexpon |   2.0896e+10 |         true |
|   14 |      16 | Accept |    0.033573 |      3982.4 |    0.012522 |   -0.015774 |       4.7743 | pureQuadrati |  exponential |   2.0569e+13 |         true |
|   15 |      16 | Accept |     0.64385 |      4141.7 |    0.012522 |   -0.019958 |   0.00075166 | pureQuadrati |  exponential |   1.4982e+13 |         true |
|   16 |      16 | Best   |    0.010015 |      3884.1 |    0.010015 |   -0.020495 |       11.296 | pureQuadrati | squaredexpon |    2.676e+12 |         true |
|   17 |      16 | Best   |  1.2163e-08 |      4163.1 |  1.2163e-08 |   -0.020306 |   0.00030455 |       linear |     matern32 |   2.0198e+13 |         true |
|   18 |      16 | Best   |  1.0343e-08 |        3772 |  1.0343e-08 |    -0.02004 |        68.86 |       linear | squaredexpon |   4.7026e+10 |         true |
|   19 |      16 | Accept |  5.1847e-06 |      3075.7 |  1.0343e-08 |    -0.02021 |     0.052757 |       linear | squaredexpon |    2.013e+13 |         true |
|   20 |      16 | Accept |     0.43128 |      3129.1 |  1.0343e-08 |    -0.02049 |       62.286 | pureQuadrati | squaredexpon |   2.0063e+13 |         true |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 20 reached.
Total function evaluations: 20
Total elapsed time: 19567.8813 seconds.
Total objective function evaluation time: 87479.9425

Best observed feasible point:
    Sigma    BasisFunction      KernelFunction      KernelScale    Standardize
    _____    _____________    __________________    ___________    ___________

    68.86       linear        squaredexponential    4.7026e+10        true    

Observed objective function value = 1.0343e-08
Estimated objective function value = 0.00092914
Function evaluation time = 3771.9576

Best estimated feasible point (according to models):
    Sigma     BasisFunction      KernelFunction      KernelScale    Standardize
    ______    _____________    __________________    ___________    ___________

    30.728    pureQuadratic    squaredexponential    2.6816e+10        true    

Estimated objective function value = -0.02049
Estimated function evaluation time = 4271.1057

[Warning: Explicit basis matrix in the GPR model is not of full column rank -
some basis coefficients are not identifiable. This could be because the
predictor matrix X is rank deficient or has a constant predictor.] 
[> In classreg.learning.impl/GPImpl/checkExplicitBasisRank (line 3132)
  In classreg.learning.impl/GPImpl/make (line 236)
  In RegressionGP (line 277)
  In classreg.learning/FitTemplate/fit (line 263)
  In RegressionGP.fit (line 308)
  In fitrgp (line 469)
  In classreg.learning.paramoptim.fitToFullDataset (line 7)
  In classreg.learning.paramoptim.fitoptimizing (line 40)
  In fitrgp (line 467)
  In fitrsuperOptimized (line 90)
  In utdNodesOptSolo3 (line 214)] 
Elapsed time is 19679.947906 seconds.
Train the super learner error model for regression
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Error  |         NaN |      534.05 |         NaN |         NaN |   0.00012659 |     constant |  exponential |    6.121e+10 |        false |
