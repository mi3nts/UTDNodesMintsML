Running calibration scripts for UTD Node: 4
Running on host: compute-1-1-4

                            < M A T L A B (R) >
                  Copyright 1984-2020 The MathWorks, Inc.
              R2020a Update 1 (9.8.0.1359463) 64-bit (glnxa64)
                               April 9, 2020

 
To get started, type doc.
For product information, visit www.mathworks.com.
 
UTD_Rsl_All_TEST0_2021_02_24_11_37_59


UTD_Rsl_All_TEST0_Daily


Super Learner All Inputs



globalCSVLabel = 

    "resultsNowXT2_TEST0"



    "---------------------MINTS---------------------"

24-Feb-2021 11:38:00

mintsDefinitions = 

  struct with fields:

                dataFolder: '/home/lhw150030/mintsData'
               poolWorkers: 16
                  timeSpan: 30
                  airmarID: '001e0610c0e4'
             binsPerColumn: 200
              numberPerBin: 2
                    pValid: 0.1500
                   nodeIDs: {1x16 cell}
               inputStack1: {1x9 cell}
         mintsInputsStack1: {1x35 cell}
    mintsInputLabelsStack1: {1x35 cell}
              latestStack1: {'BME280'  'MGS001'  'OPCN2'}
               inputStack2: {1x11 cell}
              latestStack2: {'BME280'  'MGS001'  'OPCN2'  'SCD30'}
         mintsInputsStack2: {1x35 cell}
    mintsInputLabelsStack2: {1x35 cell}
               inputStack3: {1x10 cell}
              latestStack3: {'BME280'  'MGS001'  'OPCN2'  'SCD30'}
         mintsInputsStack3: {1x38 cell}
    mintsInputLabelsStack3: {1x38 cell}
              mintsTargets: {1x10 cell}
         mintsTargetLabels: {1x10 cell}
                     units: {1x10 cell}
               instruments: {1x10 cell}

Starting parallel pool (parpool) using the 'local' profile ...
Connected to the parallel pool (number of workers: 16).

ans = 

 ProcessPool with properties: 

            Connected: true
           NumWorkers: 16
              Cluster: local
        AttachedFiles: {}
    AutoAddClientPath: true
          IdleTimeout: 30 minutes (30 minutes remaining)
          SpmdEnabled: true


airmarFolder = 

    "/home/lhw150030/mintsData/referenceMats/airmar"



    "Data Folder Located @:/home/lhw150030/mintsData"

    "Raw Data Located @: /home/lhw150030/mintsData"

    "Raw DotMat Data Located @ :/home/lhw150030/mintsData/rawMats"

    "UTD Nodes DotMat Data Located @ :/home/lhw150030/mintsData/rawMats/UTDNodes"

    "Reference Data Located @: /home/lhw150030/mintsData/reference"

    "Reference DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats"

    "Palas Raw Data Located @ :/home/lhw150030/mintsData/reference/palasStream"

    "Palas DotMat Data Located @ :/home/lhw150030/mintsData/referenceMats/palas"

    "Car GPS Files Located @ :/home/lhw150030/mintsData/referenceMats/carMintsGPS"

    "Loading Palas Files"

    "Loading GPS Files"

    "Loading Airmar Files"

    "Aligning GPS data with Palas Data"

    "WSTC Palas Data"

    "Palas With Airmar"

    "Analysis"

    "Save merged data for calibration: 001e06305a61"



    "Creating Training Data Sets for Node: 001e06305a61"



    "Gainin Data set for Node 001e06305a61 with target output pm1_palas @ 24-Feb-2021 11:41:52"

Going through column 1 and choosing a representative sample. Choosing 200 bins for this column. With 2 members per bin.
Going through column 2 and choosing a representative sample. Choosing 200 bins for this column. With 2 members per bin.
Going through column 3 and choosing a representative sample. Choosing 200 bins for this column. With 2 members per bin.
Going through column 4 and choosing a representative sample. Choosing 74 bins for this column. With 2 members per bin.
Going through column 5 and choosing a representative sample. Choosing 1 bins for this column. With 2 members per bin.
Going through column 6 and choosing a representative sample. Choosing 200 bins for this column. With 2 members per bin.
Going through column 7 and choosing a representative sample. Choosing 200 bins for this column. With 2 members per bin.
Going through column 8 and choosing a representative sample. Choosing 200 bins for this column. With 2 members per bin.
Going through column 9 and choosing a representative sample. Choosing 200 bins for this column. With 2 members per bin.
Going through column 10 and choosing a representative sample. Choosing 200 bins for this column. With 2 members per bin.
Going through column 11 and choosing a representative sample. Choosing 200 bins for this column. With 2 members per bin.
Going through column 12 and choosing a representative sample. Choosing 200 bins for this column. With 2 members per bin.
Going through column 13 and choosing a representative sample. Choosing 200 bins for this column. With 2 members per bin.
Going through column 14 and choosing a representative sample. Choosing 200 bins for this column. With 2 members per bin.
Going through column 15 and choosing a representative sample. Choosing 200 bins for this column. With 2 members per bin.
Going through column 16 and choosing a representative sample. Choosing 142 bins for this column. With 2 members per bin.
Going through column 17 and choosing a representative sample. Choosing 63 bins for this column. With 2 members per bin.
Going through column 18 and choosing a representative sample. Choosing 23 bins for this column. With 2 members per bin.
Going through column 19 and choosing a representative sample. Choosing 10 bins for this column. With 2 members per bin.
Going through column 20 and choosing a representative sample. Choosing 8 bins for this column. With 2 members per bin.
Going through column 21 and choosing a representative sample. Choosing 5 bins for this column. With 2 members per bin.
Going through column 22 and choosing a representative sample. Choosing 5 bins for this column. With 2 members per bin.
Going through column 23 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 24 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 25 and choosing a representative sample. Choosing 3 bins for this column. With 2 members per bin.
Going through column 26 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 27 and choosing a representative sample. Choosing 2 bins for this column. With 2 members per bin.
Going through column 28 and choosing a representative sample. Choosing 200 bins for this column. With 2 members per bin.
Going through column 29 and choosing a representative sample. Choosing 200 bins for this column. With 2 members per bin.
Going through column 30 and choosing a representative sample. Choosing 200 bins for this column. With 2 members per bin.
Going through column 31 and choosing a representative sample. Choosing 167 bins for this column. With 2 members per bin.
Going through column 32 and choosing a representative sample. Choosing 200 bins for this column. With 2 members per bin.
Going through column 33 and choosing a representative sample. Choosing 200 bins for this column. With 2 members per bin.
Going through column 34 and choosing a representative sample. Choosing 200 bins for this column. With 2 members per bin.
Going through column 35 and choosing a representative sample. Choosing 200 bins for this column. With 2 members per bin.
Going through column 36 and choosing a representative sample. Choosing 400 bins for this column. With 4 members per bin.

ans =

        4077


ans =

   719

    "Running Regression"

Train a hyper-parameter optimized NN model for regression
Copying objective function to workers...
Done copying objective function to workers.
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|    1 |      12 | Accept |      33.224 |      8.8488 |      11.558 |       11.56 |           77 |    0.0013473 |
|    2 |      12 | Accept |       16.57 |      9.1917 |      11.558 |       11.56 |           33 |      0.10115 |
|    3 |      12 | Accept |      11.576 |      9.5797 |      11.558 |       11.56 |           31 |     0.008212 |
|    4 |      12 | Accept |      35.972 |      8.6867 |      11.558 |       11.56 |           15 |     0.023388 |
|    5 |      12 | Best   |      11.558 |       7.921 |      11.558 |       11.56 |           95 |    0.0029128 |
|    6 |       2 | Accept |      43.659 |      16.391 |      11.558 |      33.687 |           26 |    0.0013554 |
|    7 |       2 | Accept |      12.272 |       12.03 |      11.558 |      33.687 |           81 |      0.66455 |
|    8 |       2 | Accept |       14.74 |      13.089 |      11.558 |      33.687 |           38 |      0.00491 |
|    9 |       2 | Accept |       21.77 |      12.544 |      11.558 |      33.687 |           63 |      0.55345 |
|   10 |       2 | Accept |       19.06 |      13.372 |      11.558 |      33.687 |           30 |     0.012858 |
|   11 |       2 | Accept |      46.057 |      12.146 |      11.558 |      33.687 |           40 |    0.0016905 |
|   12 |       2 | Accept |      41.044 |      15.474 |      11.558 |      33.687 |           59 |      0.28533 |
|   13 |       2 | Accept |      132.14 |      13.627 |      11.558 |      33.687 |           97 |    0.0035192 |
|   14 |       2 | Accept |      49.344 |      13.232 |      11.558 |      33.687 |           33 |    0.0016153 |
|   15 |       2 | Accept |      23.811 |      11.415 |      11.558 |      33.687 |           62 |      0.39743 |
|   16 |       2 | Accept |      26.197 |      9.7472 |      11.558 |      33.687 |           80 |     0.017786 |
|   17 |      16 | Accept |       21.02 |     0.53676 |      11.558 |      32.942 |           91 |      0.97611 |
|   18 |       2 | Accept |      18.632 |     0.82466 |      7.4715 |      24.788 |            5 |      0.99526 |
|   19 |       2 | Accept |      12.855 |      2.6661 |      7.4715 |      24.788 |            9 |      0.99877 |
|   20 |       2 | Accept |      24.025 |      1.1233 |      7.4715 |      24.788 |           38 |      0.52993 |
|===============================================================================================================|
| Iter | Active  | Eval   | Objective   | Objective   | BestSoFar   | BestSoFar   | hiddenLayerS-|           lr |
|      | workers | result |             | runtime     | (observed)  | (estim.)    | ize          |              |
|===============================================================================================================|
|   21 |       2 | Accept |      22.014 |     0.78682 |      7.4715 |      24.788 |           42 |     0.039928 |
|   22 |       2 | Accept |      60.429 |      1.5991 |      7.4715 |      24.788 |           95 |    0.0014606 |
|   23 |       2 | Accept |      63.311 |     0.98562 |      7.4715 |      24.788 |           92 |      0.80986 |
|   24 |       2 | Accept |      19.277 |      2.4722 |      7.4715 |      24.788 |           49 |      0.63295 |
|   25 |       2 | Accept |      37.077 |      2.2614 |      7.4715 |      24.788 |           76 |     0.057929 |
|   26 |       2 | Best   |      7.4715 |      2.1166 |      7.4715 |      24.788 |            5 |       0.4373 |
|   27 |       2 | Accept |       61.81 |      1.8343 |      7.4715 |      24.788 |           24 |     0.005254 |
|   28 |       2 | Accept |      14.608 |      2.0174 |      7.4715 |      24.788 |           69 |      0.37551 |
|   29 |       2 | Accept |      8.2367 |      2.8007 |      7.4715 |      24.788 |           31 |     0.013749 |
|   30 |       2 | Accept |      35.217 |      2.6875 |      7.4715 |      24.788 |           61 |    0.0013779 |
|   31 |       2 | Accept |       14.24 |      1.2788 |      7.4715 |      24.788 |            8 |      0.31886 |
|   32 |       2 | Accept |      109.25 |       1.201 |      7.4715 |      24.788 |           64 |    0.0047148 |

__________________________________________________________
Optimization completed.
MaxObjectiveEvaluations of 30 reached.
Total function evaluations: 32
Total elapsed time: 42.2832 seconds.
Total objective function evaluation time: 214.4858

Best observed feasible point:
    hiddenLayerSize      lr  
    _______________    ______

           5           0.4373

Observed objective function value = 7.4715
Estimated objective function value = 24.605
Function evaluation time = 2.1166

Best estimated feasible point (according to models):
    hiddenLayerSize      lr   
    _______________    _______

          38           0.52993

Estimated objective function value = 24.7881
Estimated function evaluation time = 4.1754


T =

  1x2 table

    hiddenLayerSize      lr   
    _______________    _______

          38           0.52993

Elapsed time is 487.725373 seconds.
Train a hyper-parameter optimized GPR model for regression
First Optimize all the GPR parameters
Copying objective function to workers...
Done copying objective function to workers.
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|    1 |      16 | Best   |      3.7309 |      1291.9 |      3.7309 |      3.7309 |       18.767 |     constant |  exponential |    1.682e+13 |        false |
|    2 |      16 | Accept |      4.8309 |      1385.9 |      3.7309 |      3.7746 |    0.0012205 |       linear |     matern32 |    2.643e+10 |         true |
|    3 |      16 | Best   |        3.73 |      1408.8 |        3.73 |      3.7305 |       32.403 |     constant |  exponential |   1.6323e+12 |        false |
|    4 |      16 | Error  |         NaN |      3092.7 |        3.73 |      3.7305 |    0.0023597 |       linear |     matern52 |   2.0251e+11 |        false |
|    5 |      16 | Accept |      5.5733 |      4256.7 |        3.73 |      3.7305 |     0.001317 |         none | rationalquad |   2.6341e+12 |        false |
|    6 |      16 | Accept |      3.8797 |      5801.5 |        3.73 |      3.7305 |        32.71 |       linear |     matern52 |   6.7621e+12 |         true |
|    7 |      16 | Error  |         NaN |      3143.1 |        3.73 |      3.7305 |     0.042017 |     constant |     matern32 |   2.3009e+10 |        false |
|    8 |      16 | Accept |      3.7305 |      6876.9 |        3.73 |      3.7305 |       1.7889 |     constant | squaredexpon |   3.5509e+12 |         true |
|    9 |      16 | Accept |      3.7396 |      1293.8 |        3.73 |      3.7305 |       62.478 |         none |  exponential |   9.0703e+12 |        false |
|   10 |      16 | Accept |      9.0019 |        1408 |        3.73 |      3.7305 |       29.243 | pureQuadrati |     matern52 |   2.9207e+10 |         true |
|   11 |      16 | Best   |      3.7295 |      7834.6 |      3.7295 |      3.7305 |     0.013437 |     constant |  exponential |   1.4838e+13 |         true |
|   12 |      16 | Accept |      5.3156 |        8012 |      3.7295 |      3.7305 |       2.6615 |       linear |  exponential |    4.085e+12 |         true |
|   13 |      16 | Accept |      3.7308 |      719.19 |      3.7295 |      3.7305 |       61.229 |         none |  exponential |   6.8857e+12 |         true |
|   14 |      16 | Best   |      3.4257 |        1935 |      3.4257 |      3.4258 |       46.782 |       linear | rationalquad |   2.3482e+12 |         true |
|   15 |      16 | Accept |      3.7309 |      780.92 |      3.4257 |      3.4258 |       62.472 |         none |     matern32 |   5.5542e+11 |         true |
|   16 |      16 | Accept |      4.5282 |      1409.1 |      3.4257 |      3.4258 |       41.497 |       linear | squaredexpon |   3.3519e+12 |         true |
|   17 |      16 | Accept |      3.7299 |      776.05 |      3.4257 |      3.4258 |       34.877 |         none |     matern52 |    1.717e+12 |         true |
|   18 |      16 | Accept |      3.7503 |      706.22 |      3.4257 |      3.4258 |       56.791 |         none |     matern32 |   1.9005e+12 |        false |
|   19 |      16 | Accept |      3.7298 |      1216.4 |      3.4257 |      3.4258 |      0.67584 |     constant |     matern32 |   2.5071e+12 |         true |
|   20 |      16 | Accept |      3.7298 |      4562.3 |      3.4257 |      3.4258 |       2.4684 |         none | squaredexpon |   2.4832e+12 |         true |
|============================================================================================================================================================|
| Iter | Active  | Eval   | Objective:  | Objective   | BestSoFar   | BestSoFar   |        Sigma | BasisFunction| KernelFuncti-|  KernelScale |  Standardize |
|      | workers | result | log(1+loss) | runtime     | (observed)  | (estim.)    |              |              | on           |              |              |
|============================================================================================================================================================|
|   21 |      16 | Accept |      3.7302 |        1393 |      3.4257 |      3.4258 |       39.802 |     constant |     matern52 |   1.8793e+12 |         true |
|   22 |      16 | Accept |      3.7207 |      826.77 |      3.4257 |      3.4258 |       5.1163 |     constant |     matern52 |   1.7102e+12 |        false |
|   23 |      16 | Accept |      3.7584 |      717.69 |      3.4257 |      3.4258 |       58.176 |         none |     matern52 |   4.4367e+11 |        false |
|   24 |      16 | Accept |      3.7118 |      3041.1 |      3.4257 |      3.4258 |       2.0777 |     constant | squaredexpon |   2.0929e+12 |        false |
|   25 |      16 | Accept |      3.7311 |      5317.3 |      3.4257 |      3.4258 |       63.682 |         none | rationalquad |    3.229e+11 |         true |
|   26 |      16 | Accept |      3.7302 |       11555 |      3.4257 |      3.4258 |       1.9646 |     constant | rationalquad |   5.3368e+12 |         true |
|   27 |      16 | Accept |      3.7293 |       11903 |      3.4257 |      3.4258 |       51.302 |     constant | rationalquad |   1.3835e+11 |        false |
